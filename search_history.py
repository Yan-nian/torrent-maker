#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Search History Module - æœç´¢å†å²è®°å½•æ¨¡å—
ä¸º Torrent Maker æä¾›æ™ºèƒ½æœç´¢å†å²å’Œå»ºè®®åŠŸèƒ½

åŠŸèƒ½ç‰¹æ€§:
- æœç´¢å†å²è®°å½•ç®¡ç†
- æ™ºèƒ½æœç´¢å»ºè®®
- æœç´¢ç»Ÿè®¡å’Œåˆ†æ
- å¿«é€Ÿæœç´¢è®¿é—®
- æœç´¢æ¨¡å¼è¯†åˆ«
"""

import os
import json
import re
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from collections import Counter, defaultdict
import difflib


@dataclass
class SearchEntry:
    """æœç´¢è®°å½•æ¡ç›®"""
    query: str
    timestamp: datetime
    results_count: int = 0
    selected_results: List[str] = field(default_factory=list)
    success: bool = True
    search_time: float = 0.0  # æœç´¢è€—æ—¶(ç§’)
    category: str = ""  # æœç´¢åˆ†ç±»(ç”µå½±ã€ç”µè§†å‰§ã€åŠ¨æ¼«ç­‰)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'query': self.query,
            'timestamp': self.timestamp.isoformat(),
            'results_count': self.results_count,
            'selected_results': self.selected_results,
            'success': self.success,
            'search_time': self.search_time,
            'category': self.category,
            'metadata': self.metadata
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SearchEntry':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(
            query=data['query'],
            timestamp=datetime.fromisoformat(data['timestamp']),
            results_count=data.get('results_count', 0),
            selected_results=data.get('selected_results', []),
            success=data.get('success', True),
            search_time=data.get('search_time', 0.0),
            category=data.get('category', ''),
            metadata=data.get('metadata', {})
        )


class SearchHistory:
    """æœç´¢å†å²ç®¡ç†å™¨"""
    
    def __init__(self, history_file: str = None, max_entries: int = 1000):
        self.history_file = history_file or os.path.expanduser("~/.torrent_maker_search_history.json")
        self.max_entries = max_entries
        self.entries: List[SearchEntry] = []
        self.load_history()
    
    def add_search(self, query: str, results_count: int = 0, 
                   selected_results: List[str] = None, success: bool = True,
                   search_time: float = 0.0, category: str = "",
                   **metadata) -> SearchEntry:
        """æ·»åŠ æœç´¢è®°å½•"""
        # æ¸…ç†æŸ¥è¯¢å­—ç¬¦ä¸²
        cleaned_query = self._clean_query(query)
        if not cleaned_query:
            return None
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤æœç´¢(5åˆ†é’Ÿå†…çš„ç›¸åŒæŸ¥è¯¢)
        recent_cutoff = datetime.now() - timedelta(minutes=5)
        for entry in reversed(self.entries):
            if (entry.timestamp > recent_cutoff and 
                entry.query.lower() == cleaned_query.lower()):
                # æ›´æ–°ç°æœ‰è®°å½•
                entry.results_count = max(entry.results_count, results_count)
                if selected_results:
                    entry.selected_results.extend(selected_results)
                    entry.selected_results = list(set(entry.selected_results))  # å»é‡
                entry.success = entry.success and success
                entry.search_time = (entry.search_time + search_time) / 2  # å¹³å‡æœç´¢æ—¶é—´
                if category:
                    entry.category = category
                entry.metadata.update(metadata)
                self.save_history()
                return entry
        
        # åˆ›å»ºæ–°è®°å½•
        entry = SearchEntry(
            query=cleaned_query,
            timestamp=datetime.now(),
            results_count=results_count,
            selected_results=selected_results or [],
            success=success,
            search_time=search_time,
            category=category,
            metadata=metadata
        )
        
        self.entries.append(entry)
        
        # é™åˆ¶å†å²è®°å½•å¤§å°
        if len(self.entries) > self.max_entries:
            self.entries = self.entries[-self.max_entries:]
        
        self.save_history()
        return entry
    
    def _clean_query(self, query: str) -> str:
        """æ¸…ç†æŸ¥è¯¢å­—ç¬¦ä¸²"""
        if not query:
            return ""
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', query.strip())
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦(ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€å¸¸ç”¨ç¬¦å·)
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff.\-_()\[\]]+', '', cleaned)
        
        return cleaned
    
    def get_suggestions(self, partial_query: str, limit: int = 10) -> List[Tuple[str, float]]:
        """è·å–æœç´¢å»ºè®®"""
        if not partial_query.strip():
            # è¿”å›æœ€è¿‘çš„æœç´¢
            recent_queries = [entry.query for entry in reversed(self.entries[-limit:])]
            return [(query, 1.0) for query in recent_queries]
        
        partial_lower = partial_query.lower().strip()
        suggestions = []
        
        # æ”¶é›†æ‰€æœ‰æŸ¥è¯¢
        all_queries = [entry.query for entry in self.entries]
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        for query in set(all_queries):  # å»é‡
            query_lower = query.lower()
            
            # ç²¾ç¡®åŒ¹é…
            if query_lower.startswith(partial_lower):
                suggestions.append((query, 1.0))
            # åŒ…å«åŒ¹é…
            elif partial_lower in query_lower:
                suggestions.append((query, 0.8))
            # æ¨¡ç³ŠåŒ¹é…
            else:
                similarity = difflib.SequenceMatcher(None, partial_lower, query_lower).ratio()
                if similarity > 0.6:
                    suggestions.append((query, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦å’Œä½¿ç”¨é¢‘ç‡æ’åº
        query_counts = Counter(all_queries)
        suggestions.sort(key=lambda x: (x[1], query_counts[x[0]]), reverse=True)
        
        return suggestions[:limit]
    
    def get_popular_queries(self, limit: int = 10, days: int = 30) -> List[Tuple[str, int]]:
        """è·å–çƒ­é—¨æœç´¢"""
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_entries = [entry for entry in self.entries if entry.timestamp > cutoff_date]
        
        query_counts = Counter(entry.query for entry in recent_entries)
        return query_counts.most_common(limit)
    
    def get_recent_queries(self, limit: int = 10) -> List[str]:
        """è·å–æœ€è¿‘æœç´¢"""
        recent_queries = []
        seen = set()
        
        for entry in reversed(self.entries):
            if entry.query not in seen:
                recent_queries.append(entry.query)
                seen.add(entry.query)
                if len(recent_queries) >= limit:
                    break
        
        return recent_queries
    
    def get_successful_queries(self, limit: int = 10) -> List[str]:
        """è·å–æˆåŠŸçš„æœç´¢(æœ‰ç»“æœä¸”è¢«é€‰æ‹©)"""
        successful_queries = []
        seen = set()
        
        for entry in reversed(self.entries):
            if (entry.success and entry.results_count > 0 and 
                entry.selected_results and entry.query not in seen):
                successful_queries.append(entry.query)
                seen.add(entry.query)
                if len(successful_queries) >= limit:
                    break
        
        return successful_queries
    
    def search_history(self, keyword: str, limit: int = 20) -> List[SearchEntry]:
        """æœç´¢å†å²è®°å½•"""
        keyword_lower = keyword.lower()
        matches = []
        
        for entry in self.entries:
            if (keyword_lower in entry.query.lower() or 
                keyword_lower in entry.category.lower() or
                any(keyword_lower in result.lower() for result in entry.selected_results)):
                matches.append(entry)
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        matches.sort(key=lambda x: x.timestamp, reverse=True)
        return matches[:limit]
    
    def get_categories(self) -> List[Tuple[str, int]]:
        """è·å–æœç´¢åˆ†ç±»ç»Ÿè®¡"""
        category_counts = Counter(entry.category for entry in self.entries if entry.category)
        return category_counts.most_common()
    
    def get_statistics(self, days: int = 30) -> Dict[str, Any]:
        """è·å–æœç´¢ç»Ÿè®¡"""
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_entries = [entry for entry in self.entries if entry.timestamp > cutoff_date]
        
        if not recent_entries:
            return {
                'total_searches': 0,
                'successful_searches': 0,
                'success_rate': 0.0,
                'average_search_time': 0.0,
                'average_results': 0.0,
                'most_active_day': None,
                'popular_categories': []
            }
        
        total_searches = len(recent_entries)
        successful_searches = sum(1 for entry in recent_entries if entry.success and entry.results_count > 0)
        success_rate = (successful_searches / total_searches) * 100 if total_searches > 0 else 0
        
        # å¹³å‡æœç´¢æ—¶é—´
        search_times = [entry.search_time for entry in recent_entries if entry.search_time > 0]
        average_search_time = sum(search_times) / len(search_times) if search_times else 0
        
        # å¹³å‡ç»“æœæ•°
        results_counts = [entry.results_count for entry in recent_entries if entry.results_count > 0]
        average_results = sum(results_counts) / len(results_counts) if results_counts else 0
        
        # æœ€æ´»è·ƒçš„æ—¥æœŸ
        daily_counts = defaultdict(int)
        for entry in recent_entries:
            date_key = entry.timestamp.date()
            daily_counts[date_key] += 1
        
        most_active_day = max(daily_counts.items(), key=lambda x: x[1]) if daily_counts else None
        
        # çƒ­é—¨åˆ†ç±»
        category_counts = Counter(entry.category for entry in recent_entries if entry.category)
        popular_categories = category_counts.most_common(5)
        
        return {
            'total_searches': total_searches,
            'successful_searches': successful_searches,
            'success_rate': success_rate,
            'average_search_time': average_search_time,
            'average_results': average_results,
            'most_active_day': most_active_day,
            'popular_categories': popular_categories
        }
    
    def clear_history(self, older_than_days: int = None) -> int:
        """æ¸…ç©ºå†å²è®°å½•"""
        if older_than_days is None:
            # æ¸…ç©ºæ‰€æœ‰
            count = len(self.entries)
            self.entries = []
        else:
            # æ¸…ç©ºæŒ‡å®šå¤©æ•°å‰çš„è®°å½•
            cutoff_date = datetime.now() - timedelta(days=older_than_days)
            old_count = len(self.entries)
            self.entries = [entry for entry in self.entries if entry.timestamp > cutoff_date]
            count = old_count - len(self.entries)
        
        self.save_history()
        return count
    
    def export_history(self, output_file: str, format: str = 'json') -> bool:
        """å¯¼å‡ºå†å²è®°å½•"""
        try:
            if format.lower() == 'json':
                data = {
                    'export_time': datetime.now().isoformat(),
                    'total_entries': len(self.entries),
                    'entries': [entry.to_dict() for entry in self.entries]
                }
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            
            elif format.lower() == 'csv':
                import csv
                with open(output_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(['æŸ¥è¯¢', 'æ—¶é—´', 'ç»“æœæ•°', 'æˆåŠŸ', 'æœç´¢æ—¶é—´', 'åˆ†ç±»'])
                    for entry in self.entries:
                        writer.writerow([
                            entry.query,
                            entry.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                            entry.results_count,
                            'æ˜¯' if entry.success else 'å¦',
                            f"{entry.search_time:.2f}s",
                            entry.category
                        ])
            
            return True
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return False
    
    def load_history(self):
        """åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    entries_data = data.get('entries', data)  # å…¼å®¹æ—§æ ¼å¼
                    self.entries = [SearchEntry.from_dict(entry_data) for entry_data in entries_data]
        except (json.JSONDecodeError, OSError, KeyError) as e:
            print(f"âš ï¸ åŠ è½½æœç´¢å†å²å¤±è´¥: {e}")
            self.entries = []
    
    def save_history(self):
        """ä¿å­˜å†å²è®°å½•"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
            
            data = {
                'version': '1.0',
                'last_updated': datetime.now().isoformat(),
                'total_entries': len(self.entries),
                'entries': [entry.to_dict() for entry in self.entries]
            }
            
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except OSError as e:
            print(f"âš ï¸ ä¿å­˜æœç´¢å†å²å¤±è´¥: {e}")


class SmartSearchSuggester:
    """æ™ºèƒ½æœç´¢å»ºè®®å™¨"""
    
    def __init__(self, search_history: SearchHistory):
        self.history = search_history
        self.patterns = self._load_search_patterns()
    
    def _load_search_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½æœç´¢æ¨¡å¼"""
        return {
            'ç”µå½±': [
                r'\d{4}',  # å¹´ä»½
                r'(ç”µå½±|movie|film)',
                r'(HD|4K|1080p|720p|BluRay|BDRip)',
                r'(ä¸­å­—|å­—å¹•|subtitle)'
            ],
            'ç”µè§†å‰§': [
                r'(ç¬¬\d+å­£|S\d+|season)',
                r'(ç¬¬\d+é›†|E\d+|episode)',
                r'(ç”µè§†å‰§|TV|series)',
                r'(å…¨é›†|å®Œæ•´ç‰ˆ|complete)'
            ],
            'åŠ¨æ¼«': [
                r'(åŠ¨æ¼«|anime|åŠ¨ç”»)',
                r'(ç¬¬\d+è¯|ç¬¬\d+é›†)',
                r'(OVA|OAD|å‰§åœºç‰ˆ)',
                r'(æ—¥è¯­|ä¸­é…|åŒè¯­)'
            ],
            'çºªå½•ç‰‡': [
                r'(çºªå½•ç‰‡|documentary)',
                r'(BBC|National Geographic|Discovery)',
                r'(è‡ªç„¶|å†å²|ç§‘å­¦)'
            ]
        }
    
    def suggest_improvements(self, query: str) -> List[str]:
        """å»ºè®®æŸ¥è¯¢æ”¹è¿›"""
        suggestions = []
        
        # æ£€æµ‹å¯èƒ½çš„åˆ†ç±»
        detected_category = self._detect_category(query)
        if detected_category:
            suggestions.append(f"æ£€æµ‹åˆ°ç±»å‹: {detected_category}")
        
        # å»ºè®®æ·»åŠ å¹´ä»½
        if not re.search(r'\d{4}', query) and detected_category in ['ç”µå½±', 'ç”µè§†å‰§']:
            suggestions.append("å»ºè®®æ·»åŠ å¹´ä»½ä»¥è·å¾—æ›´ç²¾ç¡®çš„ç»“æœ")
        
        # å»ºè®®æ·»åŠ ç”»è´¨ä¿¡æ¯
        if not re.search(r'(HD|4K|1080p|720p|BluRay)', query, re.IGNORECASE):
            suggestions.append("å¯ä»¥æ·»åŠ ç”»è´¨ä¿¡æ¯ (å¦‚: 1080p, 4K)")
        
        # å»ºè®®æ·»åŠ å­—å¹•ä¿¡æ¯
        if not re.search(r'(ä¸­å­—|å­—å¹•|subtitle)', query, re.IGNORECASE):
            suggestions.append("å¯ä»¥æ·»åŠ å­—å¹•ä¿¡æ¯ (å¦‚: ä¸­å­—)")
        
        return suggestions
    
    def _detect_category(self, query: str) -> Optional[str]:
        """æ£€æµ‹æŸ¥è¯¢åˆ†ç±»"""
        query_lower = query.lower()
        
        for category, patterns in self.patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    return category
        
        return None
    
    def get_related_queries(self, query: str, limit: int = 5) -> List[str]:
        """è·å–ç›¸å…³æŸ¥è¯¢"""
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(query)
        
        related = []
        for entry in self.history.entries:
            if entry.query.lower() != query.lower():
                entry_keywords = self._extract_keywords(entry.query)
                # è®¡ç®—å…³é”®è¯é‡å åº¦
                overlap = len(set(keywords) & set(entry_keywords))
                if overlap > 0:
                    related.append((entry.query, overlap))
        
        # æŒ‰é‡å åº¦æ’åº
        related.sort(key=lambda x: x[1], reverse=True)
        return [query for query, _ in related[:limit]]
    
    def _extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç§»é™¤å¸¸è§åœç”¨è¯
        stop_words = {'çš„', 'å’Œ', 'ä¸', 'æˆ–', 'åœ¨', 'æ˜¯', 'æœ‰', 'äº†', 'ä¸­', 'ä¸º', 'ä»', 'åˆ°'}
        
        # åˆ†è¯(ç®€å•æŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²)
        words = re.findall(r'[\w\u4e00-\u9fff]+', query.lower())
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = [word for word in words if len(word) > 1 and word not in stop_words]
        
        return keywords


def test_search_history():
    """æµ‹è¯•æœç´¢å†å²åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æœç´¢å†å²åŠŸèƒ½")
    
    history = SearchHistory()
    suggester = SmartSearchSuggester(history)
    
    # æ·»åŠ æµ‹è¯•æ•°æ®
    test_queries = [
        ("å¤ä»‡è€…è”ç›Ÿ4 2019 4K", 15, ["Avengers.Endgame.2019.4K.mkv"], True, 1.2, "ç”µå½±"),
        ("æƒåŠ›çš„æ¸¸æˆ ç¬¬å…«å­£", 8, ["Game.of.Thrones.S08.mkv"], True, 0.8, "ç”µè§†å‰§"),
        ("é¬¼ç­ä¹‹åˆƒ åŠ¨æ¼«", 12, ["Demon.Slayer.anime.mkv"], True, 0.9, "åŠ¨æ¼«"),
        ("å¤ä»‡è€…è”ç›Ÿ", 25, [], True, 1.5, "ç”µå½±"),
        ("æƒåŠ›çš„æ¸¸æˆ", 20, ["Game.of.Thrones.S01.mkv"], True, 1.1, "ç”µè§†å‰§")
    ]
    
    for query, count, results, success, time, category in test_queries:
        history.add_search(query, count, results, success, time, category)
    
    # æµ‹è¯•å»ºè®®åŠŸèƒ½
    print("\nğŸ” æœç´¢å»ºè®®æµ‹è¯•:")
    suggestions = history.get_suggestions("å¤ä»‡")
    for suggestion, score in suggestions:
        print(f"  {suggestion} (ç›¸ä¼¼åº¦: {score:.2f})")
    
    # æµ‹è¯•çƒ­é—¨æŸ¥è¯¢
    print("\nğŸ”¥ çƒ­é—¨æŸ¥è¯¢:")
    popular = history.get_popular_queries()
    for query, count in popular:
        print(f"  {query}: {count}æ¬¡")
    
    # æµ‹è¯•æ™ºèƒ½å»ºè®®
    print("\nğŸ’¡ æ™ºèƒ½å»ºè®®:")
    improvements = suggester.suggest_improvements("å¤ä»‡è€…è”ç›Ÿ")
    for improvement in improvements:
        print(f"  {improvement}")
    
    # æµ‹è¯•ç›¸å…³æŸ¥è¯¢
    print("\nğŸ”— ç›¸å…³æŸ¥è¯¢:")
    related = suggester.get_related_queries("å¤ä»‡è€…è”ç›Ÿ4")
    for query in related:
        print(f"  {query}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = history.get_statistics()
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æœç´¢æ¬¡æ•°: {stats['total_searches']}")
    print(f"  æˆåŠŸç‡: {stats['success_rate']:.1f}%")
    print(f"  å¹³å‡æœç´¢æ—¶é—´: {stats['average_search_time']:.2f}ç§’")
    print(f"  å¹³å‡ç»“æœæ•°: {stats['average_results']:.1f}")


if __name__ == "__main__":
    test_search_history()