#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Torrent Maker v1.5.0 ç¬¬äºŒé˜¶æ®µä¼˜åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•æœç´¢ç®—æ³•ä¼˜åŒ–ã€å†…å­˜ç®¡ç†å’Œå¼‚æ­¥ I/O å¤„ç†

ä½œè€…ï¼šTorrent Maker Team
ç‰ˆæœ¬ï¼š1.5.0 Stage 2
"""

import os
import sys
import time
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from torrent_maker import (
        TorrentCreator, FileMatcher, DirectorySizeCache,
        SmartIndexCache, FastSimilarityCalculator, MemoryManager,
        StreamFileProcessor, AsyncIOProcessor
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class Stage2OptimizationTest:
    """ç¬¬äºŒé˜¶æ®µä¼˜åŒ–æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_data_dir = None
        self.results = {}
    
    def setup_test_data(self) -> str:
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        print("ğŸ”§ åˆ›å»ºç¬¬äºŒé˜¶æ®µæµ‹è¯•æ•°æ®...")
        
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
        self.test_data_dir = tempfile.mkdtemp(prefix="torrent_stage2_test_")
        test_path = Path(self.test_data_dir)
        
        # åˆ›å»ºå¤šæ ·åŒ–çš„æµ‹è¯•æ–‡ä»¶å¤¹
        test_folders = [
            "The.Matrix.1999.1080p.BluRay.x264",
            "Inception.2010.4K.UHD.HDR",
            "Avengers.Endgame.2019.720p.WEBRip",
            "Breaking.Bad.S01.Complete.1080p",
            "Game.of.Thrones.S08E06.FINAL",
            "Spider-Man.No.Way.Home.2021",
            "The.Office.US.Complete.Series",
            "Stranger.Things.S04.2160p.Netflix",
            "Top.Gun.Maverick.2022.IMAX",
            "House.of.Cards.S01-S06.Complete"
        ]
        
        for folder_name in test_folders:
            folder_path = test_path / folder_name
            folder_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºä¸€äº›æµ‹è¯•æ–‡ä»¶
            for i in range(3):
                file_name = f"{folder_name}.part{i+1}.mkv"
                file_path = folder_path / file_name
                with open(file_path, 'w') as f:
                    f.write(f"Test content for {file_name}")
        
        print(f"âœ… æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ: {self.test_data_dir}")
        return self.test_data_dir
    
    def cleanup_test_data(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        if self.test_data_dir and os.path.exists(self.test_data_dir):
            shutil.rmtree(self.test_data_dir)
            print(f"ğŸ§¹ æµ‹è¯•æ•°æ®å·²æ¸…ç†: {self.test_data_dir}")
    
    def test_smart_search_optimization(self) -> Dict[str, Any]:
        """æµ‹è¯•æ™ºèƒ½æœç´¢ä¼˜åŒ–"""
        print("\nğŸ” æµ‹è¯•æ™ºèƒ½æœç´¢ä¼˜åŒ–...")
        
        matcher = FileMatcher(self.test_data_dir, enable_cache=True)
        
        # æµ‹è¯•æœç´¢æŸ¥è¯¢
        search_queries = [
            "Matrix",
            "Breaking Bad",
            "Avengers",
            "Spider Man",
            "Game Thrones"
        ]
        
        results = {
            'search_times': [],
            'cache_performance': {},
            'index_performance': {},
            'total_searches': len(search_queries)
        }
        
        print("  æ‰§è¡Œæœç´¢æµ‹è¯•...")
        for query in search_queries:
            print(f"    æœç´¢: '{query}'")
            
            start_time = time.time()
            matches = matcher.fuzzy_search(query, max_results=5)
            search_time = time.time() - start_time
            
            results['search_times'].append(search_time)
            print(f"      è€—æ—¶: {search_time:.4f}s, æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        perf_stats = matcher.get_performance_stats()
        results['cache_performance'] = perf_stats.get('cache_performance', {})
        results['optimization_level'] = perf_stats.get('optimization_level', 'Unknown')
        
        # è®¡ç®—å¹³å‡æœç´¢æ—¶é—´
        results['avg_search_time'] = sum(results['search_times']) / len(results['search_times'])
        results['fastest_search'] = min(results['search_times'])
        results['slowest_search'] = max(results['search_times'])
        
        return results
    
    def test_memory_management(self) -> Dict[str, Any]:
        """æµ‹è¯•å†…å­˜ç®¡ç†"""
        print("\nğŸ’¾ æµ‹è¯•å†…å­˜ç®¡ç†...")
        
        memory_manager = MemoryManager(max_memory_mb=128)
        
        results = {
            'initial_memory': memory_manager.get_memory_usage(),
            'cleanup_results': [],
            'memory_efficiency': 'Unknown'
        }
        
        print("  åˆå§‹å†…å­˜çŠ¶æ€:")
        initial_mem = results['initial_memory']
        print(f"    RSS: {initial_mem.get('rss_mb', 0):.1f}MB")
        print(f"    å¯ç”¨: {initial_mem.get('available_mb', 0):.1f}MB")
        
        # æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨
        print("  æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨...")
        large_data = []
        for i in range(100):
            large_data.append([f"data_{j}" for j in range(1000)])
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        current_mem = memory_manager.get_memory_usage()
        print(f"  ä½¿ç”¨åå†…å­˜: {current_mem.get('rss_mb', 0):.1f}MB")
        
        # æµ‹è¯•å†…å­˜æ¸…ç†
        print("  æµ‹è¯•å†…å­˜æ¸…ç†...")
        cleaned_items = memory_manager.cleanup_memory()
        results['cleanup_results'].append(cleaned_items)
        
        # æ¸…ç†å¤§æ•°æ®
        del large_data
        
        final_mem = memory_manager.get_memory_usage()
        results['final_memory'] = final_mem
        
        print(f"  æ¸…ç†åå†…å­˜: {final_mem.get('rss_mb', 0):.1f}MB")
        print(f"  æ¸…ç†é¡¹ç›®æ•°: {cleaned_items}")
        
        return results
    
    def test_async_io_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥ I/O å¤„ç†"""
        print("\nâš¡ æµ‹è¯•å¼‚æ­¥ I/O å¤„ç†...")
        
        async_processor = AsyncIOProcessor(max_concurrent=4)
        stream_processor = StreamFileProcessor()
        
        results = {
            'async_scan_time': 0,
            'stream_operations': [],
            'concurrent_operations': 0
        }
        
        # æµ‹è¯•å¼‚æ­¥ç›®å½•æ‰«æ
        print("  æµ‹è¯•å¼‚æ­¥ç›®å½•æ‰«æ...")
        start_time = time.time()
        folders = async_processor.async_directory_scan(Path(self.test_data_dir), max_depth=2)
        async_scan_time = time.time() - start_time
        
        results['async_scan_time'] = async_scan_time
        results['folders_found'] = len(folders)
        
        print(f"    å¼‚æ­¥æ‰«æè€—æ—¶: {async_scan_time:.4f}s")
        print(f"    æ‰¾åˆ°æ–‡ä»¶å¤¹: {len(folders)} ä¸ª")
        
        # æµ‹è¯•æµå¼æ–‡ä»¶å¤„ç†
        print("  æµ‹è¯•æµå¼æ–‡ä»¶å¤„ç†...")
        test_files = []
        for folder in folders[:3]:  # åªæµ‹è¯•å‰3ä¸ªæ–‡ä»¶å¤¹
            for file_path in folder.iterdir():
                if file_path.is_file():
                    test_files.append(file_path)
        
        for file_path in test_files[:5]:  # åªæµ‹è¯•å‰5ä¸ªæ–‡ä»¶
            start_time = time.time()
            file_size = stream_processor.get_file_size_stream(file_path)
            operation_time = time.time() - start_time
            
            results['stream_operations'].append({
                'file': file_path.name,
                'size': file_size,
                'time': operation_time
            })
        
        results['avg_stream_time'] = sum(op['time'] for op in results['stream_operations']) / len(results['stream_operations']) if results['stream_operations'] else 0
        
        return results
    
    def test_integrated_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•é›†æˆæ€§èƒ½"""
        print("\nğŸš€ æµ‹è¯•é›†æˆæ€§èƒ½...")
        
        # åˆ›å»ºé›†æˆçš„ TorrentCreator
        creator = TorrentCreator(
            tracker_links=["udp://test.tracker.com:8080/announce"],
            output_dir=tempfile.mkdtemp(),
            max_workers=2
        )
        
        results = {
            'system_info': creator.get_system_info(),
            'performance_stats': {},
            'cache_stats': {}
        }
        
        print("  ç³»ç»Ÿä¿¡æ¯:")
        sys_info = results['system_info']
        print(f"    ç‰ˆæœ¬: {sys_info['version']}")
        print(f"    ä¼˜åŒ–çº§åˆ«: {sys_info['optimization_level']}")
        print(f"    åŠŸèƒ½æ•°é‡: {len(sys_info['features'])}")
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        perf_stats = creator.get_performance_stats()
        results['performance_stats'] = perf_stats
        
        print("  æ€§èƒ½ç»Ÿè®¡:")
        summary = perf_stats.get('summary', {})
        print(f"    æ€§èƒ½ç­‰çº§: {summary.get('performance_grade', 'Unknown')}")
        print(f"    å†…å­˜ä½¿ç”¨: {summary.get('memory_usage_mb', 0):.1f}MB")
        
        # æµ‹è¯•ç¼“å­˜æ¸…ç†
        print("  æµ‹è¯•ç¼“å­˜æ¸…ç†...")
        cleared = creator.clear_caches()
        results['cache_stats'] = cleared
        
        print(f"    æ¸…ç†é¡¹ç›®: {sum(cleared.values())}")
        
        return results
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰ç¬¬äºŒé˜¶æ®µæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ Torrent Maker v1.5.0 ç¬¬äºŒé˜¶æ®µä¼˜åŒ–æµ‹è¯•...")
        print("=" * 60)
        
        try:
            # è®¾ç½®æµ‹è¯•æ•°æ®
            self.setup_test_data()
            
            # è¿è¡Œå„é¡¹æµ‹è¯•
            self.results['search_optimization'] = self.test_smart_search_optimization()
            self.results['memory_management'] = self.test_memory_management()
            self.results['async_io'] = self.test_async_io_processing()
            self.results['integrated_performance'] = self.test_integrated_performance()
            
            return self.results
            
        finally:
            # æ¸…ç†æµ‹è¯•æ•°æ®
            self.cleanup_test_data()
    
    def print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ“Š Torrent Maker v1.5.0 ç¬¬äºŒé˜¶æ®µä¼˜åŒ–æµ‹è¯•ç»“æœ")
        print("=" * 60)
        
        # æœç´¢ä¼˜åŒ–ç»“æœ
        if 'search_optimization' in self.results:
            search_results = self.results['search_optimization']
            print(f"\nğŸ” æ™ºèƒ½æœç´¢ä¼˜åŒ–:")
            print(f"  å¹³å‡æœç´¢æ—¶é—´: {search_results['avg_search_time']:.4f}s")
            print(f"  æœ€å¿«æœç´¢: {search_results['fastest_search']:.4f}s")
            print(f"  æœ€æ…¢æœç´¢: {search_results['slowest_search']:.4f}s")
            print(f"  ä¼˜åŒ–ç­‰çº§: {search_results['optimization_level']}")
        
        # å†…å­˜ç®¡ç†ç»“æœ
        if 'memory_management' in self.results:
            memory_results = self.results['memory_management']
            initial_mem = memory_results['initial_memory']
            final_mem = memory_results['final_memory']
            print(f"\nğŸ’¾ å†…å­˜ç®¡ç†:")
            print(f"  åˆå§‹å†…å­˜: {initial_mem.get('rss_mb', 0):.1f}MB")
            print(f"  æœ€ç»ˆå†…å­˜: {final_mem.get('rss_mb', 0):.1f}MB")
            print(f"  æ¸…ç†é¡¹ç›®: {sum(memory_results['cleanup_results'])}")
        
        # å¼‚æ­¥ I/O ç»“æœ
        if 'async_io' in self.results:
            async_results = self.results['async_io']
            print(f"\nâš¡ å¼‚æ­¥ I/O å¤„ç†:")
            print(f"  å¼‚æ­¥æ‰«ææ—¶é—´: {async_results['async_scan_time']:.4f}s")
            print(f"  æ‰¾åˆ°æ–‡ä»¶å¤¹: {async_results['folders_found']} ä¸ª")
            print(f"  å¹³å‡æµå¤„ç†æ—¶é—´: {async_results['avg_stream_time']:.6f}s")
        
        # é›†æˆæ€§èƒ½ç»“æœ
        if 'integrated_performance' in self.results:
            integrated_results = self.results['integrated_performance']
            sys_info = integrated_results['system_info']
            print(f"\nğŸš€ é›†æˆæ€§èƒ½:")
            print(f"  ç‰ˆæœ¬: {sys_info['version']}")
            print(f"  ä¼˜åŒ–çº§åˆ«: {sys_info['optimization_level']}")
            print(f"  æ€§èƒ½ç­‰çº§: {sys_info['performance_grade']}")
            print(f"  åŠŸèƒ½ç‰¹æ€§: {len(sys_info['features'])} é¡¹")
        
        print("\n" + "=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Torrent Maker v1.5.0 ç¬¬äºŒé˜¶æ®µä¼˜åŒ–æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    test_suite = Stage2OptimizationTest()
    
    try:
        results = test_suite.run_all_tests()
        test_suite.print_results()
        
        print(f"\nâœ… ç¬¬äºŒé˜¶æ®µä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
        print("ğŸš€ v1.5.0 ç¬¬äºŒé˜¶æ®µä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼š")
        print("   ğŸ” æ™ºèƒ½æœç´¢ç´¢å¼•å’Œé¢„ç­›é€‰")
        print("   ğŸ’¾ å†…å­˜ç®¡ç†å’Œè‡ªåŠ¨æ¸…ç†")
        print("   âš¡ å¼‚æ­¥ I/O å¤„ç†ä¼˜åŒ–")
        print("   ğŸ“Š å¢å¼ºæ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        test_suite.cleanup_test_data()


if __name__ == "__main__":
    main()
