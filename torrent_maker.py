#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Torrent Maker - å•æ–‡ä»¶ç‰ˆæœ¬ v2.1.0
åŸºäº mktorrent çš„é«˜æ€§èƒ½åŠè‡ªåŠ¨åŒ–ç§å­åˆ¶ä½œå·¥å…·

ğŸŒ v2.1.0 Webç•Œé¢å¢å¼ºç‰ˆæœ¬:
- ğŸŒ å…¨æ–°Webç•Œé¢ï¼šåŸºäºFlask + WebSocketçš„ç°ä»£åŒ–ç•Œé¢
- ğŸ–¥ï¸ å¤šæœåŠ¡å™¨SSHè¿æ¥ï¼šæ”¯æŒè¿œç¨‹æœåŠ¡å™¨åˆ¶ç§ç®¡ç†
- ğŸ“Š å®æ—¶è¿›åº¦ç›‘æ§ï¼šWebSocketæ¨é€åˆ¶ç§è¿›åº¦å’Œç³»ç»ŸçŠ¶æ€
- ğŸ¯ ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†ï¼šå¯è§†åŒ–ä»»åŠ¡é˜Ÿåˆ—å’Œæ‰¹é‡æ“ä½œ
- ğŸ“± ç§»åŠ¨ç«¯é€‚é…ï¼šå“åº”å¼è®¾è®¡æ”¯æŒæ‰‹æœºå¹³æ¿è®¿é—®
- ğŸ” å®‰å…¨è¿æ¥ï¼šSSHå¯†é’¥å’Œå¯†ç è®¤è¯æ”¯æŒ
- ğŸš€ å¯åŠ¨è„šæœ¬ï¼šä¸€é”®å¯åŠ¨Webç•Œé¢å’Œä¾èµ–æ£€æŸ¥
- ğŸ“‹ é…ç½®ç®¡ç†ï¼šYAMLæ ¼å¼çš„æœåŠ¡å™¨é…ç½®æ–‡ä»¶

ğŸ¯ v2.0.2 æ‰¹é‡åˆ¶ç§ä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤TorrentProgressMonitorç¼ºå¤±start_monitoringæ–¹æ³•
- ğŸ”§ ä¿®å¤TorrentProgressMonitorç¼ºå¤±stop_monitoringæ–¹æ³•
- ğŸ“Š å¢å¼ºè¿›åº¦ç›‘æ§åŠŸèƒ½å’ŒçŠ¶æ€ç®¡ç†
- âœ… è§£å†³æ‰¹é‡åˆ¶ç§å¤±è´¥é—®é¢˜
- ğŸ“¦ è‡ªåŠ¨ç”Ÿæˆå‘å¸ƒåŒ…å’Œå®‰è£…è¯´æ˜
- ğŸ› ï¸ å¢åŠ æ‰‹åŠ¨å‘å¸ƒå¤‡ç”¨æµç¨‹
- âœ¨ ä¼˜åŒ–å‘å¸ƒæµç¨‹çš„ç”¨æˆ·ä½“éªŒ

ğŸ¯ v2.0.0 ä¸€é”®å®‰è£…è„šæœ¬é‡æ„ç‰ˆæœ¬:
- ğŸ”§ å®Œå…¨é‡æ„å®‰è£…è„šæœ¬ï¼Œä»1186è¡Œç®€åŒ–ä¸º150è¡Œæ ‡å‡†ç‰ˆ
- âœ¨ ç»Ÿä¸€å®‰è£…æµç¨‹ï¼šæ£€æŸ¥mktorrentã€å®‰è£…ä¾èµ–ã€å®‰è£…æœ€æ–°ç¨‹åº
- ğŸš€ æ”¯æŒmacOSã€Ubuntuã€Debianã€CentOSã€RHELå¤šå¹³å°
- ğŸ“‹ å¢å¼ºé”™è¯¯å¤„ç†å’Œç”¨æˆ·å‹å¥½çš„å½©è‰²è¾“å‡º
- ğŸ›¡ï¸ æå‡å®‰è£…è„šæœ¬çš„ç¨³å®šæ€§å’Œç»´æŠ¤æ€§
- âš¡ ä¼˜åŒ–ç‰ˆæœ¬æ£€æµ‹é€»è¾‘ï¼Œæ”¯æŒæœ¬åœ°å’Œè¿œç¨‹ç‰ˆæœ¬è·å–

ğŸ¯ v1.9.19 åˆ¶ç§å‘½åä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤é˜Ÿåˆ—åˆ¶ç§æ—¶æ–‡ä»¶å‘½åé”™è¯¯é—®é¢˜ï¼ˆä»-root_pack_æ—¶é—´æˆ³ä¿®å¤ä¸ºæ­£ç¡®çš„æ–‡ä»¶å¤¹å_æ—¶é—´æˆ³ï¼‰
- âœ… ä¿®æ­£TorrentQueueManagerä¸­create_torrentå‚æ•°ä¼ é€’é”™è¯¯
- ğŸ”„ æ­£ç¡®è®¾ç½®TorrentCreatorè¾“å‡ºç›®å½•ï¼Œç¡®ä¿æ–‡ä»¶ä¿å­˜åˆ°æŒ‡å®šä½ç½®
- ğŸ“‹ ä¼˜åŒ–é˜Ÿåˆ—ä»»åŠ¡æ‰§è¡Œé€»è¾‘ï¼Œæå‡åˆ¶ç§æ–‡ä»¶å‘½åå‡†ç¡®æ€§
- ğŸš€ ç¡®ä¿æ‰¹é‡åˆ¶ç§å’Œé˜Ÿåˆ—ç®¡ç†åŠŸèƒ½çš„æ–‡ä»¶å‘½åæ­£ç¡®æ€§

ğŸ¯ v1.9.16 é˜Ÿåˆ—ç®¡ç†ç±»å‹é”™è¯¯ä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤é˜Ÿåˆ—ç®¡ç†ä¸­å­—ç¬¦ä¸²ä¸æ•´æ•°æ¯”è¾ƒçš„ç±»å‹é”™è¯¯
- ğŸ›¡ï¸ å¢å¼ºä»»åŠ¡æ•°æ®åºåˆ—åŒ–/ååºåˆ—åŒ–çš„å®‰å…¨æ€§
- ğŸ“‹ æ”¹è¿›æšä¸¾ç±»å‹è½¬æ¢çš„å®¹é”™å¤„ç†
- ğŸš€ æå‡é˜Ÿåˆ—ç®¡ç†ç³»ç»Ÿçš„ç¨³å®šæ€§

ğŸ¯ v1.9.15 åˆ¶ç§å¤±è´¥é—®é¢˜ä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤tracker URLæ ¼å¼é”™è¯¯ï¼ˆç§»é™¤åå¼•å·ç­‰éæ³•å­—ç¬¦ï¼‰
- âœ… æ”¹è¿›æ—¶é—´æˆ³ç²¾åº¦åˆ°å¾®ç§’çº§ï¼Œè§£å†³æ–‡ä»¶åå†²çªé—®é¢˜
- ğŸ”„ æ·»åŠ æ–‡ä»¶å†²çªæ£€æµ‹å’Œé‡è¯•æœºåˆ¶
- ğŸ“‹ å¢å¼ºURLæ ¼å¼éªŒè¯ï¼Œæå‡åˆ¶ç§æˆåŠŸç‡
- ğŸš€ æå‡åˆ¶ç§ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§

ğŸ¯ v1.9.14 é˜Ÿåˆ—ç®¡ç†ä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤é˜Ÿåˆ—è¯¦æƒ…æ˜¾ç¤ºä¸ºç©ºçš„é—®é¢˜
- âœ… ä¿®æ­£é˜Ÿåˆ—æ–‡ä»¶ä¿å­˜è·¯å¾„ä¸ä¸€è‡´å¯¼è‡´çš„æ•°æ®ä¸¢å¤±
- ğŸ”„ ç¡®ä¿é˜Ÿåˆ—çŠ¶æ€å’Œä»»åŠ¡æ•°æ®åŒæ­¥æ˜¾ç¤º
- ğŸ“‹ ä¿®å¤é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½çš„æ•°æ®æŒä¹…åŒ–é—®é¢˜
- ğŸš€ æå‡é˜Ÿåˆ—ç®¡ç†ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§

ğŸ¯ v1.9.13 æœç´¢å†å²å¿«æ·é”®å¢å¼ºç‰ˆæœ¬:
- âœ¨ æ–°å¢æœç´¢å†å²å¿«æ·é”®é€‰æ‹©åŠŸèƒ½ï¼ˆè¾“å…¥æ•°å­—1-5ç›´æ¥é€‰æ‹©å†å²æœç´¢ï¼‰
- ğŸ” ä¼˜åŒ–æœç´¢ç•Œé¢æç¤ºä¿¡æ¯ï¼Œæ”¯æŒå¿«æ·é”®å’Œæ‰‹åŠ¨è¾“å…¥åŒæ¨¡å¼
- ğŸ¯ å¢å¼ºç”¨æˆ·ä½“éªŒï¼Œå¿«é€Ÿé‡å¤æœç´¢æ›´åŠ ä¾¿æ·
- ğŸ“‹ å…¼å®¹ç°æœ‰æœç´¢å†å²æ•°æ®ç»“æ„ï¼Œæ— ç¼å‡çº§
- ğŸš€ æå‡æœç´¢æ•ˆç‡å’Œæ“ä½œä¾¿æ·æ€§

ğŸ¯ v1.9.10 æœç´¢å†å²å…¼å®¹æ€§ä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤æœç´¢å†å²æ˜¾ç¤ºä¸­çš„ 'str' object has no attribute 'query' é”™è¯¯
- âœ… å¢å¼ºæœç´¢å†å²æ•°æ®ç»“æ„å…¼å®¹æ€§å¤„ç†
- ğŸ”„ ä¿®å¤ä¸»èœå•å’Œæœç´¢å†å²ç®¡ç†ä¸­çš„æ˜¾ç¤ºé—®é¢˜
- ğŸ“‹ ç¡®ä¿ä¸åŒ SearchHistory å®ç°çš„å…¼å®¹æ€§
- ğŸš€ æå‡ç¨‹åºç¨³å®šæ€§å’Œç”¨æˆ·ä½“éªŒ

ğŸ¯ v1.9.9 PathCompleterä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤ PathCompleter ç¼ºå°‘ get_input æ–¹æ³•çš„é—®é¢˜
- âœ… æ·»åŠ æ”¯æŒè·¯å¾„è¡¥å…¨çš„ç”¨æˆ·è¾“å…¥åŠŸèƒ½
- ğŸ”„ å®Œå–„è·¯å¾„å†å²è®°å½•å’Œè‡ªåŠ¨è¡¥å…¨æœºåˆ¶
- ğŸ“‹ ç¡®ä¿æ™ºèƒ½æœç´¢å’Œæ‰¹é‡åˆ¶ç§åŠŸèƒ½æ­£å¸¸
- ğŸš€ æå‡ç”¨æˆ·äº¤äº’ä½“éªŒå’Œæ“ä½œä¾¿æ·æ€§

ğŸ¯ v1.9.8 å¢å¼ºåŠŸèƒ½æµ‹è¯•ä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤å¢å¼ºåŠŸèƒ½æ¨¡å—æµ‹è¯•é—®é¢˜
- âœ… å®Œå–„ PathCompleterã€TorrentProgressMonitor åŠŸèƒ½
- ğŸ”„ ä¿®å¤ SearchHistory å’Œ SmartSearchSuggester å…¼å®¹æ€§
- ğŸ“‹ è§£å†³æ–‡ä»¶æƒé™å’Œæ–¹æ³•ç¼ºå¤±é—®é¢˜
- ğŸš€ ç¡®ä¿æ‰€æœ‰å¢å¼ºåŠŸèƒ½æ­£å¸¸å·¥ä½œ

ğŸ¯ v1.9.4 é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½ä¿®å¤ç‰ˆæœ¬:
- ğŸ”§ ä¿®å¤é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½ä¸å¯ç”¨é—®é¢˜
- âœ… ä¿®å¤ TorrentCreator ä¸ ConfigManager é›†æˆ
- ğŸ”„ æ¢å¤é˜Ÿåˆ—ç®¡ç†ç³»ç»Ÿå®Œæ•´åŠŸèƒ½
- ğŸ“‹ ä¿®å¤ä»»åŠ¡çŠ¶æ€è·Ÿè¸ªå’Œè¿›åº¦ç›‘æ§
- ğŸš€ ç¡®ä¿æ‰¹é‡åˆ¶ç§å’Œé˜Ÿåˆ—æ§åˆ¶æ­£å¸¸å·¥ä½œ

ğŸ¯ v1.9.2 é˜Ÿåˆ—ç®¡ç†ä¸é¢„è®¾ä¼˜åŒ–ç‰ˆæœ¬:
- ğŸ”„ é˜Ÿåˆ—ç®¡ç†ç³»ç»Ÿï¼ˆä»»åŠ¡é˜Ÿåˆ—ã€è¿›åº¦ç›‘æ§ã€æ‰¹é‡æ§åˆ¶ï¼‰
- âš¡ é¢„è®¾æ¨¡å¼ç®¡ç†ï¼ˆå†…ç½®é¢„è®¾ã€è‡ªå®šä¹‰é¢„è®¾ã€è‡ªåŠ¨æ£€æµ‹ï¼‰
- ğŸ“‹ ä»»åŠ¡çŠ¶æ€è·Ÿè¸ªï¼ˆç­‰å¾…ã€è¿è¡Œã€å®Œæˆã€å¤±è´¥çŠ¶æ€ç®¡ç†ï¼‰
- ğŸ›ï¸ é«˜çº§é…ç½®ç•Œé¢ï¼ˆé¢„è®¾é€‰æ‹©ã€é˜Ÿåˆ—æ§åˆ¶ã€ç»Ÿè®¡æŠ¥å‘Šï¼‰
- ğŸš€ æ‰¹é‡åˆ¶ç§ä¼˜åŒ–ï¼ˆå¹¶å‘å¤„ç†ã€æ™ºèƒ½è°ƒåº¦ã€æ€§èƒ½ç›‘æ§ï¼‰

ğŸ¯ v1.9.1 ç”¨æˆ·ä½“éªŒä¼˜åŒ–ç‰ˆæœ¬:
- ğŸ” æ™ºèƒ½è·¯å¾„è¡¥å…¨åŠŸèƒ½ï¼ˆTabé”®è¡¥å…¨ã€å†å²è®°å½•ã€æ™ºèƒ½å»ºè®®ï¼‰
- ğŸ“Š å®æ—¶åˆ¶ç§è¿›åº¦ç›‘æ§ï¼ˆè¿›åº¦æ¡ã€å¯è§†åŒ–ã€æ€§èƒ½ç»Ÿè®¡ï¼‰
- ğŸ“ æœç´¢å†å²ç®¡ç†ï¼ˆå†å²è®°å½•ã€çƒ­é—¨æœç´¢ã€æ™ºèƒ½å»ºè®®ï¼‰
- âš¡ åˆ¶ç§è¿‡ç¨‹æ§åˆ¶ï¼ˆè¿›åº¦å–æ¶ˆã€æš‚åœæ¢å¤ã€å¤šä»»åŠ¡ç®¡ç†ï¼‰
- ğŸ¨ ç”¨æˆ·ç•Œé¢å…¨é¢ä¼˜åŒ–ï¼ˆäº¤äº’ä½“éªŒã€è§†è§‰æç¤ºã€æ“ä½œä¾¿æ·æ€§ï¼‰

ğŸ¯ v1.9.0 æ€§èƒ½ç›‘æ§å¢å¼ºç‰ˆæœ¬:
- â° æ–°å¢åˆ¶ç§æ—¶é—´æ˜¾ç¤ºåŠŸèƒ½ï¼ˆå¼€å§‹æ—¶é—´ã€å®Œæˆæ—¶é—´ã€æ€»è€—æ—¶ï¼‰
- ğŸ§µ æ™ºèƒ½å¤šçº¿ç¨‹æ£€æµ‹ä¸ä¼˜åŒ–ï¼ˆè‡ªåŠ¨æ£€æµ‹æœ€ä¼˜çº¿ç¨‹æ•°ï¼‰
- ğŸ“Š è¯¦ç»†æ€§èƒ½ä¿¡æ¯å±•ç¤ºï¼ˆåˆ¶ç§é€Ÿåº¦ã€æ•ˆç‡åˆ†æã€æ€§èƒ½å»ºè®®ï¼‰
- ğŸ¨ ç”¨æˆ·ç•Œé¢ä¼˜åŒ–ï¼ˆæ¸…æ™°çš„ä¿¡æ¯å¸ƒå±€å’Œè§†è§‰æç¤ºï¼‰
- ğŸ’¡ æ™ºèƒ½æ€§èƒ½å»ºè®®ç³»ç»Ÿï¼ˆæ ¹æ®ç³»ç»ŸçŠ¶æ€æä¾›ä¼˜åŒ–å»ºè®®ï¼‰

ğŸ¯ v1.6.0 å½»åº•é‡æ„ç‰ˆæœ¬:
- ğŸ—‚ï¸ é¡¹ç›®ç»“æ„å½»åº•ç®€åŒ–ï¼Œç§»é™¤æ‰€æœ‰æ¨¡å—åŒ–ç»„ä»¶
- ğŸ“¦ å•æ–‡ä»¶æ¶æ„ï¼Œä¸‹è½½å³ç”¨ï¼Œæ— éœ€å¤æ‚é…ç½®
- ğŸ§¹ åˆ é™¤ 80% å†—ä½™æ–‡ä»¶ï¼Œé¡¹ç›®ä½“ç§¯å‡å°‘ 80%
- ğŸ“– æ–‡æ¡£å®Œå…¨é‡å†™ï¼Œä¸“æ³¨å•æ–‡ä»¶ç‰ˆæœ¬ä½¿ç”¨
- âš¡ å®‰è£…æµç¨‹ç®€åŒ–ï¼Œä¸€é”®å®Œæˆæ‰€æœ‰é…ç½®
- ğŸ¨ ç”¨æˆ·ä½“éªŒä¼˜åŒ–ï¼Œæ“ä½œæ›´åŠ ç›´è§‚ç®€æ´

ğŸš€ ç»§æ‰¿ v1.5.1 æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–:
- âš¡ ç§å­åˆ›å»ºé€Ÿåº¦æå‡ 30-50%
- ğŸ§  æ™ºèƒ½ Piece Size è®¡ç®—ï¼Œå‡å°‘è®¡ç®—æ—¶é—´ 80%
- ğŸ’¾ ç›®å½•å¤§å°ç¼“å­˜ä¼˜åŒ–ï¼Œæ”¯æŒ LRU æ·˜æ±°ç­–ç•¥
- ğŸ”§ mktorrent å‚æ•°ä¼˜åŒ–ï¼Œå¯ç”¨å¤šçº¿ç¨‹å¤„ç†
- ğŸ”„ æ‰¹é‡å¤„ç†å¹¶å‘ä¼˜åŒ–ï¼Œæ”¯æŒè¿›ç¨‹æ± å¤„ç†
- ğŸ“Š å¢å¼ºæ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åˆ†æ
- ğŸ¯ æ™ºèƒ½æŸ¥æ‰¾è¡¨ï¼ŒO(1) æ—¶é—´å¤æ‚åº¦ä¼˜åŒ–

ğŸ›¡ï¸ ç»§æ‰¿ v1.5.1 æ‰€æœ‰ç¨³å®šæ€§ä¿®å¤:
- ğŸ› ä¿®å¤ macOS å†…å­˜ä½¿ç”¨è®¡ç®—é”™è¯¯
- âš¡ ä¼˜åŒ–æ–‡ä»¶å¤¹æ‰«ææ€§èƒ½ï¼Œæ·»åŠ è¶…æ—¶å’Œæ•°é‡é™åˆ¶
- ğŸ” ä¿®å¤æœç´¢åŠŸèƒ½ï¼Œæ¢å¤æ–‡ä»¶å¤¹åŒ¹é…èƒ½åŠ›
- ğŸ›¡ï¸ å¢å¼ºæ‰«æç¨³å®šæ€§ï¼Œé˜²æ­¢å¤§æ–‡ä»¶å¤¹å¯¼è‡´çš„å¡æ­»

é¡¹ç›®ç‰¹ç‚¹:
- ğŸ“¦ çœŸæ­£çš„å•æ–‡ä»¶åº”ç”¨ï¼ŒåŒ…å«æ‰€æœ‰åŠŸèƒ½
- ğŸš€ æç®€å®‰è£…ï¼Œä¸€ä¸ªå‘½ä»¤å®Œæˆ
- ğŸ“– æ¸…æ™°æ–‡æ¡£ï¼Œä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½
- ğŸ”§ æ˜“äºç»´æŠ¤ï¼Œå•ä¸€ä»£ç è·¯å¾„

ä½¿ç”¨æ–¹æ³•ï¼š
    python torrent_maker.py

ä½œè€…ï¼šTorrent Maker Team
è®¸å¯è¯ï¼šMIT
ç‰ˆæœ¬ï¼š1.9.0
"""

import os
import sys
import json
import subprocess
import shutil
import time
import logging
import hashlib
import threading
import re
from datetime import datetime

from typing import List, Dict, Any, Tuple, Optional, Union, Set
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor

# æ‰€æœ‰åŠŸèƒ½å·²å†…ç½®åˆ°å•æ–‡ä»¶ä¸­
ENHANCED_FEATURES_AVAILABLE = True

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# ================== ç‰ˆæœ¬ä¿¡æ¯ ==================
VERSION = "v2.2.0"
VERSION_NAME = "è¿œç¨‹æ–‡ä»¶æµè§ˆå™¨ç‰ˆ"
FULL_VERSION_INFO = f"Torrent Maker {VERSION} - {VERSION_NAME}"
# è§¦å‘GitHub Actionsè‡ªåŠ¨å‘å¸ƒ - 2025-06-27


# ================== é˜Ÿåˆ—ç®¡ç†æ¨¡å— ==================
import uuid
from enum import Enum
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue, PriorityQueue

class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""
    WAITING = "waiting"      # ç­‰å¾…æ‰§è¡Œ
    RUNNING = "running"      # æ­£åœ¨æ‰§è¡Œ
    COMPLETED = "completed"  # å·²å®Œæˆ
    FAILED = "failed"        # æ‰§è¡Œå¤±è´¥
    PAUSED = "paused"        # å·²æš‚åœ
    CANCELLED = "cancelled"  # å·²å–æ¶ˆ


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾"""
    LOW = 3
    NORMAL = 2
    HIGH = 1
    URGENT = 0


@dataclass
class QueueTask:
    """é˜Ÿåˆ—ä»»åŠ¡æ•°æ®ç±»"""
    id: str
    name: str
    path: str
    status: TaskStatus = TaskStatus.WAITING
    priority: TaskPriority = TaskPriority.NORMAL
    progress: float = 0.0
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    error_message: str = ""
    preset: str = "standard"
    output_path: str = ""
    file_size: int = 0
    created_time: float = None
    estimated_duration: float = 0.0
    actual_duration: float = 0.0
    retry_count: int = 0
    max_retries: int = 3
    
    def __post_init__(self):
        if self.created_time is None:
            self.created_time = time.time()
    
    def __lt__(self, other):
        """ç”¨äºä¼˜å…ˆçº§é˜Ÿåˆ—æ’åº"""
        if self.priority.value != other.priority.value:
            return self.priority.value < other.priority.value
        return self.created_time < other.created_time
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        data = asdict(self)
        data['status'] = self.status.value
        data['priority'] = self.priority.value
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'QueueTask':
        """ä»å­—å…¸åˆ›å»ºä»»åŠ¡å¯¹è±¡"""
        # å®‰å…¨è½¬æ¢çŠ¶æ€æšä¸¾
        try:
            if isinstance(data['status'], str):
                data['status'] = TaskStatus[data['status']]
            else:
                data['status'] = TaskStatus(data['status'])
        except (KeyError, ValueError):
            data['status'] = TaskStatus.WAITING
        
        # å®‰å…¨è½¬æ¢ä¼˜å…ˆçº§æšä¸¾
        try:
            if isinstance(data['priority'], str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æŒ‰åç§°æŸ¥æ‰¾
                data['priority'] = TaskPriority[data['priority']]
            else:
                # å¦‚æœæ˜¯æ•°å­—ï¼ŒæŒ‰å€¼æŸ¥æ‰¾
                data['priority'] = TaskPriority(int(data['priority']))
        except (KeyError, ValueError, TypeError):
            data['priority'] = TaskPriority.NORMAL
        
        return cls(**data)


class QueueStatusDisplay:
    """é˜Ÿåˆ—çŠ¶æ€æ˜¾ç¤ºç®¡ç†ç±»"""
    
    def __init__(self):
        self.last_display_time = 0
        self.last_status_hash = None
        self.display_interval = 1.0  # æœ€å°æ˜¾ç¤ºé—´éš”ï¼ˆç§’ï¼‰
    
    def display_status(self, queue_manager, mode: str = "standard", force_update: bool = False):
        """ç»Ÿä¸€çš„é˜Ÿåˆ—çŠ¶æ€æ˜¾ç¤ºæ¥å£
        
        Args:
            queue_manager: é˜Ÿåˆ—ç®¡ç†å™¨å®ä¾‹
            mode: æ˜¾ç¤ºæ¨¡å¼ ('compact', 'standard', 'detailed')
            force_update: å¼ºåˆ¶æ›´æ–°æ˜¾ç¤º
        """
        if not queue_manager:
            print("âŒ é˜Ÿåˆ—ç®¡ç†å™¨ä¸å¯ç”¨")
            return
        
        # è·å–çŠ¶æ€ä¿¡æ¯
        status = queue_manager.get_queue_status()
        current_time = time.time()
        
        # ç”ŸæˆçŠ¶æ€å“ˆå¸Œï¼Œç”¨äºæ£€æµ‹å˜åŒ–
        status_hash = self._generate_status_hash(status)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ˜¾ç¤º
        if not force_update:
            if (current_time - self.last_display_time < self.display_interval and 
                status_hash == self.last_status_hash):
                return
        
        # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¿¡æ¯
        if mode == "compact":
            self._display_compact_status(status)
        elif mode == "detailed":
            self._display_detailed_status(status, queue_manager)
        else:  # standard
            self._display_standard_status(status)
        
        # æ›´æ–°æ˜¾ç¤ºè®°å½•
        self.last_display_time = current_time
        self.last_status_hash = status_hash
    
    def _generate_status_hash(self, status: dict) -> str:
        """ç”ŸæˆçŠ¶æ€å“ˆå¸Œå€¼ç”¨äºå˜åŒ–æ£€æµ‹"""
        import hashlib
        key_info = {
            'running': status.get('running', False),
            'paused': status.get('paused', False),
            'current_running': status.get('current_running', 0),
            'waiting_tasks': status.get('waiting_tasks', 0),
            'total_tasks': status.get('total_tasks', 0),
            'completed': status.get('statistics', {}).get('completed_tasks', 0),
            'failed': status.get('statistics', {}).get('failed_tasks', 0)
        }
        return hashlib.md5(str(key_info).encode()).hexdigest()
    
    def _display_compact_status(self, status: dict):
        """ç®€æ´æ¨¡å¼æ˜¾ç¤º"""
        running_status = "ğŸŸ¢ è¿è¡Œä¸­" if status['running'] and not status['paused'] else "ğŸŸ¡ æš‚åœ" if status['paused'] else "ğŸ”´ å·²åœæ­¢"
        print(f"ğŸ“Š é˜Ÿåˆ—: {running_status} | ä»»åŠ¡: {status['current_running']}/{status['max_concurrent']} | ç­‰å¾…: {status['waiting_tasks']}")
    
    def _display_standard_status(self, status: dict):
        """æ ‡å‡†æ¨¡å¼æ˜¾ç¤º"""
        print(f"\nğŸ“Š é˜Ÿåˆ—çŠ¶æ€: {'ğŸŸ¢ è¿è¡Œä¸­' if status['running'] and not status['paused'] else 'ğŸŸ¡ æš‚åœ' if status['paused'] else 'ğŸ”´ å·²åœæ­¢'}")
        print(f"âš¡ å¹¶å‘æ•°: {status['current_running']}/{status['max_concurrent']}")
        print(f"ğŸ“‹ ç­‰å¾…ä»»åŠ¡: {status['waiting_tasks']} | æ€»ä»»åŠ¡: {status['total_tasks']}")
        
        stats = status['statistics']
        print(f"âœ… å·²å®Œæˆ: {stats['completed_tasks']} | âŒ å¤±è´¥: {stats['failed_tasks']}")
        if stats['average_processing_time'] > 0:
            print(f"â±ï¸ å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.1f}ç§’")
    
    def _display_detailed_status(self, status: dict, queue_manager):
        """è¯¦ç»†æ¨¡å¼æ˜¾ç¤º"""
        print("\n" + "="*60)
        print("           ğŸ“Š é˜Ÿåˆ—è¯¦ç»†çŠ¶æ€")
        print("="*60)
        
        # åŸºæœ¬çŠ¶æ€
        self._display_standard_status(status)
        
        # æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        running_tasks = [task for task in queue_manager.get_all_tasks() 
                        if task.status == TaskStatus.RUNNING]
        if running_tasks:
            print(f"\nğŸ”„ æ­£åœ¨å¤„ç† ({len(running_tasks)} ä¸ªä»»åŠ¡):")
            for task in running_tasks:
                progress_str = f" ({task.progress*100:.1f}%)" if task.progress > 0 else ""
                print(f"  â€¢ {task.name}{progress_str}")
        
        # ç­‰å¾…é˜Ÿåˆ—
        waiting_tasks = [task for task in queue_manager.get_all_tasks() 
                        if task.status == TaskStatus.WAITING]
        if waiting_tasks:
            print(f"\nâ³ ç­‰å¾…é˜Ÿåˆ— ({len(waiting_tasks)} ä¸ªä»»åŠ¡):")
            for i, task in enumerate(waiting_tasks[:5], 1):
                print(f"  {i}. {task.name}")
            if len(waiting_tasks) > 5:
                print(f"     ... è¿˜æœ‰ {len(waiting_tasks) - 5} ä¸ªä»»åŠ¡")
        
        # æ€§èƒ½ç»Ÿè®¡
        stats = status['statistics']
        if stats['completed_tasks'] > 0 or stats['failed_tasks'] > 0:
            print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
            print(f"  æ€»å¤„ç†æ—¶é—´: {stats['total_processing_time']:.1f}ç§’")
            if stats['completed_tasks'] > 0:
                success_rate = (stats['completed_tasks'] / (stats['completed_tasks'] + stats['failed_tasks'])) * 100
                print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
        
        print("="*60)


class QueueManager:
    """é˜Ÿåˆ—ç®¡ç†å™¨"""
    
    def __init__(self, max_concurrent: int = 4, save_file: Optional[str] = None):
        self.max_concurrent = max_concurrent
        self.save_file = save_file or os.path.expanduser("~/.torrent_maker/queue.json")
        
        # ä»»åŠ¡å­˜å‚¨
        self.tasks: Dict[str, QueueTask] = {}
        self.priority_queue = PriorityQueue()
        self.running_tasks: Dict[str, QueueTask] = {}
        
        # çº¿ç¨‹ç®¡ç†
        self.executor = ThreadPoolExecutor(max_workers=max_concurrent)
        self.worker_threads: Dict[str, Any] = {}
        
        # åŒæ­¥é”
        self._lock = threading.RLock()
        self._running = False
        self._paused = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'total_processing_time': 0.0,
            'average_processing_time': 0.0
        }
        
        # å›è°ƒå‡½æ•°
        self.on_task_start: Optional[Callable[[QueueTask], None]] = None
        self.on_task_complete: Optional[Callable[[QueueTask], None]] = None
        self.on_task_failed: Optional[Callable[[QueueTask, str], None]] = None
        self.on_progress_update: Optional[Callable[[QueueTask], None]] = None
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()
        
        # åŠ è½½ä¿å­˜çš„é˜Ÿåˆ—
        self._load_queue()
    
    def set_callbacks(self, on_task_start=None, on_task_complete=None, 
                     on_task_failed=None, on_progress_update=None):
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        if on_task_start:
            self.on_task_start = on_task_start
        if on_task_complete:
            self.on_task_complete = on_task_complete
        if on_task_failed:
            self.on_task_failed = on_task_failed
        if on_progress_update:
            self.on_progress_update = on_progress_update
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('queue_manager')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def add_task(self, name: str, path: str, priority: TaskPriority = TaskPriority.NORMAL, 
                 preset: str = "standard", output_path: str = "") -> str:
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        with self._lock:
            task_id = str(uuid.uuid4())
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = 0
            try:
                if os.path.isfile(path):
                    file_size = os.path.getsize(path)
                elif os.path.isdir(path):
                    file_size = self._calculate_directory_size(path)
            except OSError:
                pass
            
            task = QueueTask(
                id=task_id,
                name=name,
                path=path,
                priority=priority,
                preset=preset,
                output_path=output_path,
                file_size=file_size
            )
            
            self.tasks[task_id] = task
            self.priority_queue.put(task)
            self.stats['total_tasks'] += 1
            
            self.logger.info(f"ä»»åŠ¡å·²æ·»åŠ : {name} (ID: {task_id})")
            self._save_queue()
            
            # å¦‚æœé˜Ÿåˆ—æ­£åœ¨è¿è¡Œï¼Œå°è¯•å¯åŠ¨æ–°ä»»åŠ¡
            if self._running:
                self._try_start_next_task()
            
            return task_id
    
    def _calculate_directory_size(self, path: str) -> int:
        """è®¡ç®—ç›®å½•å¤§å°"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    try:
                        total_size += os.path.getsize(file_path)
                    except OSError:
                        continue
        except OSError:
            pass
        return total_size
    
    def remove_task(self, task_id: str) -> bool:
        """ç§»é™¤ä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            # å¦‚æœä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œå…ˆå–æ¶ˆå®ƒ
            if task.status == TaskStatus.RUNNING:
                self.cancel_task(task_id)
            
            # ä»ä»»åŠ¡å­—å…¸ä¸­ç§»é™¤
            del self.tasks[task_id]
            
            # ä»è¿è¡Œä»»åŠ¡ä¸­ç§»é™¤
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
            
            # é‡å»ºä¼˜å…ˆçº§é˜Ÿåˆ—ï¼ˆç§»é™¤å·²åˆ é™¤çš„ä»»åŠ¡ï¼‰
            self._rebuild_priority_queue()
            
            self.logger.info(f"ä»»åŠ¡å·²ç§»é™¤: {task.name} (ID: {task_id})")
            self._save_queue()
            return True
    
    def _rebuild_priority_queue(self):
        """é‡å»ºä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œç§»é™¤å·²åˆ é™¤çš„ä»»åŠ¡"""
        # åˆ›å»ºæ–°çš„ä¼˜å…ˆçº§é˜Ÿåˆ—
        new_queue = queue.PriorityQueue()
        
        # å°†ç°æœ‰é˜Ÿåˆ—ä¸­çš„æœ‰æ•ˆä»»åŠ¡é‡æ–°åŠ å…¥
        while not self.priority_queue.empty():
            try:
                task = self.priority_queue.get_nowait()
                # åªæœ‰åœ¨taskså­—å…¸ä¸­å­˜åœ¨çš„ä»»åŠ¡æ‰é‡æ–°åŠ å…¥é˜Ÿåˆ—
                if task.id in self.tasks:
                    new_queue.put(task)
            except queue.Empty:
                break
        
        # æ›¿æ¢æ—§é˜Ÿåˆ—
        self.priority_queue = new_queue
    
    def pause_task(self, task_id: str) -> bool:
        """æš‚åœä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            if task.status == TaskStatus.RUNNING:
                # å–æ¶ˆæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
                self._cancel_running_task(task_id)
                task.status = TaskStatus.PAUSED
                self.logger.info(f"ä»»åŠ¡å·²æš‚åœ: {task.name} (ID: {task_id})")
            elif task.status == TaskStatus.WAITING:
                task.status = TaskStatus.PAUSED
                self.logger.info(f"ç­‰å¾…ä¸­çš„ä»»åŠ¡å·²æš‚åœ: {task.name} (ID: {task_id})")
            else:
                return False
            
            self._save_queue()
            return True
    
    def resume_task(self, task_id: str) -> bool:
        """æ¢å¤ä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            if task.status == TaskStatus.PAUSED:
                task.status = TaskStatus.WAITING
                self.priority_queue.put(task)
                self.logger.info(f"ä»»åŠ¡å·²æ¢å¤: {task.name} (ID: {task_id})")
                
                # å¦‚æœé˜Ÿåˆ—æ­£åœ¨è¿è¡Œï¼Œå°è¯•å¯åŠ¨ä»»åŠ¡
                if self._running:
                    self._try_start_next_task()
                
                self._save_queue()
                return True
            
            return False
    
    def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            if task.status == TaskStatus.RUNNING:
                self._cancel_running_task(task_id)
            
            task.status = TaskStatus.CANCELLED
            task.end_time = time.time()
            
            self.logger.info(f"ä»»åŠ¡å·²å–æ¶ˆ: {task.name} (ID: {task_id})")
            self._save_queue()
            return True
    
    def _cancel_running_task(self, task_id: str) -> None:
        """å–æ¶ˆæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"""
        if task_id in self.worker_threads:
            future = self.worker_threads[task_id]
            future.cancel()
            del self.worker_threads[task_id]
        
        if task_id in self.running_tasks:
            del self.running_tasks[task_id]
    
    def retry_task(self, task_id: str) -> bool:
        """é‡è¯•å¤±è´¥çš„ä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            if task.status != TaskStatus.FAILED:
                return False
            
            if task.retry_count >= task.max_retries:
                self.logger.warning(f"ä»»åŠ¡é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™: {task.name} (ID: {task_id})")
                return False
            
            # é‡ç½®ä»»åŠ¡çŠ¶æ€
            task.status = TaskStatus.WAITING
            task.progress = 0.0
            task.error_message = ""
            task.retry_count += 1
            task.start_time = None
            task.end_time = None
            
            self.priority_queue.put(task)
            
            self.logger.info(f"ä»»åŠ¡é‡è¯•: {task.name} (ID: {task_id}, ç¬¬{task.retry_count}æ¬¡é‡è¯•)")
            
            # å¦‚æœé˜Ÿåˆ—æ­£åœ¨è¿è¡Œï¼Œå°è¯•å¯åŠ¨ä»»åŠ¡
            if self._running:
                self._try_start_next_task()
            
            self._save_queue()
            return True
    
    def set_task_priority(self, task_id: str, priority: TaskPriority) -> bool:
        """è®¾ç½®ä»»åŠ¡ä¼˜å…ˆçº§"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            if task.status in [TaskStatus.RUNNING, TaskStatus.COMPLETED, TaskStatus.CANCELLED]:
                return False
            
            task.priority = priority
            
            # å¦‚æœä»»åŠ¡åœ¨ç­‰å¾…é˜Ÿåˆ—ä¸­ï¼Œéœ€è¦é‡æ–°æ’åº
            if task.status == TaskStatus.WAITING:
                # é‡å»ºä¼˜å…ˆçº§é˜Ÿåˆ—
                self._rebuild_priority_queue()
            
            self.logger.info(f"ä»»åŠ¡ä¼˜å…ˆçº§å·²æ›´æ–°: {task.name} (ID: {task_id}, ä¼˜å…ˆçº§: {priority.name})")
            self._save_queue()
            return True
    
    def _rebuild_priority_queue(self) -> None:
        """é‡å»ºä¼˜å…ˆçº§é˜Ÿåˆ—"""
        # æ¸…ç©ºå½“å‰é˜Ÿåˆ—
        while not self.priority_queue.empty():
            try:
                self.priority_queue.get_nowait()
            except:
                break
        
        # é‡æ–°æ·»åŠ ç­‰å¾…ä¸­çš„ä»»åŠ¡
        for task in self.tasks.values():
            if task.status == TaskStatus.WAITING:
                self.priority_queue.put(task)
    
    def start_queue(self) -> None:
        """å¯åŠ¨é˜Ÿåˆ—å¤„ç†"""
        with self._lock:
            if self._running:
                return
            
            self._running = True
            self._paused = False
            
            self.logger.info("é˜Ÿåˆ—å¤„ç†å·²å¯åŠ¨")
            
            # å¯åŠ¨å¯ç”¨çš„ä»»åŠ¡
            for _ in range(self.max_concurrent):
                self._try_start_next_task()
    
    def stop_queue(self) -> None:
        """åœæ­¢é˜Ÿåˆ—å¤„ç†"""
        with self._lock:
            if not self._running:
                return
            
            self._running = False
            
            # å–æ¶ˆæ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            for task_id in list(self.running_tasks.keys()):
                self._cancel_running_task(task_id)
                task = self.tasks[task_id]
                task.status = TaskStatus.WAITING
                self.priority_queue.put(task)
            
            self.logger.info("é˜Ÿåˆ—å¤„ç†å·²åœæ­¢")
            self._save_queue()
    
    def pause_queue(self) -> None:
        """æš‚åœé˜Ÿåˆ—å¤„ç†"""
        with self._lock:
            self._paused = True
            self.logger.info("é˜Ÿåˆ—å¤„ç†å·²æš‚åœ")
    
    def resume_queue(self) -> None:
        """æ¢å¤é˜Ÿåˆ—å¤„ç†"""
        with self._lock:
            if not self._running:
                self.start_queue()
                return
            
            self._paused = False
            self.logger.info("é˜Ÿåˆ—å¤„ç†å·²æ¢å¤")
            
            # å¯åŠ¨å¯ç”¨çš„ä»»åŠ¡
            for _ in range(self.max_concurrent - len(self.running_tasks)):
                self._try_start_next_task()
    
    def is_running(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        return self._running
    
    def is_paused(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æš‚åœ"""
        return self._paused
    
    def _try_start_next_task(self) -> bool:
        """å°è¯•å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡"""
        if not self._running or self._paused:
            return False
        
        if len(self.running_tasks) >= self.max_concurrent:
            return False
        
        if self.priority_queue.empty():
            return False
        
        try:
            task = self.priority_queue.get_nowait()
            
            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            if task.status != TaskStatus.WAITING:
                return self._try_start_next_task()
            
            # å¯åŠ¨ä»»åŠ¡
            self._start_task(task)
            return True
            
        except:
            return False
    
    def _start_task(self, task: QueueTask) -> None:
        """å¯åŠ¨å•ä¸ªä»»åŠ¡"""
        task.status = TaskStatus.RUNNING
        task.start_time = time.time()
        task.progress = 0.0
        
        self.running_tasks[task.id] = task
        
        # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        future = self.executor.submit(self._execute_task, task)
        self.worker_threads[task.id] = future
        
        # æ·»åŠ å®Œæˆå›è°ƒ
        future.add_done_callback(lambda f: self._task_completed(task.id, f))
        
        self.logger.info(f"ä»»åŠ¡å¼€å§‹æ‰§è¡Œ: {task.name} (ID: {task.id})")
        
        # è°ƒç”¨å›è°ƒå‡½æ•°
        if self.on_task_start:
            try:
                self.on_task_start(task)
            except Exception as e:
                self.logger.error(f"ä»»åŠ¡å¼€å§‹å›è°ƒå¤±è´¥: {e}")
    
    def _execute_task(self, task: QueueTask) -> bool:
        """æ‰§è¡Œä»»åŠ¡çš„å®é™…é€»è¾‘ï¼ˆéœ€è¦å­ç±»å®ç°ï¼‰"""
        # è¿™é‡Œæ˜¯ä¸€ä¸ªç¤ºä¾‹å®ç°ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®å…·ä½“éœ€æ±‚å®ç°
        try:
            # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
            for i in range(100):
                if task.status != TaskStatus.RUNNING:
                    return False
                
                time.sleep(0.1)  # æ¨¡æ‹Ÿå·¥ä½œ
                task.progress = (i + 1) / 100.0
                
                # è°ƒç”¨è¿›åº¦æ›´æ–°å›è°ƒ
                if self.on_progress_update:
                    try:
                        self.on_progress_update(task)
                    except Exception as e:
                        self.logger.error(f"è¿›åº¦æ›´æ–°å›è°ƒå¤±è´¥: {e}")
            
            return True
            
        except Exception as e:
            task.error_message = str(e)
            self.logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.name} - {e}")
            return False
    
    def _task_completed(self, task_id: str, future) -> None:
        """ä»»åŠ¡å®Œæˆå¤„ç†"""
        with self._lock:
            if task_id not in self.tasks:
                return
            
            task = self.tasks[task_id]
            task.end_time = time.time()
            task.actual_duration = task.end_time - (task.start_time or task.end_time)
            
            # ä»è¿è¡Œä»»åŠ¡ä¸­ç§»é™¤
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
            
            if task_id in self.worker_threads:
                del self.worker_threads[task_id]
            
            try:
                success = future.result()
                
                if success and task.status == TaskStatus.RUNNING:
                    task.status = TaskStatus.COMPLETED
                    task.progress = 1.0
                    self.stats['completed_tasks'] += 1
                    
                    self.logger.info(f"ä»»åŠ¡å®Œæˆ: {task.name} (ID: {task_id})")
                    
                    # è°ƒç”¨å®Œæˆå›è°ƒ
                    if self.on_task_complete:
                        try:
                            self.on_task_complete(task)
                        except Exception as e:
                            self.logger.error(f"ä»»åŠ¡å®Œæˆå›è°ƒå¤±è´¥: {e}")
                else:
                    task.status = TaskStatus.FAILED
                    self.stats['failed_tasks'] += 1
                    
                    self.logger.error(f"ä»»åŠ¡å¤±è´¥: {task.name} (ID: {task_id})")
                    
                    # è°ƒç”¨å¤±è´¥å›è°ƒ
                    if self.on_task_failed:
                        try:
                            self.on_task_failed(task, task.error_message)
                        except Exception as e:
                            self.logger.error(f"ä»»åŠ¡å¤±è´¥å›è°ƒå¤±è´¥: {e}")
                
            except Exception as e:
                task.status = TaskStatus.FAILED
                task.error_message = str(e)
                self.stats['failed_tasks'] += 1
                
                self.logger.error(f"ä»»åŠ¡å¼‚å¸¸: {task.name} (ID: {task_id}) - {e}")
                
                # è°ƒç”¨å¤±è´¥å›è°ƒ
                if self.on_task_failed:
                    try:
                        self.on_task_failed(task, str(e))
                    except Exception as e:
                        self.logger.error(f"ä»»åŠ¡å¤±è´¥å›è°ƒå¤±è´¥: {e}")
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['total_processing_time'] += task.actual_duration
            if self.stats['completed_tasks'] > 0:
                self.stats['average_processing_time'] = (
                    self.stats['total_processing_time'] / self.stats['completed_tasks']
                )
            
            self._save_queue()
            
            # å°è¯•å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡
            if self._running:
                self._try_start_next_task()
    
    def get_task(self, task_id: str) -> Optional[QueueTask]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        return self.tasks.get(task_id)
    
    def get_all_tasks(self) -> List[QueueTask]:
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        return list(self.tasks.values())
    
    def get_tasks_by_status(self, status: TaskStatus) -> List[QueueTask]:
        """æ ¹æ®çŠ¶æ€è·å–ä»»åŠ¡"""
        return [task for task in self.tasks.values() if task.status == status]
    
    def get_queue_status(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        with self._lock:
            status_counts = {}
            for status in TaskStatus:
                status_counts[status.value] = len(self.get_tasks_by_status(status))
            
            return {
                'running': self._running,
                'paused': self._paused,
                'max_concurrent': self.max_concurrent,
                'current_running': len(self.running_tasks),
                'waiting_tasks': status_counts[TaskStatus.WAITING.value],
                'total_tasks': len(self.tasks),
                'status_counts': status_counts,
                'statistics': self.stats.copy()
            }
    
    def clear_completed_tasks(self) -> int:
        """æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡"""
        with self._lock:
            completed_tasks = self.get_tasks_by_status(TaskStatus.COMPLETED)
            count = len(completed_tasks)
            
            for task in completed_tasks:
                del self.tasks[task.id]
            
            self.logger.info(f"å·²æ¸…ç† {count} ä¸ªå·²å®Œæˆçš„ä»»åŠ¡")
            self._save_queue()
            return count
    
    def clear_failed_tasks(self) -> int:
        """æ¸…ç†å¤±è´¥çš„ä»»åŠ¡"""
        with self._lock:
            failed_tasks = self.get_tasks_by_status(TaskStatus.FAILED)
            count = len(failed_tasks)
            
            for task in failed_tasks:
                del self.tasks[task.id]
            
            self.logger.info(f"å·²æ¸…ç† {count} ä¸ªå¤±è´¥çš„ä»»åŠ¡")
            self._save_queue()
            return count
    
    def _save_queue(self) -> None:
        """ä¿å­˜é˜Ÿåˆ—åˆ°æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.save_file), exist_ok=True)
            
            queue_data = {
                'tasks': {task_id: task.to_dict() for task_id, task in self.tasks.items()},
                'stats': self.stats,
                'settings': {
                    'max_concurrent': self.max_concurrent,
                    'running': self._running,
                    'paused': self._paused
                },
                'save_time': time.time()
            }
            
            with open(self.save_file, 'w', encoding='utf-8') as f:
                json.dump(queue_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜é˜Ÿåˆ—å¤±è´¥: {e}")
    
    def _load_queue(self) -> None:
        """ä»æ–‡ä»¶åŠ è½½é˜Ÿåˆ—"""
        try:
            if not os.path.exists(self.save_file):
                return
            
            with open(self.save_file, 'r', encoding='utf-8') as f:
                queue_data = json.load(f)
            
            # æ¢å¤ä»»åŠ¡
            tasks_data = queue_data.get('tasks', {})
            for task_id, task_data in tasks_data.items():
                try:
                    task = QueueTask.from_dict(task_data)
                    self.tasks[task_id] = task
                    
                    # å°†ç­‰å¾…ä¸­çš„ä»»åŠ¡é‡æ–°åŠ å…¥é˜Ÿåˆ—
                    if task.status == TaskStatus.WAITING:
                        self.priority_queue.put(task)
                    # å°†è¿è¡Œä¸­çš„ä»»åŠ¡é‡ç½®ä¸ºç­‰å¾…çŠ¶æ€
                    elif task.status == TaskStatus.RUNNING:
                        task.status = TaskStatus.WAITING
                        task.start_time = None
                        task.progress = 0.0
                        self.priority_queue.put(task)
                        
                except Exception as e:
                    self.logger.error(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {task_id} - {e}")
            
            # æ¢å¤ç»Ÿè®¡ä¿¡æ¯
            self.stats.update(queue_data.get('stats', {}))
            
            # æ¢å¤è®¾ç½®
            settings = queue_data.get('settings', {})
            self.max_concurrent = settings.get('max_concurrent', self.max_concurrent)
            
            self.logger.info(f"é˜Ÿåˆ—å·²æ¢å¤: {len(self.tasks)} ä¸ªä»»åŠ¡")
            
        except Exception as e:
            self.logger.error(f"åŠ è½½é˜Ÿåˆ—å¤±è´¥: {e}")
    
    def shutdown(self) -> None:
        """å…³é—­é˜Ÿåˆ—ç®¡ç†å™¨"""
        self.stop_queue()
        self.executor.shutdown(wait=True)
        self._save_queue()
        self.logger.info("é˜Ÿåˆ—ç®¡ç†å™¨å·²å…³é—­")


class TorrentQueueManager(QueueManager):
    """Torrentåˆ¶ç§é˜Ÿåˆ—ç®¡ç†å™¨"""
    
    def __init__(self, torrent_creator, max_concurrent: int = 4, save_file: Optional[str] = None):
        super().__init__(max_concurrent, save_file)
        self.torrent_creator = torrent_creator
    
    def _execute_task(self, task: QueueTask) -> bool:
        """æ‰§è¡ŒTorrentåˆ¶ç§ä»»åŠ¡"""
        try:
            # åº”ç”¨é¢„è®¾é…ç½®
            if hasattr(self.torrent_creator, 'config_manager'):
                config_manager = self.torrent_creator.config_manager
                if hasattr(config_manager, 'apply_preset'):
                    config_manager.apply_preset(task.preset)
            
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            output_path = task.output_path or self.torrent_creator.config_manager.get_output_folder()
            
            # æ›´æ–°TorrentCreatorçš„è¾“å‡ºç›®å½•
            from pathlib import Path
            self.torrent_creator.output_dir = Path(output_path)
            
            # æ‰§è¡Œåˆ¶ç§
            success = self.torrent_creator.create_torrent(
                task.path,
                custom_name=None,  # ä½¿ç”¨é»˜è®¤å‘½åï¼ˆåŸºäºæ–‡ä»¶å¤¹åï¼‰
                progress_callback=lambda p: self._update_task_progress(task, p)
            )
            
            return success
            
        except Exception as e:
            task.error_message = str(e)
            self.logger.error(f"åˆ¶ç§ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.name} - {e}")
            return False
    
    def _update_task_progress(self, task: QueueTask, progress: float) -> None:
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        task.progress = progress
        
        # è°ƒç”¨è¿›åº¦æ›´æ–°å›è°ƒ
        if self.on_progress_update:
            try:
                self.on_progress_update(task)
            except Exception as e:
                self.logger.error(f"è¿›åº¦æ›´æ–°å›è°ƒå¤±è´¥: {e}")
    
    def add_torrent_task(self, file_path: str, preset: str = "standard", 
                        priority: TaskPriority = TaskPriority.NORMAL,
                        output_path: str = "") -> str:
        """æ·»åŠ åˆ¶ç§ä»»åŠ¡"""
        name = self._generate_smart_task_name(file_path)
        return self.add_task(name, file_path, priority, preset, output_path)
    
    def _generate_smart_task_name(self, file_path: str) -> str:
        """ç”Ÿæˆæ™ºèƒ½ä»»åŠ¡åç§°"""
        try:
            from pathlib import Path
            path_obj = Path(file_path)
            
            # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œæ˜¾ç¤ºæ›´æœ‰æ„ä¹‰çš„è·¯å¾„
            if path_obj.is_dir():
                # å°è¯•è·å–ç›¸å¯¹äºèµ„æºæ–‡ä»¶å¤¹çš„è·¯å¾„
                try:
                    if hasattr(self.torrent_creator, 'config_manager'):
                        resource_folder = self.torrent_creator.config_manager.get_resource_folder()
                        if resource_folder:
                            resource_path = Path(resource_folder)
                            relative_path = path_obj.relative_to(resource_path)
                            name = str(relative_path)
                        else:
                            raise ValueError("No resource folder")
                    else:
                        raise ValueError("No config manager")
                except (ValueError, AttributeError):
                    # å¦‚æœä¸åœ¨èµ„æºæ–‡ä»¶å¤¹å†…æˆ–æ— æ³•è·å–ï¼Œæ˜¾ç¤ºæœ€åä¸¤çº§ç›®å½•
                    parts = path_obj.parts
                    if len(parts) >= 2:
                        name = os.path.join(parts[-2], parts[-1])
                    else:
                        name = path_obj.name
            else:
                name = path_obj.name
            
            # é™åˆ¶åç§°é•¿åº¦ï¼Œé¿å…ç•Œé¢æ˜¾ç¤ºé—®é¢˜
            if len(name) > 50:
                name = name[:47] + "..."
            
            return name
            
        except Exception as e:
            # å¦‚æœå‡ºç°ä»»ä½•é”™è¯¯ï¼Œå›é€€åˆ°ç®€å•å‘½å
            self.logger.warning(f"æ™ºèƒ½å‘½åå¤±è´¥ï¼Œä½¿ç”¨ç®€å•å‘½å: {e}")
            return os.path.basename(file_path)
    
    def batch_add_tasks(self, file_paths: List[str], preset: str = "standard",
                       priority: TaskPriority = TaskPriority.NORMAL) -> List[str]:
        """æ‰¹é‡æ·»åŠ åˆ¶ç§ä»»åŠ¡"""
        task_ids = []
        for file_path in file_paths:
            task_id = self.add_torrent_task(file_path, preset, priority)
            task_ids.append(task_id)
        
        self.logger.info(f"æ‰¹é‡æ·»åŠ äº† {len(task_ids)} ä¸ªåˆ¶ç§ä»»åŠ¡")
        return task_ids


# ================== è·¯å¾„è¡¥å…¨æ¨¡å— ==================
import glob
try:
    import readline
except ImportError:
    readline = None

class PathCompleter:
    """è·¯å¾„è‡ªåŠ¨è¡¥å…¨ç±» - ä¸º Torrent Maker æä¾› Tab é”®è¡¥å…¨åŠŸèƒ½"""
    
    def __init__(self, history_file: str = None):
        self.history_file = history_file or os.path.expanduser("~/.torrent_maker_path_history.json")
        self.path_history: List[str] = []
        self.load_history()
        
        # è®¾ç½® readline è¡¥å…¨
        if readline:
            readline.set_completer(self.complete)
            readline.parse_and_bind("tab: complete")
            readline.set_completer_delims(' \t\n`!@#$%^&*()=+[{]}\\|;:\'\",<>?')
    
    def complete(self, text: str, state: int) -> Optional[str]:
        """Tab è¡¥å…¨å›è°ƒå‡½æ•°"""
        if state == 0:
            self.matches = self._get_matches(text)
        
        try:
            return self.matches[state]
        except IndexError:
            return None
    
    def _get_matches(self, text: str) -> List[str]:
        """è·å–åŒ¹é…çš„è·¯å¾„"""
        matches = []
        
        # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›å†å²è®°å½•
        if not text.strip():
            return self.path_history[-10:]  # æœ€è¿‘10ä¸ª
        
        # å±•å¼€ç”¨æˆ·ç›®å½•
        expanded_text = os.path.expanduser(text)
        
        # è·å–ç›®å½•å’Œæ–‡ä»¶åéƒ¨åˆ†
        if os.path.isdir(expanded_text):
            search_dir = expanded_text
            prefix = ""
        else:
            search_dir = os.path.dirname(expanded_text) or "."
            prefix = os.path.basename(expanded_text)
        
        try:
            # ä½¿ç”¨ glob è¿›è¡ŒåŒ¹é…
            pattern = os.path.join(search_dir, prefix + "*")
            glob_matches = glob.glob(pattern)
            
            for match in sorted(glob_matches):
                # å¦‚æœæ˜¯ç›®å½•ï¼Œæ·»åŠ æ–œæ 
                if os.path.isdir(match):
                    match += os.sep
                matches.append(match)
            
            # æ·»åŠ å†å²è®°å½•ä¸­çš„åŒ¹é…é¡¹
            for hist_path in self.path_history:
                if hist_path.startswith(text) and hist_path not in matches:
                    matches.append(hist_path)
        
        except (OSError, PermissionError):
            pass
        
        return matches[:20]  # é™åˆ¶è¿”å›æ•°é‡
    
    def add_to_history(self, path: str) -> None:
        """æ·»åŠ è·¯å¾„åˆ°å†å²è®°å½•"""
        if not path or not os.path.exists(path):
            return
        
        # è§„èŒƒåŒ–è·¯å¾„
        normalized_path = os.path.abspath(path)
        
        # ç§»é™¤é‡å¤é¡¹
        if normalized_path in self.path_history:
            self.path_history.remove(normalized_path)
        
        # æ·»åŠ åˆ°å¼€å¤´
        self.path_history.insert(0, normalized_path)
        
        # é™åˆ¶å†å²è®°å½•å¤§å°
        if len(self.path_history) > 100:
            self.path_history = self.path_history[:100]
        
        self.save_history()
    
    def get_suggestions(self, partial_path: str, limit: int = 10) -> List[str]:
        """è·å–è·¯å¾„å»ºè®®"""
        suggestions = []
        
        # ä»å†å²è®°å½•ä¸­æŸ¥æ‰¾
        for path in self.path_history:
            if partial_path.lower() in path.lower():
                suggestions.append(path)
                if len(suggestions) >= limit:
                    break
        
        return suggestions
    
    def get_recent_paths(self, limit: int = 10) -> List[str]:
        """è·å–æœ€è¿‘ä½¿ç”¨çš„è·¯å¾„"""
        return self.path_history[:limit]
    
    def load_history(self) -> None:
        """åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.path_history = data.get('paths', [])
        except (json.JSONDecodeError, OSError):
            self.path_history = []
    
    def save_history(self) -> None:
        """ä¿å­˜å†å²è®°å½•"""
        try:
            os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'paths': self.path_history,
                    'last_updated': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
        except OSError:
            pass
    
    def get_input(self, prompt: str) -> str:
        """è·å–ç”¨æˆ·è¾“å…¥ï¼Œæ”¯æŒè·¯å¾„è¡¥å…¨"""
        try:
            if readline:
                # è®¾ç½®å½“å‰è¡¥å…¨å™¨
                old_completer = readline.get_completer()
                readline.set_completer(self.complete)
                
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input(prompt).strip()
                
                # æ¢å¤åŸè¡¥å…¨å™¨
                readline.set_completer(old_completer)
                
                # å¦‚æœè¾“å…¥çš„æ˜¯è·¯å¾„ï¼Œæ·»åŠ åˆ°å†å²è®°å½•
                if user_input and (os.path.exists(user_input) or os.path.dirname(user_input)):
                    self.add_to_history(user_input)
                
                return user_input
            else:
                # æ²¡æœ‰ readline æ”¯æŒæ—¶çš„é™çº§å¤„ç†
                return input(prompt).strip()
        except (EOFError, KeyboardInterrupt):
            return ""


# ================== è¿›åº¦ç›‘æ§æ¨¡å— ==================
from collections import defaultdict

@dataclass
class ProgressInfo:
    """è¿›åº¦ä¿¡æ¯æ•°æ®ç±»"""
    task_id: str
    status: TaskStatus
    progress: float = 0.0  # 0-100
    current_step: str = ""
    total_steps: int = 0
    completed_steps: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    error_message: str = ""
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

class ProgressDisplay:
    """è¿›åº¦æ¡æ˜¾ç¤ºç±»"""
    
    def __init__(self, width: int = 50):
        self.width = width
        self.last_output_length = 0
    
    def show_progress(self, progress: float, message: str = "", show_percentage: bool = True) -> None:
        """æ˜¾ç¤ºè¿›åº¦æ¡"""
        # ç¡®ä¿è¿›åº¦åœ¨ 0-100 èŒƒå›´å†…
        progress = max(0, min(100, progress))
        
        # è®¡ç®—è¿›åº¦æ¡
        filled_width = int(self.width * progress / 100)
        bar = "â–ˆ" * filled_width + "â–‘" * (self.width - filled_width)
        
        # æ„å»ºè¾“å‡ºå­—ç¬¦ä¸²
        if show_percentage:
            output = f"\r[{bar}] {progress:6.2f}%"
        else:
            output = f"\r[{bar}]"
        
        if message:
            output += f" {message}"
        
        # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º
        if len(output) < self.last_output_length:
            output += " " * (self.last_output_length - len(output))
        
        print(output, end="", flush=True)
        self.last_output_length = len(output)
    
    def clear(self) -> None:
        """æ¸…é™¤è¿›åº¦æ¡"""
        if self.last_output_length > 0:
            print("\r" + " " * self.last_output_length + "\r", end="", flush=True)
            self.last_output_length = 0
    
    def finish(self, message: str = "å®Œæˆ!") -> None:
        """å®Œæˆè¿›åº¦æ˜¾ç¤º"""
        self.show_progress(100, message)
        print()  # æ¢è¡Œ
        self.last_output_length = 0

class ProgressMonitor:
    """è¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self):
        self.tasks: Dict[str, ProgressInfo] = {}
        self.callbacks: Dict[str, List[callable]] = defaultdict(list)
        self.display = ProgressDisplay()
        self._lock = threading.Lock()
        self._running = False
        self._display_thread = None
    
    def create_task(self, task_id: str, total_steps: int = 0, metadata: Dict[str, Any] = None) -> ProgressInfo:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        with self._lock:
            task = ProgressInfo(
                task_id=task_id,
                status=TaskStatus.WAITING,
                total_steps=total_steps,
                start_time=datetime.now(),
                metadata=metadata or {}
            )
            self.tasks[task_id] = task
            return task
    
    def start_task(self, task_id: str) -> bool:
        """å¼€å§‹ä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            task.status = TaskStatus.RUNNING
            task.start_time = datetime.now()
            
            self._notify_callbacks(task_id, "started")
            return True
    
    def update_progress(self, task_id: str, progress: float = None, 
                       current_step: str = None, completed_steps: int = None) -> bool:
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            if progress is not None:
                task.progress = max(0, min(100, progress))
            
            if current_step is not None:
                task.current_step = current_step
            
            if completed_steps is not None:
                task.completed_steps = completed_steps
                if task.total_steps > 0:
                    task.progress = (completed_steps / task.total_steps) * 100
            
            self._notify_callbacks(task_id, "progress")
            return True
    
    def complete_task(self, task_id: str, success: bool = True, error_message: str = "") -> bool:
        """å®Œæˆä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            task.status = TaskStatus.COMPLETED if success else TaskStatus.FAILED
            task.end_time = datetime.now()
            task.progress = 100 if success else task.progress
            
            if error_message:
                task.error_message = error_message
            
            self._notify_callbacks(task_id, "completed" if success else "failed")
            return True
    
    def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            task.status = TaskStatus.CANCELLED
            task.end_time = datetime.now()
            
            self._notify_callbacks(task_id, "cancelled")
            return True
    
    def get_task(self, task_id: str) -> Optional[ProgressInfo]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        with self._lock:
            return self.tasks.get(task_id)
    
    def get_all_tasks(self) -> Dict[str, ProgressInfo]:
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        with self._lock:
            return self.tasks.copy()
    
    def add_callback(self, task_id: str, callback: callable) -> None:
        """æ·»åŠ å›è°ƒå‡½æ•°"""
        self.callbacks[task_id].append(callback)
    
    def _notify_callbacks(self, task_id: str, event: str) -> None:
        """é€šçŸ¥å›è°ƒå‡½æ•°"""
        for callback in self.callbacks.get(task_id, []):
            try:
                callback(task_id, event, self.tasks[task_id])
            except Exception as e:
                print(f"âš ï¸ å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
    
    def start_display_loop(self, task_id: str, update_interval: float = 0.1) -> None:
        """å¼€å§‹æ˜¾ç¤ºå¾ªç¯"""
        if self._running:
            return
        
        self._running = True
        self._display_thread = threading.Thread(
            target=self._display_loop,
            args=(task_id, update_interval),
            daemon=True
        )
        self._display_thread.start()
    
    def stop_display_loop(self) -> None:
        """åœæ­¢æ˜¾ç¤ºå¾ªç¯"""
        self._running = False
        if self._display_thread:
            self._display_thread.join(timeout=1.0)
    
    def _display_loop(self, task_id: str, update_interval: float) -> None:
        """æ˜¾ç¤ºå¾ªç¯"""
        while self._running:
            with self._lock:
                task = self.tasks.get(task_id)
                if not task or task.status in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED]:
                    break
                
                message = task.current_step if task.current_step else f"ä»»åŠ¡: {task_id}"
                self.display.show_progress(task.progress, message)
            
            time.sleep(update_interval)
        
        # æ¸…é™¤æ˜¾ç¤º
        self.display.clear()
    
    def clear_completed_tasks(self) -> int:
        """æ¸…é™¤å·²å®Œæˆçš„ä»»åŠ¡"""
        with self._lock:
            completed_statuses = {TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED}
            to_remove = [task_id for task_id, task in self.tasks.items() 
                        if task.status in completed_statuses]
            
            for task_id in to_remove:
                del self.tasks[task_id]
                if task_id in self.callbacks:
                    del self.callbacks[task_id]
            
            return len(to_remove)
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            stats = {
                'total_tasks': len(self.tasks),
                'pending': 0,
                'running': 0,
                'completed': 0,
                'failed': 0,
                'cancelled': 0
            }
            
            for task in self.tasks.values():
                stats[task.status.value] += 1
            
            return stats

class TorrentProgressMonitor:
    """Torrent åˆ¶ç§è¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self):
        self.monitor = ProgressMonitor()
        self.processes: Dict[str, subprocess.Popen] = {}
        self._lock = threading.Lock()
        self.current_task_id: Optional[str] = None
        self.is_monitoring = False
    
    def start_torrent_creation(self, task_id: str, command: List[str], 
                              input_path: str, output_path: str) -> bool:
        """å¼€å§‹åˆ¶ç§ä»»åŠ¡"""
        try:
            # åˆ›å»ºä»»åŠ¡
            file_size = self._get_file_size(input_path)
            self.monitor.create_task(task_id, metadata={
                'input_path': input_path,
                'output_path': output_path,
                'file_size': file_size,
                'command': command
            })
            
            # å¯åŠ¨è¿›ç¨‹
            process = subprocess.Popen(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            with self._lock:
                self.processes[task_id] = process
            
            # å¼€å§‹ç›‘æ§
            self.monitor.start_task(task_id)
            
            # å¯åŠ¨ç›‘æ§çº¿ç¨‹
            monitor_thread = threading.Thread(
                target=self._monitor_process,
                args=(task_id, process),
                daemon=True
            )
            monitor_thread.start()
            
            return True
            
        except Exception as e:
            self.monitor.complete_task(task_id, False, str(e))
            return False
    
    def _monitor_process(self, task_id: str, process: subprocess.Popen) -> None:
        """ç›‘æ§è¿›ç¨‹æ‰§è¡Œ"""
        try:
            # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°ï¼ˆmktorrent æ²¡æœ‰å®æ—¶è¿›åº¦è¾“å‡ºï¼‰
            start_time = time.time()
            
            while process.poll() is None:
                elapsed = time.time() - start_time
                # åŸºäºæ—¶é—´ä¼°ç®—è¿›åº¦ï¼ˆè¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼‰
                estimated_progress = min(90, elapsed * 10)  # å‡è®¾90%çš„è¿›åº¦åŸºäºæ—¶é—´
                
                self.monitor.update_progress(task_id, estimated_progress, "æ­£åœ¨åˆ›å»ºç§å­æ–‡ä»¶...")
                time.sleep(0.5)
            
            # è¿›ç¨‹ç»“æŸ
            return_code = process.returncode
            
            if return_code == 0:
                self.monitor.update_progress(task_id, 100, "ç§å­æ–‡ä»¶åˆ›å»ºå®Œæˆ")
                self.monitor.complete_task(task_id, True)
            else:
                stderr_output = process.stderr.read() if process.stderr else ""
                self.monitor.complete_task(task_id, False, f"è¿›ç¨‹é€€å‡ºç : {return_code}, é”™è¯¯: {stderr_output}")
            
        except Exception as e:
            self.monitor.complete_task(task_id, False, str(e))
        finally:
            with self._lock:
                if task_id in self.processes:
                    del self.processes[task_id]
    
    def cancel_torrent_creation(self, task_id: str) -> bool:
        """å–æ¶ˆåˆ¶ç§ä»»åŠ¡"""
        with self._lock:
            process = self.processes.get(task_id)
            if process:
                try:
                    process.terminate()
                    # ç­‰å¾…è¿›ç¨‹ç»“æŸ
                    try:
                        process.wait(timeout=5)
                    except subprocess.TimeoutExpired:
                        process.kill()
                    
                    self.monitor.cancel_task(task_id)
                    del self.processes[task_id]
                    return True
                except Exception as e:
                    print(f"âš ï¸ å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}")
                    return False
        
        return False
    
    def _get_file_size(self, path: str) -> int:
        """è·å–æ–‡ä»¶æˆ–ç›®å½•å¤§å°"""
        try:
            if os.path.isfile(path):
                return os.path.getsize(path)
            elif os.path.isdir(path):
                total_size = 0
                for dirpath, dirnames, filenames in os.walk(path):
                    for filename in filenames:
                        filepath = os.path.join(dirpath, filename)
                        try:
                            total_size += os.path.getsize(filepath)
                        except (OSError, IOError):
                            continue
                return total_size
        except (OSError, IOError):
            pass
        return 0
    
    def get_task_info(self, task_id: str) -> Optional[ProgressInfo]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        return self.monitor.get_task(task_id)
    
    def get_all_tasks(self) -> Dict[str, ProgressInfo]:
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        return self.monitor.get_all_tasks()
    
    def create_task(self, task_id: str, description: str = "", path: str = "", metadata: Dict[str, Any] = None) -> bool:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        try:
            task_metadata = metadata or {}
            if description:
                task_metadata['description'] = description
            if path:
                task_metadata['path'] = path
            self.monitor.create_task(task_id, task_metadata)
            return True
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def start_task(self, task_id: str) -> bool:
        """å¯åŠ¨ä»»åŠ¡"""
        try:
            self.monitor.start_task(task_id)
            return True
        except Exception as e:
            print(f"âš ï¸ å¯åŠ¨ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def update_progress(self, task_id: str, progress: float, current_step: str = "") -> bool:
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        try:
            self.monitor.update_progress(task_id, progress, current_step)
            return True
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
            return False
    
    def complete_task(self, task_id: str, success: bool, error_message: str = "") -> bool:
        """å®Œæˆä»»åŠ¡"""
        try:
            self.monitor.complete_task(task_id, success, error_message)
            return True
        except Exception as e:
            print(f"âš ï¸ å®Œæˆä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def start_monitoring(self, task_name: str, task_path: str) -> bool:
        """å¼€å§‹ç›‘æ§åˆ¶ç§ä»»åŠ¡"""
        try:
            # ç”Ÿæˆä»»åŠ¡ID
            task_id = f"torrent_{int(time.time())}_{task_name}"
            self.current_task_id = task_id
            
            # åˆ›å»ºç›‘æ§ä»»åŠ¡
            file_size = self._get_file_size(task_path)
            self.monitor.create_task(task_id, metadata={
                'task_name': task_name,
                'task_path': task_path,
                'file_size': file_size,
                'start_time': time.time()
            })
            
            # å¯åŠ¨ä»»åŠ¡
            self.monitor.start_task(task_id)
            self.is_monitoring = True
            
            print(f"ğŸ“Š å¼€å§‹ç›‘æ§åˆ¶ç§ä»»åŠ¡: {task_name}")
            return True
            
        except Exception as e:
            print(f"âš ï¸ å¯åŠ¨ç›‘æ§å¤±è´¥: {e}")
            return False
    
    def stop_monitoring(self) -> bool:
        """åœæ­¢ç›‘æ§åˆ¶ç§ä»»åŠ¡"""
        try:
            if self.current_task_id and self.is_monitoring:
                # å®Œæˆå½“å‰ä»»åŠ¡
                self.monitor.complete_task(self.current_task_id, True, "åˆ¶ç§ä»»åŠ¡å®Œæˆ")
                print(f"ğŸ“Š åœæ­¢ç›‘æ§åˆ¶ç§ä»»åŠ¡: {self.current_task_id}")
                
                # é‡ç½®çŠ¶æ€
                self.current_task_id = None
                self.is_monitoring = False
                return True
            else:
                print("âš ï¸ æ²¡æœ‰æ­£åœ¨ç›‘æ§çš„ä»»åŠ¡")
                return False
                
        except Exception as e:
            print(f"âš ï¸ åœæ­¢ç›‘æ§å¤±è´¥: {e}")
            return False
    
    def update_progress(self, message: str, progress: float = None) -> bool:
        """æ›´æ–°ç›‘æ§è¿›åº¦"""
        try:
            if self.current_task_id and self.is_monitoring:
                if progress is not None:
                    self.monitor.update_progress(self.current_task_id, progress, message)
                else:
                    # å¦‚æœæ²¡æœ‰æä¾›è¿›åº¦å€¼ï¼ŒåŸºäºæ—¶é—´ä¼°ç®—
                    task_info = self.monitor.get_task(self.current_task_id)
                    if task_info and task_info.metadata.get('start_time'):
                        elapsed = time.time() - task_info.metadata['start_time']
                        estimated_progress = min(90, elapsed * 5)  # ç®€å•çš„æ—¶é—´ä¼°ç®—
                        self.monitor.update_progress(self.current_task_id, estimated_progress, message)
                return True
            return False
            
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
            return False


# ================== æœç´¢å†å²æ¨¡å— ==================
from collections import Counter
import difflib

@dataclass
class SearchEntry:
    """æœç´¢è®°å½•æ¡ç›®"""
    query: str
    timestamp: datetime
    results_count: int = 0
    selected_results: List[str] = None
    success: bool = True
    search_time: float = 0.0
    category: str = ""
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.selected_results is None:
            self.selected_results = []
        if self.metadata is None:
            self.metadata = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'query': self.query,
            'timestamp': self.timestamp.isoformat(),
            'results_count': self.results_count,
            'selected_results': self.selected_results,
            'success': self.success,
            'search_time': self.search_time,
            'category': self.category,
            'metadata': self.metadata
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SearchEntry':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(
            query=data['query'],
            timestamp=datetime.fromisoformat(data['timestamp']),
            results_count=data.get('results_count', 0),
            selected_results=data.get('selected_results', []),
            success=data.get('success', True),
            search_time=data.get('search_time', 0.0),
            category=data.get('category', ''),
            metadata=data.get('metadata', {})
        )

class SearchHistory:
    """æœç´¢å†å²ç®¡ç†å™¨"""
    
    def __init__(self, history_file: str = None, max_entries: int = 1000):
        self.history_file = history_file or os.path.expanduser("~/.torrent_maker_search_history.json")
        self.max_entries = max_entries
        self.entries: List[SearchEntry] = []
        self.load_history()
    
    def add_search(self, query: str, results_count: int = 0, 
                   selected_results: List[str] = None, success: bool = True,
                   search_time: float = 0.0, category: str = "",
                   **metadata) -> SearchEntry:
        """æ·»åŠ æœç´¢è®°å½•"""
        cleaned_query = self._clean_query(query)
        if not cleaned_query:
            return None
        
        # æ£€æŸ¥é‡å¤æœç´¢
        from datetime import timedelta
        recent_cutoff = datetime.now() - timedelta(minutes=5)
        for entry in reversed(self.entries):
            if (entry.timestamp > recent_cutoff and 
                entry.query.lower() == cleaned_query.lower()):
                # æ›´æ–°ç°æœ‰è®°å½•
                entry.results_count = max(entry.results_count, results_count)
                if selected_results:
                    entry.selected_results.extend(selected_results)
                    entry.selected_results = list(set(entry.selected_results))
                entry.success = entry.success and success
                entry.search_time = (entry.search_time + search_time) / 2
                if category:
                    entry.category = category
                entry.metadata.update(metadata)
                self.save_history()
                return entry
        
        # åˆ›å»ºæ–°è®°å½•
        entry = SearchEntry(
            query=cleaned_query,
            timestamp=datetime.now(),
            results_count=results_count,
            selected_results=selected_results or [],
            success=success,
            search_time=search_time,
            category=category,
            metadata=metadata
        )
        
        self.entries.append(entry)
        
        # é™åˆ¶å†å²è®°å½•å¤§å°
        if len(self.entries) > self.max_entries:
            self.entries = self.entries[-self.max_entries:]
        
        self.save_history()
        return entry
    
    def _clean_query(self, query: str) -> str:
        """æ¸…ç†æŸ¥è¯¢å­—ç¬¦ä¸²"""
        if not query:
            return ""
        
        cleaned = re.sub(r'\s+', ' ', query.strip())
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff.\-_()\[\]]+', '', cleaned)
        return cleaned
    
    def get_suggestions(self, partial_query: str, limit: int = 10) -> List[Tuple[str, float]]:
        """è·å–æœç´¢å»ºè®®"""
        if not partial_query.strip():
            recent_queries = [entry.query for entry in reversed(self.entries[-limit:])]
            return [(query, 1.0) for query in recent_queries]
        
        partial_lower = partial_query.lower().strip()
        suggestions = []
        
        all_queries = [entry.query for entry in self.entries]
        
        for query in set(all_queries):
            query_lower = query.lower()
            
            if query_lower.startswith(partial_lower):
                suggestions.append((query, 1.0))
            elif partial_lower in query_lower:
                suggestions.append((query, 0.8))
            else:
                similarity = difflib.SequenceMatcher(None, partial_lower, query_lower).ratio()
                if similarity > 0.6:
                    suggestions.append((query, similarity))
        
        query_counts = Counter(all_queries)
        suggestions.sort(key=lambda x: (x[1], query_counts[x[0]]), reverse=True)
        
        return suggestions[:limit]
    
    def get_recent_queries(self, limit: int = 10) -> List[str]:
        """è·å–æœ€è¿‘æœç´¢"""
        recent_queries = []
        seen = set()
        
        for entry in reversed(self.entries):
            if entry.query not in seen:
                recent_queries.append(entry.query)
                seen.add(entry.query)
                if len(recent_queries) >= limit:
                    break
        
        return recent_queries
    
    def get_popular_queries(self, limit: int = 10) -> List[str]:
        """è·å–çƒ­é—¨æœç´¢"""
        query_counts = Counter(entry.query for entry in self.entries)
        popular_queries = [query for query, count in query_counts.most_common(limit)]
        return popular_queries
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯"""
        if not self.entries:
            return {
                'total_searches': 0,
                'unique_queries': 0,
                'success_rate': 0.0,
                'average_results': 0.0
            }
        
        total_searches = len(self.entries)
        unique_queries = len(set(entry.query for entry in self.entries))
        successful_searches = sum(1 for entry in self.entries if entry.success)
        success_rate = successful_searches / total_searches if total_searches > 0 else 0.0
        average_results = sum(entry.results_count for entry in self.entries) / total_searches if total_searches > 0 else 0.0
        
        return {
            'total_searches': total_searches,
            'unique_queries': unique_queries,
            'success_rate': round(success_rate * 100, 1),
            'average_results': round(average_results, 1)
        }
    
    def load_history(self):
        """åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    entries_data = data.get('entries', data)
                    self.entries = [SearchEntry.from_dict(entry_data) for entry_data in entries_data]
        except (json.JSONDecodeError, OSError, KeyError) as e:
            print(f"âš ï¸ åŠ è½½æœç´¢å†å²å¤±è´¥: {e}")
            self.entries = []
    
    def save_history(self):
        """ä¿å­˜å†å²è®°å½•"""
        try:
            os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
            
            data = {
                'version': '1.0',
                'last_updated': datetime.now().isoformat(),
                'total_entries': len(self.entries),
                'entries': [entry.to_dict() for entry in self.entries]
            }
            
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except OSError as e:
            print(f"âš ï¸ ä¿å­˜æœç´¢å†å²å¤±è´¥: {e}")

class SmartSearchSuggester:
    """æ™ºèƒ½æœç´¢å»ºè®®å™¨"""
    
    def __init__(self, search_history: SearchHistory):
        self.history = search_history
        self.patterns = {
            'ç”µå½±': [r'\d{4}', r'(ç”µå½±|movie|film)', r'(HD|4K|1080p|720p|BluRay|BDRip)', r'(ä¸­å­—|å­—å¹•|subtitle)'],
            'ç”µè§†å‰§': [r'(ç¬¬\d+å­£|S\d+|season)', r'(ç¬¬\d+é›†|E\d+|episode)', r'(ç”µè§†å‰§|TV|series)', r'(å…¨é›†|å®Œæ•´ç‰ˆ|complete)'],
            'åŠ¨æ¼«': [r'(åŠ¨æ¼«|anime|åŠ¨ç”»)', r'(ç¬¬\d+è¯|ç¬¬\d+é›†)', r'(OVA|OAD|å‰§åœºç‰ˆ)', r'(æ—¥è¯­|ä¸­é…|åŒè¯­)'],
            'çºªå½•ç‰‡': [r'(çºªå½•ç‰‡|documentary)', r'(BBC|National Geographic|Discovery)', r'(è‡ªç„¶|å†å²|ç§‘å­¦)']
        }
    
    def suggest_improvements(self, query: str) -> List[str]:
        """å»ºè®®æŸ¥è¯¢æ”¹è¿›"""
        suggestions = []
        
        detected_category = self._detect_category(query)
        if detected_category:
            suggestions.append(f"æ£€æµ‹åˆ°ç±»å‹: {detected_category}")
        
        if not re.search(r'\d{4}', query) and detected_category in ['ç”µå½±', 'ç”µè§†å‰§']:
            suggestions.append("å»ºè®®æ·»åŠ å¹´ä»½ä»¥è·å¾—æ›´ç²¾ç¡®çš„ç»“æœ")
        
        if not re.search(r'(HD|4K|1080p|720p|BluRay)', query, re.IGNORECASE):
            suggestions.append("å¯ä»¥æ·»åŠ ç”»è´¨ä¿¡æ¯ (å¦‚: 1080p, 4K)")
        
        if not re.search(r'(ä¸­å­—|å­—å¹•|subtitle)', query, re.IGNORECASE):
            suggestions.append("å¯ä»¥æ·»åŠ å­—å¹•ä¿¡æ¯ (å¦‚: ä¸­å­—)")
        
        return suggestions
    
    def _detect_category(self, query: str) -> Optional[str]:
        """æ£€æµ‹æŸ¥è¯¢åˆ†ç±»"""
        query_lower = query.lower()
        
        for category, patterns in self.patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    return category
        
        return None
    
    def get_related_queries(self, query: str, limit: int = 5) -> List[str]:
        """è·å–ç›¸å…³æŸ¥è¯¢å»ºè®®"""
        related_queries = []
        query_lower = query.lower()
        
        # ä»å†å²è®°å½•ä¸­æŸ¥æ‰¾ç›¸ä¼¼æŸ¥è¯¢
        # å…¼å®¹ä¸¤ç§SearchHistoryå®ç°
        history_data = getattr(self.history, 'entries', None) or getattr(self.history, 'history', [])
        
        for entry in history_data:
            # å…¼å®¹ä¸åŒçš„æ•°æ®ç»“æ„
            entry_query = entry.query if hasattr(entry, 'query') else entry.get('query', '')
            entry_query_lower = entry_query.lower()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸åŒå…³é”®è¯
            query_words = set(query_lower.split())
            entry_words = set(entry_query_lower.split())
            
            # å¦‚æœæœ‰å…±åŒè¯æ±‡ä¸”ä¸æ˜¯å®Œå…¨ç›¸åŒçš„æŸ¥è¯¢
            if (query_words & entry_words and 
                entry_query != query and 
                entry_query not in related_queries):
                related_queries.append(entry_query)
                
                if len(related_queries) >= limit:
                    break
        
        return related_queries
    
    def get_search_suggestions(self, query: str) -> List[str]:
        """è·å–æœç´¢å»ºè®®ï¼ˆæ•´åˆæ”¹è¿›å»ºè®®å’Œç›¸å…³æŸ¥è¯¢ï¼‰"""
        suggestions = []
        
        # æ·»åŠ æŸ¥è¯¢æ”¹è¿›å»ºè®®
        improvements = self.suggest_improvements(query)
        suggestions.extend(improvements)
        
        # æ·»åŠ ç›¸å…³æŸ¥è¯¢å»ºè®®
        related = self.get_related_queries(query, limit=3)
        if related:
            suggestions.append("ç›¸å…³æœç´¢å†å²:")
            for related_query in related:
                suggestions.append(f"  â†’ {related_query}")
        
        return suggestions


# ================== æ€§èƒ½ç›‘æ§ç³»ç»Ÿ ==================
class PerformanceMonitor:
    """ç®€å•çš„æ€§èƒ½ç›‘æ§ç±»"""

    def __init__(self):
        self._timers: Dict[str, float] = {}
        self._stats: Dict[str, Dict[str, float]] = {}
        self._lock = threading.Lock()

    def start_timer(self, name: str) -> None:
        """å¼€å§‹è®¡æ—¶"""
        with self._lock:
            self._timers[name] = time.time()

    def end_timer(self, name: str) -> float:
        """ç»“æŸè®¡æ—¶å¹¶è¿”å›è€—æ—¶"""
        with self._lock:
            if name not in self._timers:
                return 0.0

            duration = time.time() - self._timers[name]
            del self._timers[name]

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if name not in self._stats:
                self._stats[name] = {
                    'count': 0,
                    'total': 0.0,
                    'average': 0.0,
                    'max': 0.0,
                    'min': float('inf')
                }

            stats = self._stats[name]
            stats['count'] += 1
            stats['total'] += duration
            stats['average'] = stats['total'] / stats['count']
            stats['max'] = max(stats['max'], duration)
            stats['min'] = min(stats['min'], duration)

            return duration

    def get_stats(self, name: str) -> Dict[str, float]:
        """è·å–æŒ‡å®šè®¡æ—¶å™¨çš„ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return self._stats.get(name, {})

    def get_all_stats(self) -> Dict[str, Dict[str, float]]:
        """è·å–æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return self._stats.copy()


# ================== ç¼“å­˜ç³»ç»Ÿ ==================
class SearchCache:
    """æœç´¢ç»“æœç¼“å­˜ç±»"""

    def __init__(self, cache_duration: int = 3600):
        self.cache_duration = cache_duration
        self._cache: Dict[str, Tuple[float, Any]] = {}
        self._lock = threading.Lock()

    def get(self, key: str) -> Optional[Any]:
        with self._lock:
            if key in self._cache:
                timestamp, value = self._cache[key]
                if time.time() - timestamp < self.cache_duration:
                    return value
                else:
                    del self._cache[key]
            return None

    def set(self, key: str, value: Any) -> None:
        with self._lock:
            self._cache[key] = (time.time(), value)

    def clear(self) -> None:
        with self._lock:
            self._cache.clear()

    def get_stats(self) -> Dict[str, Any]:
        with self._lock:
            total_items = len(self._cache)
            current_time = time.time()
            expired_items = sum(1 for timestamp, _ in self._cache.values()
                              if current_time - timestamp >= self.cache_duration)
            return {
                'total_items': total_items,
                'valid_items': total_items - expired_items,
                'expired_items': expired_items
            }


# ================== ç›®å½•å¤§å°ç¼“å­˜ ==================
class DirectorySizeCache:
    """ç›®å½•å¤§å°ç¼“å­˜ç±» - é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬"""

    def __init__(self, cache_duration: int = 1800, max_cache_size: int = 1000):
        self.cache_duration = cache_duration
        self.max_cache_size = max_cache_size
        self._cache: Dict[str, Tuple[float, int, float, int]] = {}  # path -> (timestamp, size, mtime, access_count)
        self._access_order: List[str] = []  # LRU è®¿é—®é¡ºåº
        self._lock = threading.Lock()
        self._stats = {'hits': 0, 'misses': 0, 'evictions': 0}

    def get_directory_size(self, path: Path) -> int:
        """è·å–ç›®å½•å¤§å°ï¼Œä½¿ç”¨é«˜æ€§èƒ½ç¼“å­˜ä¼˜åŒ–"""
        path_str = str(path)
        current_time = time.time()

        try:
            # è·å–ç›®å½•çš„ä¿®æ”¹æ—¶é—´
            dir_mtime = path.stat().st_mtime
        except (OSError, PermissionError):
            return self._calculate_size_fallback(path)

        with self._lock:
            # æ£€æŸ¥ç¼“å­˜
            if path_str in self._cache:
                timestamp, cached_size, cached_mtime, access_count = self._cache[path_str]
                # å¦‚æœç¼“å­˜æœªè¿‡æœŸä¸”ç›®å½•æœªä¿®æ”¹ï¼Œè¿”å›ç¼“å­˜å€¼
                if (current_time - timestamp < self.cache_duration and
                    abs(dir_mtime - cached_mtime) < 1.0):  # 1ç§’å®¹å·®
                    # æ›´æ–°è®¿é—®ç»Ÿè®¡å’Œ LRU é¡ºåº
                    self._cache[path_str] = (timestamp, cached_size, cached_mtime, access_count + 1)
                    self._update_access_order(path_str)
                    self._stats['hits'] += 1
                    return cached_size
                else:
                    # ç¼“å­˜è¿‡æœŸï¼Œç§»é™¤
                    self._remove_from_cache(path_str)

        self._stats['misses'] += 1

        # è®¡ç®—ç›®å½•å¤§å°
        total_size = self._calculate_size_optimized(path)

        # æ›´æ–°ç¼“å­˜
        with self._lock:
            self._add_to_cache(path_str, current_time, total_size, dir_mtime)

        return total_size

    def _add_to_cache(self, path_str: str, timestamp: float, size: int, mtime: float) -> None:
        """æ·»åŠ åˆ°ç¼“å­˜ï¼Œå®ç° LRU æ·˜æ±°"""
        # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€å°‘ä½¿ç”¨çš„é¡¹
        if len(self._cache) >= self.max_cache_size:
            self._evict_lru()

        self._cache[path_str] = (timestamp, size, mtime, 1)
        self._access_order.append(path_str)

    def _remove_from_cache(self, path_str: str) -> None:
        """ä»ç¼“å­˜ä¸­ç§»é™¤é¡¹ç›®"""
        if path_str in self._cache:
            del self._cache[path_str]
        if path_str in self._access_order:
            self._access_order.remove(path_str)

    def _update_access_order(self, path_str: str) -> None:
        """æ›´æ–° LRU è®¿é—®é¡ºåº"""
        if path_str in self._access_order:
            self._access_order.remove(path_str)
        self._access_order.append(path_str)

    def _evict_lru(self) -> None:
        """æ·˜æ±°æœ€å°‘ä½¿ç”¨çš„ç¼“å­˜é¡¹"""
        if self._access_order:
            lru_path = self._access_order.pop(0)
            if lru_path in self._cache:
                del self._cache[lru_path]
                self._stats['evictions'] += 1

    def _calculate_size_optimized(self, path: Path) -> int:
        """å†…å­˜ä¼˜åŒ–çš„ç›®å½•å¤§å°è®¡ç®—"""
        # æ£€æŸ¥ç›®å½•å¤§å°ï¼Œå†³å®šä½¿ç”¨å“ªç§ç­–ç•¥
        try:
            # å¿«é€Ÿä¼°ç®—ç›®å½•å¤æ‚åº¦
            complexity = self._estimate_directory_complexity(path)

            if complexity['estimated_files'] > 10000:
                # å¤§ç›®å½•ä½¿ç”¨æµå¼å¤„ç†
                return self._calculate_size_streaming(path)
            elif complexity['estimated_files'] > 1000:
                # ä¸­ç­‰ç›®å½•ä½¿ç”¨æ‰¹é‡å¤„ç†
                return self._calculate_size_batch(path)
            else:
                # å°ç›®å½•ä½¿ç”¨ç®€å•æ–¹æ³•
                return self._scan_directory_simple(path)

        except Exception:
            # å›é€€åˆ°ç®€å•æ–¹æ³•
            return self._scan_directory_simple(path)

    def _estimate_directory_complexity(self, path: Path) -> Dict[str, int]:
        """ä¼°ç®—ç›®å½•å¤æ‚åº¦"""
        try:
            sample_count = 0
            dir_count = 0
            file_count = 0

            # åªæ‰«æå‰å‡ ä¸ªå­ç›®å½•æ¥ä¼°ç®—
            with os.scandir(path) as entries:
                for entry in entries:
                    sample_count += 1
                    if entry.is_dir(follow_symlinks=False):
                        dir_count += 1
                    elif entry.is_file(follow_symlinks=False):
                        file_count += 1

                    # åªé‡‡æ ·å‰ 100 ä¸ªé¡¹ç›®
                    if sample_count >= 100:
                        break

            # ä¼°ç®—æ€»æ–‡ä»¶æ•°
            if dir_count > 0:
                estimated_files = file_count + dir_count * 50  # å‡è®¾æ¯ä¸ªå­ç›®å½•å¹³å‡ 50 ä¸ªæ–‡ä»¶
            else:
                estimated_files = file_count

            return {
                'sample_count': sample_count,
                'dir_count': dir_count,
                'file_count': file_count,
                'estimated_files': estimated_files
            }

        except (OSError, PermissionError):
            return {'sample_count': 0, 'dir_count': 0, 'file_count': 0, 'estimated_files': 0}

    def _calculate_size_streaming(self, path: Path) -> int:
        """æµå¼è®¡ç®—å¤§ç›®å½•å¤§å° - å¼‚æ­¥ä¼˜åŒ–ç‰ˆæœ¬"""
        # å°è¯•ä½¿ç”¨å¼‚æ­¥å¤„ç†å™¨
        try:
            async_processor = AsyncFileProcessor(max_concurrent=4)

            # å…ˆå¼‚æ­¥æ‰«æç›®å½•æ ‘
            loop = async_processor.async_io._get_event_loop()
            if loop is not None:
                try:
                    import asyncio
                    if loop.is_running():
                        future = asyncio.ensure_future(
                            async_processor.async_directory_tree_scan(path, max_depth=10, include_files=True)
                        )
                        result = asyncio.run_coroutine_threadsafe(future, loop).result(timeout=30)
                    else:
                        result = loop.run_until_complete(
                            async_processor.async_directory_tree_scan(path, max_depth=10, include_files=True)
                        )

                    return result.get('total_size', 0)
                except Exception:
                    pass
        except Exception:
            pass

        # å›é€€åˆ°åŒæ­¥æµå¼å¤„ç†
        total_size = 0
        processed_count = 0

        try:
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    try:
                        total_size += file_path.stat().st_size
                        processed_count += 1

                        # æ¯å¤„ç† 1000 ä¸ªæ–‡ä»¶æ£€æŸ¥ä¸€æ¬¡å†…å­˜
                        if processed_count % 1000 == 0:
                            # è¿™é‡Œå¯ä»¥æ·»åŠ å†…å­˜æ£€æŸ¥é€»è¾‘
                            pass

                    except (OSError, IOError):
                        pass
        except (OSError, PermissionError):
            pass

        return total_size

    def _calculate_size_batch(self, path: Path) -> int:
        """æ‰¹é‡è®¡ç®—ä¸­ç­‰ç›®å½•å¤§å°"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import queue

        total_size = 0
        scan_queue = queue.Queue()
        scan_queue.put(path)

        def scan_directory_batch() -> int:
            """æ‰¹é‡æ‰«æç›®å½•"""
            batch_size = 0

            try:
                while not scan_queue.empty():
                    try:
                        current_path = scan_queue.get_nowait()

                        with os.scandir(current_path) as entries:
                            for entry in entries:
                                if entry.is_file(follow_symlinks=False):
                                    try:
                                        batch_size += entry.stat().st_size
                                    except (OSError, IOError):
                                        pass
                                elif entry.is_dir(follow_symlinks=False):
                                    scan_queue.put(Path(entry.path))
                    except queue.Empty:
                        break
                    except (PermissionError, OSError):
                        continue
            except Exception:
                pass

            return batch_size

        try:
            # ä½¿ç”¨å°‘é‡çº¿ç¨‹å¹¶è¡Œå¤„ç†
            with ThreadPoolExecutor(max_workers=2) as executor:
                futures = []

                # å¯åŠ¨æ‰«æä»»åŠ¡
                for _ in range(2):
                    if not scan_queue.empty():
                        futures.append(executor.submit(scan_directory_batch))

                # æ”¶é›†ç»“æœ
                for future in as_completed(futures):
                    try:
                        total_size += future.result()
                    except Exception:
                        pass

                # å¤„ç†å‰©ä½™ç›®å½•
                while not scan_queue.empty():
                    try:
                        remaining_path = scan_queue.get_nowait()
                        total_size += self._scan_directory_simple(remaining_path)
                    except queue.Empty:
                        break

        except Exception:
            total_size = self._scan_directory_simple(path)

        return total_size

    def _scan_directory_simple(self, path: Path) -> int:
        """ç®€å•çš„ç›®å½•æ‰«ææ–¹æ³•"""
        size = 0
        try:
            with os.scandir(path) as entries:
                for entry in entries:
                    if entry.is_file(follow_symlinks=False):
                        try:
                            size += entry.stat().st_size
                        except (OSError, IOError):
                            pass
                    elif entry.is_dir(follow_symlinks=False):
                        size += self._scan_directory_simple(Path(entry.path))
        except (PermissionError, OSError):
            pass
        return size

    def _calculate_size_fallback(self, path: Path) -> int:
        """å›é€€çš„ç›®å½•å¤§å°è®¡ç®—æ–¹æ³•"""
        total_size = 0
        try:
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    try:
                        total_size += file_path.stat().st_size
                    except (OSError, IOError):
                        pass
        except (OSError, PermissionError):
            pass
        return total_size

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            total_requests = self._stats['hits'] + self._stats['misses']
            hit_rate = self._stats['hits'] / total_requests if total_requests > 0 else 0

            return {
                'cache_size': len(self._cache),
                'max_cache_size': self.max_cache_size,
                'hit_rate': hit_rate,
                'hits': self._stats['hits'],
                'misses': self._stats['misses'],
                'evictions': self._stats['evictions'],
                'total_requests': total_requests
            }

    def clear_cache(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self._cache.clear()
            self._access_order.clear()
            self._stats = {'hits': 0, 'misses': 0, 'evictions': 0}

    def cleanup_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜é¡¹"""
        current_time = time.time()
        expired_count = 0

        with self._lock:
            expired_paths = []
            for path_str, (timestamp, _, _, _) in self._cache.items():
                if current_time - timestamp >= self.cache_duration:
                    expired_paths.append(path_str)

            for path_str in expired_paths:
                self._remove_from_cache(path_str)
                expired_count += 1

        return expired_count


# ================== å¼‚å¸¸ç±» ==================
class ConfigValidationError(Exception):
    """é…ç½®éªŒè¯é”™è¯¯"""
    pass


class TorrentCreationError(Exception):
    """ç§å­åˆ›å»ºé”™è¯¯"""
    pass


# ================== é…ç½®ç®¡ç†å™¨ ==================
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ - v1.5.1ä¿®å¤ä¼˜åŒ–ç‰ˆæœ¬"""
    
    DEFAULT_SETTINGS = {
        "resource_folder": "~/Downloads",
        "output_folder": "~/Desktop/torrents",
        "file_search_tolerance": 60,
        "max_search_results": 10,
        "auto_create_output_dir": True,
        "enable_cache": True,
        "cache_duration": 3600,
        "max_concurrent_operations": 4,
        "log_level": "WARNING",
        "max_scan_depth": 3,
        "max_scan_folders": 5000,
        "max_scan_time": 30
    }
    
    DEFAULT_TRACKERS = [
        "udp://tracker.openbittorrent.com:80",
        "udp://tracker.opentrackr.org:1337/announce",
        "udp://exodus.desync.com:6969/announce",
        "udp://tracker.torrent.eu.org:451/announce"
    ]

    def __init__(self):
        self.config_dir = os.path.expanduser("~/.torrent_maker")
        self.settings_path = os.path.join(self.config_dir, "settings.json")
        self.trackers_path = os.path.join(self.config_dir, "trackers.txt")
        
        self._ensure_config_files()
        self.settings = self._load_settings()
        self.trackers = self._load_trackers()
        self._validate_config()

    def _ensure_config_files(self) -> None:
        try:
            os.makedirs(self.config_dir, exist_ok=True)
            if not os.path.exists(self.settings_path):
                self._create_default_settings()
            if not os.path.exists(self.trackers_path):
                self._create_default_trackers()
            
            # ç¡®ä¿é¢„è®¾é…ç½®æ–‡ä»¶å­˜åœ¨
            presets_path = os.path.join(self.config_dir, "presets.json")
            if not os.path.exists(presets_path):
                self._create_default_presets()
        except OSError as e:
            raise ConfigValidationError(f"æ— æ³•åˆ›å»ºé…ç½®æ–‡ä»¶: {e}")

    def _create_default_settings(self) -> None:
        settings = self.DEFAULT_SETTINGS.copy()
        settings['resource_folder'] = os.path.expanduser(settings['resource_folder'])
        settings['output_folder'] = os.path.expanduser(settings['output_folder'])
        
        with open(self.settings_path, 'w', encoding='utf-8') as f:
            json.dump(settings, f, ensure_ascii=False, indent=4)

    def _create_default_trackers(self) -> None:
        with open(self.trackers_path, 'w', encoding='utf-8') as f:
            f.write("# BitTorrent Tracker åˆ—è¡¨\n")
            f.write("# æ¯è¡Œä¸€ä¸ª tracker URLï¼Œä»¥ # å¼€å¤´çš„è¡Œä¸ºæ³¨é‡Š\n\n")
            for tracker in self.DEFAULT_TRACKERS:
                f.write(f"{tracker}\n")
    
    def _create_default_presets(self) -> None:
        """åˆ›å»ºé»˜è®¤é¢„è®¾é…ç½®æ–‡ä»¶"""
        presets_path = os.path.join(self.config_dir, "presets.json")
        
        # å°è¯•ä»é¡¹ç›®configç›®å½•å¤åˆ¶é¢„è®¾æ–‡ä»¶
        project_presets_path = os.path.join(os.path.dirname(__file__), "config", "presets.json")
        
        if os.path.exists(project_presets_path):
            try:
                import shutil
                shutil.copy2(project_presets_path, presets_path)
                return
            except Exception:
                pass
        
        # å¦‚æœå¤åˆ¶å¤±è´¥ï¼Œåˆ›å»ºåŸºæœ¬çš„é¢„è®¾é…ç½®
        default_presets = {
            "presets": {
                "fast": {
                    "name": "å¿«é€Ÿæ¨¡å¼",
                    "description": "é€‚ç”¨äºå°æ–‡ä»¶(<1GB)ï¼Œä¼˜å…ˆåˆ¶ç§é€Ÿåº¦",
                    "settings": {
                        "piece_size": "256k",
                        "max_concurrent_operations": "auto_x2",
                        "cache_enabled": False,
                        "cache_size_mb": 64,
                        "max_scan_depth": 3,
                        "file_search_tolerance": 0.7,
                        "auto_create_output_dir": True,
                        "log_level": "WARNING"
                    },
                    "recommended_for": [
                        "å°æ–‡ä»¶æ‰¹é‡åˆ¶ç§",
                        "å¿«é€Ÿåˆ†äº«éœ€æ±‚",
                        "ç½‘ç»œå¸¦å®½æœ‰é™"
                    ]
                },
                "standard": {
                    "name": "æ ‡å‡†æ¨¡å¼",
                    "description": "å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦ï¼Œé€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯(1-10GB)",
                    "settings": {
                        "piece_size": "auto",
                        "max_concurrent_operations": "auto",
                        "cache_enabled": True,
                        "cache_size_mb": 256,
                        "max_scan_depth": 5,
                        "file_search_tolerance": 0.8,
                        "auto_create_output_dir": True,
                        "log_level": "INFO"
                    },
                    "recommended_for": [
                        "æ—¥å¸¸åˆ¶ç§éœ€æ±‚",
                        "ä¸­ç­‰å¤§å°æ–‡ä»¶",
                        "å¹³è¡¡æ€§èƒ½è¦æ±‚"
                    ]
                },
                "quality": {
                    "name": "é«˜è´¨é‡æ¨¡å¼",
                    "description": "é€‚ç”¨äºå¤§æ–‡ä»¶(>10GB)ï¼Œä¼˜å…ˆåˆ¶ç§è´¨é‡",
                    "settings": {
                        "piece_size": "2m",
                        "max_concurrent_operations": "auto_half",
                        "cache_enabled": True,
                        "cache_size_mb": 512,
                        "max_scan_depth": 10,
                        "file_search_tolerance": 0.9,
                        "auto_create_output_dir": True,
                        "log_level": "DEBUG"
                    },
                    "recommended_for": [
                        "å¤§æ–‡ä»¶åˆ¶ç§",
                        "é«˜è´¨é‡è¦æ±‚",
                        "æœåŠ¡å™¨ç¯å¢ƒ"
                    ]
                }
            },
            "preset_metadata": {
                "version": "1.0",
                "created_time": time.time(),
                "description": "Torrent Maker é»˜è®¤é¢„è®¾é…ç½®"
            }
        }
        
        with open(presets_path, 'w', encoding='utf-8') as f:
            json.dump(default_presets, f, ensure_ascii=False, indent=2)

    def _load_settings(self) -> Dict[str, Any]:
        try:
            with open(self.settings_path, 'r', encoding='utf-8') as f:
                settings = json.load(f)
            
            for key in ['resource_folder', 'output_folder']:
                if key in settings:
                    settings[key] = os.path.expanduser(settings[key])
                    
            merged_settings = self.DEFAULT_SETTINGS.copy()
            merged_settings.update(settings)
            return merged_settings
            
        except (FileNotFoundError, json.JSONDecodeError):
            return self.DEFAULT_SETTINGS.copy()

    def _load_trackers(self) -> List[str]:
        try:
            with open(self.trackers_path, 'r', encoding='utf-8') as f:
                trackers = []
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        # æ¸…ç†URLæ ¼å¼ï¼Œç§»é™¤å¯èƒ½çš„åå¼•å·å’Œå…¶ä»–éæ³•å­—ç¬¦
                        cleaned_line = line.strip('`"\'')
                        # åŸºæœ¬URLæ ¼å¼éªŒè¯
                        if cleaned_line.startswith(('http://', 'https://', 'udp://')):
                            trackers.append(cleaned_line)
                        else:
                            print(f"âš ï¸  è·³è¿‡æ— æ•ˆçš„tracker URL: {line}")
                return trackers if trackers else self.DEFAULT_TRACKERS.copy()
        except FileNotFoundError:
            return self.DEFAULT_TRACKERS.copy()

    def _validate_config(self) -> None:
        numeric_configs = {
            'file_search_tolerance': (0, 100),
            'max_search_results': (1, 100),
            'cache_duration': (60, 86400),
            'max_concurrent_operations': (1, 20)
        }
        
        for key, (min_val, max_val) in numeric_configs.items():
            if key in self.settings:
                value = self.settings[key]
                if not isinstance(value, (int, float)) or not (min_val <= value <= max_val):
                    self.settings[key] = self.DEFAULT_SETTINGS[key]

    def get_resource_folder(self) -> str:
        return os.path.abspath(self.settings.get('resource_folder', os.path.expanduser("~/Downloads")))

    def get_output_folder(self) -> str:
        output_path = self.settings.get('output_folder', os.path.expanduser("~/Desktop/torrents"))
        return os.path.abspath(output_path)

    def get_trackers(self) -> List[str]:
        return self.trackers.copy()

    def save_settings(self):
        try:
            with open(self.settings_path, 'w', encoding='utf-8') as f:
                json.dump(self.settings, f, ensure_ascii=False, indent=4)
        except Exception as e:
            print(f"ä¿å­˜è®¾ç½®æ—¶å‡ºé”™: {e}")

    def save_trackers(self):
        try:
            with open(self.trackers_path, 'w', encoding='utf-8') as f:
                f.write("# BitTorrent Tracker åˆ—è¡¨\n")
                f.write("# æ¯è¡Œä¸€ä¸ª tracker URLï¼Œä»¥ # å¼€å¤´çš„è¡Œä¸ºæ³¨é‡Š\n\n")
                for tracker in self.trackers:
                    f.write(f"{tracker}\n")
        except Exception as e:
            print(f"ä¿å­˜ tracker æ—¶å‡ºé”™: {e}")

    def set_resource_folder(self, path: str) -> bool:
        """è®¾ç½®èµ„æºæ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¹¶éªŒè¯è·¯å¾„æœ‰æ•ˆæ€§"""
        try:
            expanded_path = os.path.expanduser(path)
            expanded_path = os.path.abspath(expanded_path)

            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(expanded_path):
                print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {expanded_path}")
                return False

            # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
            if not os.path.isdir(expanded_path):
                print(f"âŒ è·¯å¾„ä¸æ˜¯ç›®å½•: {expanded_path}")
                return False

            self.settings['resource_folder'] = expanded_path
            self.save_settings()
            print(f"âœ… èµ„æºæ–‡ä»¶å¤¹å·²è®¾ç½®ä¸º: {expanded_path}")
            return True

        except Exception as e:
            print(f"âŒ è®¾ç½®èµ„æºæ–‡ä»¶å¤¹å¤±è´¥: {e}")
            return False

    def set_output_folder(self, path: str):
        expanded_path = os.path.expanduser(path)
        self.settings['output_folder'] = expanded_path
        self.save_settings()

    def add_tracker(self, tracker_url: str):
        if tracker_url not in self.trackers:
            self.trackers.append(tracker_url)
            self.save_trackers()
            return True
        return False

    def remove_tracker(self, tracker_url: str):
        if tracker_url in self.trackers:
            self.trackers.remove(tracker_url)
            self.save_trackers()
            return True
        return False

    def get_setting(self, key: str, default=None):
        """è·å–å•ä¸ªè®¾ç½®é¡¹

        Args:
            key: è®¾ç½®é¡¹é”®å
            default: é»˜è®¤å€¼

        Returns:
            è®¾ç½®é¡¹çš„å€¼
        """
        return self.settings.get(key, default)

    def set_setting(self, key: str, value):
        """è®¾ç½®å•ä¸ªé…ç½®é¡¹

        Args:
            key: è®¾ç½®é¡¹é”®å
            value: è®¾ç½®é¡¹çš„å€¼

        Returns:
            è®¾ç½®æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        try:
            self.settings[key] = value
            self.save_settings()
            return True
        except Exception as e:
            print(f"è®¾ç½®é…ç½®é¡¹å¤±è´¥: {e}")
            return False

    # ================== é¢„è®¾æ¨¡å¼ç®¡ç† ==================
    
    def _load_presets(self) -> Dict[str, Any]:
        """åŠ è½½é¢„è®¾é…ç½®"""
        presets_path = os.path.join(self.config_dir, "presets.json")
        try:
            with open(presets_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"âš ï¸ åŠ è½½é¢„è®¾é…ç½®å¤±è´¥: {e}")
            return {"presets": {}, "preset_metadata": {}}
    
    def get_available_presets(self) -> Dict[str, Dict[str, Any]]:
        """è·å–å¯ç”¨çš„é¢„è®¾æ¨¡å¼"""
        presets_data = self._load_presets()
        return presets_data.get("presets", {})
    
    def get_preset_info(self, preset_name: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šé¢„è®¾çš„è¯¦ç»†ä¿¡æ¯"""
        presets = self.get_available_presets()
        return presets.get(preset_name, {})
    
    def apply_preset(self, preset_name: str) -> bool:
        """åº”ç”¨é¢„è®¾é…ç½®"""
        try:
            preset_info = self.get_preset_info(preset_name)
            if not preset_info:
                print(f"âŒ é¢„è®¾ '{preset_name}' ä¸å­˜åœ¨")
                return False
            
            preset_settings = preset_info.get("settings", {})
            if not preset_settings:
                print(f"âŒ é¢„è®¾ '{preset_name}' æ²¡æœ‰æœ‰æ•ˆçš„è®¾ç½®")
                return False
            
            # å¤„ç†ç‰¹æ®Šçš„çº¿ç¨‹æ•°é…ç½®
            if "max_concurrent_operations" in preset_settings:
                thread_config = preset_settings["max_concurrent_operations"]
                if isinstance(thread_config, str):
                    import multiprocessing
                    cpu_count = multiprocessing.cpu_count()
                    
                    if thread_config == "auto":
                        preset_settings["max_concurrent_operations"] = cpu_count
                    elif thread_config == "auto_x2":
                        preset_settings["max_concurrent_operations"] = cpu_count * 2
                    elif thread_config == "auto_half":
                        preset_settings["max_concurrent_operations"] = max(1, cpu_count // 2)
            
            # åº”ç”¨é¢„è®¾è®¾ç½®
            for key, value in preset_settings.items():
                self.settings[key] = value
            
            self.save_settings()
            print(f"âœ… å·²åº”ç”¨é¢„è®¾: {preset_info.get('name', preset_name)}")
            print(f"   {preset_info.get('description', '')}")
            return True
            
        except Exception as e:
            print(f"âŒ åº”ç”¨é¢„è®¾å¤±è´¥: {e}")
            return False
    
    def save_custom_preset(self, preset_name: str, description: str = "") -> bool:
        """ä¿å­˜å½“å‰é…ç½®ä¸ºè‡ªå®šä¹‰é¢„è®¾"""
        try:
            presets_path = os.path.join(self.config_dir, "presets.json")
            presets_data = self._load_presets()
            
            # åˆ›å»ºè‡ªå®šä¹‰é¢„è®¾
            custom_preset = {
                "name": preset_name,
                "description": description or f"ç”¨æˆ·è‡ªå®šä¹‰é¢„è®¾: {preset_name}",
                "settings": self.settings.copy(),
                "user_defined": True,
                "created_time": time.time(),
                "recommended_for": ["ç”¨æˆ·è‡ªå®šä¹‰é…ç½®"]
            }
            
            # æ·»åŠ åˆ°é¢„è®¾åˆ—è¡¨
            if "presets" not in presets_data:
                presets_data["presets"] = {}
            
            presets_data["presets"][preset_name] = custom_preset
            
            # ä¿å­˜é¢„è®¾æ–‡ä»¶
            with open(presets_path, 'w', encoding='utf-8') as f:
                json.dump(presets_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… è‡ªå®šä¹‰é¢„è®¾ '{preset_name}' å·²ä¿å­˜")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è‡ªå®šä¹‰é¢„è®¾å¤±è´¥: {e}")
            return False
    
    def delete_custom_preset(self, preset_name: str) -> bool:
        """åˆ é™¤è‡ªå®šä¹‰é¢„è®¾"""
        try:
            presets_path = os.path.join(self.config_dir, "presets.json")
            presets_data = self._load_presets()
            
            presets = presets_data.get("presets", {})
            if preset_name not in presets:
                print(f"âŒ é¢„è®¾ '{preset_name}' ä¸å­˜åœ¨")
                return False
            
            preset_info = presets[preset_name]
            if not preset_info.get("user_defined", False):
                print(f"âŒ æ— æ³•åˆ é™¤ç³»ç»Ÿé¢„è®¾ '{preset_name}'")
                return False
            
            del presets[preset_name]
            
            # ä¿å­˜æ›´æ–°åçš„é¢„è®¾æ–‡ä»¶
            with open(presets_path, 'w', encoding='utf-8') as f:
                json.dump(presets_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… è‡ªå®šä¹‰é¢„è®¾ '{preset_name}' å·²åˆ é™¤")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ é™¤è‡ªå®šä¹‰é¢„è®¾å¤±è´¥: {e}")
            return False
    
    def auto_detect_preset(self, file_size_bytes: int = 0) -> str:
        """æ ¹æ®æ–‡ä»¶å¤§å°è‡ªåŠ¨æ£€æµ‹æ¨èçš„é¢„è®¾æ¨¡å¼"""
        try:
            presets_data = self._load_presets()
            metadata = presets_data.get("preset_metadata", {})
            auto_detect_rules = metadata.get("auto_detect_rules", {})
            
            if not auto_detect_rules:
                return "standard"  # é»˜è®¤è¿”å›æ ‡å‡†æ¨¡å¼
            
            thresholds = auto_detect_rules.get("file_size_thresholds", {})
            mapping = auto_detect_rules.get("auto_preset_mapping", {})
            
            # æ ¹æ®æ–‡ä»¶å¤§å°ç¡®å®šç±»åˆ«
            if file_size_bytes < thresholds.get("small", 1073741824):  # < 1GB
                return mapping.get("small", "fast")
            elif file_size_bytes < thresholds.get("medium", 10737418240):  # < 10GB
                return mapping.get("medium", "standard")
            else:  # >= 10GB
                return mapping.get("large", "quality")
                
        except Exception as e:
            print(f"âš ï¸ è‡ªåŠ¨æ£€æµ‹é¢„è®¾å¤±è´¥: {e}")
            return "standard"
    
    def display_presets_menu(self) -> None:
        """æ˜¾ç¤ºé¢„è®¾æ¨¡å¼èœå•"""
        presets = self.get_available_presets()
        if not presets:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„é¢„è®¾æ¨¡å¼")
            return
        
        print("\n" + "="*60)
        print("ğŸ›ï¸  é…ç½®é¢„è®¾æ¨¡å¼")
        print("="*60)
        
        for i, (preset_key, preset_info) in enumerate(presets.items(), 1):
            name = preset_info.get("name", preset_key)
            description = preset_info.get("description", "")
            is_custom = preset_info.get("user_defined", False)
            custom_tag = " [è‡ªå®šä¹‰]" if is_custom else ""
            
            print(f"{i}. {name}{custom_tag}")
            print(f"   {description}")
            
            # æ˜¾ç¤ºæ¨èåœºæ™¯
            recommended = preset_info.get("recommended_for", [])
            if recommended:
                print(f"   ğŸ’¡ æ¨èç”¨äº: {', '.join(recommended)}")
            print()
        
        print(f"{len(presets) + 1}. ä¿å­˜å½“å‰é…ç½®ä¸ºè‡ªå®šä¹‰é¢„è®¾")
        print(f"{len(presets) + 2}. åˆ é™¤è‡ªå®šä¹‰é¢„è®¾")
        print(f"{len(presets) + 3}. è¿”å›ä¸Šçº§èœå•")
        print("="*60)


# ================== æ™ºèƒ½ç´¢å¼•ç¼“å­˜ ==================
class SmartIndexCache:
    """æ™ºèƒ½ç´¢å¼•ç¼“å­˜ - v1.5.1 æœç´¢ä¼˜åŒ–"""

    def __init__(self, cache_duration: int = 3600):
        self.cache_duration = cache_duration
        self._word_index: Dict[str, Set[str]] = {}  # word -> set of folder paths
        self._folder_words: Dict[str, Set[str]] = {}  # folder_path -> set of words
        self._last_update = 0
        self._lock = threading.Lock()

    def build_index(self, folders: List[Path], normalize_func) -> None:
        """æ„å»ºæ™ºèƒ½ç´¢å¼•"""
        with self._lock:
            self._word_index.clear()
            self._folder_words.clear()

            for folder in folders:
                folder_path = str(folder)
                normalized_name = normalize_func(folder.name)
                words = set(normalized_name.split())

                self._folder_words[folder_path] = words

                for word in words:
                    if word not in self._word_index:
                        self._word_index[word] = set()
                    self._word_index[word].add(folder_path)

            self._last_update = time.time()

    def get_candidate_folders(self, search_words: Set[str]) -> Set[str]:
        """æ ¹æ®æœç´¢è¯è·å–å€™é€‰æ–‡ä»¶å¤¹"""
        if not search_words:
            return set()

        candidate_sets = []
        for word in search_words:
            if word in self._word_index:
                candidate_sets.append(self._word_index[word])

        if not candidate_sets:
            return set()

        # è¿”å›åŒ…å«ä»»æ„æœç´¢è¯çš„æ–‡ä»¶å¤¹
        return set.union(*candidate_sets)

    def is_expired(self) -> bool:
        """æ£€æŸ¥ç´¢å¼•æ˜¯å¦è¿‡æœŸ"""
        return time.time() - self._last_update > self.cache_duration


# ================== å†…å­˜åˆ†æå™¨ ==================
class MemoryAnalyzer:
    """å†…å­˜åˆ†æå™¨ - æ·±åº¦å†…å­˜ä½¿ç”¨åˆ†æ"""

    @staticmethod
    def get_object_memory_usage() -> Dict[str, Any]:
        """è·å–å¯¹è±¡å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        import gc
        import sys

        # ç»Ÿè®¡ä¸åŒç±»å‹å¯¹è±¡çš„æ•°é‡
        type_counts = {}
        total_objects = 0

        for obj in gc.get_objects():
            obj_type = type(obj).__name__
            type_counts[obj_type] = type_counts.get(obj_type, 0) + 1
            total_objects += 1

        # è·å–æœ€å å†…å­˜çš„å¯¹è±¡ç±»å‹
        top_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:10]

        return {
            'total_objects': total_objects,
            'top_memory_types': top_types,
            'gc_stats': {
                'collections': gc.get_stats(),
                'garbage_count': len(gc.garbage)
            }
        }

    @staticmethod
    def analyze_memory_leaks() -> Dict[str, Any]:
        """åˆ†ææ½œåœ¨çš„å†…å­˜æ³„æ¼"""
        import gc
        import weakref

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        collected = gc.collect()

        # æ£€æŸ¥å¾ªç¯å¼•ç”¨
        referrers_count = {}
        for obj in gc.get_objects():
            referrers = gc.get_referrers(obj)
            ref_count = len(referrers)
            if ref_count > 10:  # è¢«å¼•ç”¨æ¬¡æ•°è¿‡å¤šçš„å¯¹è±¡
                obj_type = type(obj).__name__
                referrers_count[obj_type] = referrers_count.get(obj_type, 0) + 1

        return {
            'collected_objects': collected,
            'high_reference_objects': referrers_count,
            'unreachable_objects': len(gc.garbage)
        }


# ================== å¢å¼ºå†…å­˜ç®¡ç†å™¨ ==================
class MemoryManager:
    """å†…å­˜ç®¡ç†å™¨ - v1.5.1 æ·±åº¦å†…å­˜ä¼˜åŒ–"""

    def __init__(self, max_memory_mb: int = 512):
        self.max_memory_mb = max_memory_mb
        self.max_memory_bytes = max_memory_mb * 1024 * 1024
        self._memory_pools: Dict[str, List[Any]] = {}
        self._object_cache: Dict[str, Any] = {}
        self._memory_history: List[Dict[str, float]] = []
        self._lock = threading.Lock()
        self._analyzer = MemoryAnalyzer()
        self._cleanup_threshold = 0.8  # 80% å†…å­˜ä½¿ç”¨æ—¶è§¦å‘æ¸…ç†

    def get_memory_usage(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            system_memory = psutil.virtual_memory()

            usage_data = {
                'rss_mb': memory_info.rss / (1024 * 1024),
                'vms_mb': memory_info.vms / (1024 * 1024),
                'percent': process.memory_percent(),
                'available_mb': system_memory.available / (1024 * 1024),
                'system_total_mb': system_memory.total / (1024 * 1024),
                'system_used_percent': system_memory.percent,
                'swap_mb': getattr(memory_info, 'swap', 0) / (1024 * 1024)
            }

            # è®°å½•å†…å­˜å†å²
            self._record_memory_history(usage_data)

            return usage_data

        except ImportError:
            # å›é€€åˆ°ç®€å•çš„å†…å­˜ä¼°ç®—
            import resource
            try:
                # å°è¯•ä½¿ç”¨ resource æ¨¡å—
                usage = resource.getrusage(resource.RUSAGE_SELF)
                # ä¿®å¤ macOS å†…å­˜è®¡ç®—é”™è¯¯ï¼šmacOS è¿”å›çš„æ˜¯å­—èŠ‚ï¼Œä¸éœ€è¦é™¤ä»¥1024
                import platform
                if platform.system() == 'Darwin':  # macOS
                    rss_mb = usage.ru_maxrss / (1024 * 1024)  # å­—èŠ‚è½¬MB
                else:  # Linux
                    rss_mb = usage.ru_maxrss / 1024  # KBè½¬MB

                return {
                    'rss_mb': rss_mb,
                    'vms_mb': 0,
                    'percent': 0,
                    'available_mb': 1024,
                    'system_total_mb': 0,
                    'system_used_percent': 0,
                    'swap_mb': 0
                }
            except:
                return {
                    'rss_mb': 0,
                    'vms_mb': 0,
                    'percent': 0,
                    'available_mb': 1024,
                    'system_total_mb': 0,
                    'system_used_percent': 0,
                    'swap_mb': 0
                }

    def _record_memory_history(self, usage_data: Dict[str, float]) -> None:
        """è®°å½•å†…å­˜ä½¿ç”¨å†å²"""
        with self._lock:
            self._memory_history.append({
                'timestamp': time.time(),
                'rss_mb': usage_data['rss_mb'],
                'percent': usage_data['percent']
            })

            # åªä¿ç•™æœ€è¿‘ 100 æ¡è®°å½•
            if len(self._memory_history) > 100:
                self._memory_history = self._memory_history[-100:]

    def should_cleanup(self) -> bool:
        """æ™ºèƒ½æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†å†…å­˜"""
        memory_info = self.get_memory_usage()
        current_usage = memory_info['rss_mb']

        # å¤šé‡æ£€æŸ¥æ¡ä»¶
        conditions = [
            current_usage > self.max_memory_mb,  # è¶…è¿‡è®¾å®šé™åˆ¶
            current_usage > self.max_memory_mb * self._cleanup_threshold,  # è¶…è¿‡é˜ˆå€¼
            memory_info.get('system_used_percent', 0) > 85,  # ç³»ç»Ÿå†…å­˜ä½¿ç”¨è¿‡é«˜
            self._is_memory_growing_rapidly()  # å†…å­˜å¢é•¿è¿‡å¿«
        ]

        return any(conditions)

    def _is_memory_growing_rapidly(self) -> bool:
        """æ£€æŸ¥å†…å­˜æ˜¯å¦å¢é•¿è¿‡å¿«"""
        if len(self._memory_history) < 5:
            return False

        recent_usage = [entry['rss_mb'] for entry in self._memory_history[-5:]]
        if len(recent_usage) < 2:
            return False

        # è®¡ç®—å†…å­˜å¢é•¿ç‡
        growth_rate = (recent_usage[-1] - recent_usage[0]) / len(recent_usage)
        return growth_rate > 10  # æ¯æ¬¡æµ‹é‡å¢é•¿è¶…è¿‡ 10MB

    def cleanup_if_needed(self, force: bool = False) -> Dict[str, int]:
        """æ™ºèƒ½å†…å­˜æ¸…ç†"""
        if force or self.should_cleanup():
            return self.cleanup_memory()
        return {'cleaned_items': 0, 'freed_mb': 0}

    def cleanup_memory(self) -> Dict[str, int]:
        """æ·±åº¦å†…å­˜æ¸…ç†"""
        cleaned_stats = {
            'memory_pools_cleaned': 0,
            'object_cache_cleaned': 0,
            'gc_collected': 0,
            'freed_mb': 0
        }

        # è®°å½•æ¸…ç†å‰çš„å†…å­˜ä½¿ç”¨
        before_memory = self.get_memory_usage()['rss_mb']

        with self._lock:
            # æ¸…ç†å†…å­˜æ± 
            for pool_name in list(self._memory_pools.keys()):
                pool = self._memory_pools[pool_name]
                if len(pool) > 10:  # ä¿ç•™æœ€è¿‘çš„ 10 ä¸ªé¡¹ç›®
                    removed = len(pool) - 10
                    self._memory_pools[pool_name] = pool[-10:]
                    cleaned_stats['memory_pools_cleaned'] += removed

            # æ¸…ç†å¯¹è±¡ç¼“å­˜
            if len(self._object_cache) > 50:
                # ä¿ç•™æœ€è¿‘ä½¿ç”¨çš„ 50 ä¸ªå¯¹è±¡
                cache_items = list(self._object_cache.items())
                self._object_cache = dict(cache_items[-50:])
                cleaned_stats['object_cache_cleaned'] = len(cache_items) - 50

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        collected = gc.collect()
        cleaned_stats['gc_collected'] = collected

        # è®¡ç®—é‡Šæ”¾çš„å†…å­˜
        after_memory = self.get_memory_usage()['rss_mb']
        cleaned_stats['freed_mb'] = max(0, before_memory - after_memory)

        return cleaned_stats

    def get_memory_analysis(self) -> Dict[str, Any]:
        """è·å–å†…å­˜åˆ†ææŠ¥å‘Š"""
        current_usage = self.get_memory_usage()
        object_analysis = self._analyzer.get_object_memory_usage()
        leak_analysis = self._analyzer.analyze_memory_leaks()

        # è®¡ç®—å†…å­˜è¶‹åŠ¿
        memory_trend = self._calculate_memory_trend()

        return {
            'current_usage': current_usage,
            'object_analysis': object_analysis,
            'leak_analysis': leak_analysis,
            'memory_trend': memory_trend,
            'pool_stats': {
                'total_pools': len(self._memory_pools),
                'total_cached_objects': sum(len(pool) for pool in self._memory_pools.values()),
                'object_cache_size': len(self._object_cache)
            },
            'recommendations': self._generate_memory_recommendations(current_usage)
        }

    def _calculate_memory_trend(self) -> Dict[str, Any]:
        """è®¡ç®—å†…å­˜ä½¿ç”¨è¶‹åŠ¿"""
        if len(self._memory_history) < 3:
            return {'trend': 'insufficient_data', 'growth_rate': 0}

        recent_usage = [entry['rss_mb'] for entry in self._memory_history[-10:]]

        # ç®€å•çº¿æ€§è¶‹åŠ¿è®¡ç®—
        if len(recent_usage) >= 2:
            growth_rate = (recent_usage[-1] - recent_usage[0]) / len(recent_usage)

            if growth_rate > 5:
                trend = 'increasing_rapidly'
            elif growth_rate > 1:
                trend = 'increasing'
            elif growth_rate < -1:
                trend = 'decreasing'
            else:
                trend = 'stable'
        else:
            trend = 'stable'
            growth_rate = 0

        return {
            'trend': trend,
            'growth_rate': growth_rate,
            'history_points': len(self._memory_history)
        }

    def _generate_memory_recommendations(self, usage: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå†…å­˜ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        rss_mb = usage.get('rss_mb', 0)

        if rss_mb > self.max_memory_mb * 0.9:
            recommendations.append("å†…å­˜ä½¿ç”¨æ¥è¿‘é™åˆ¶ï¼Œå»ºè®®ç«‹å³æ¸…ç†ç¼“å­˜")
        elif rss_mb > self.max_memory_mb * 0.7:
            recommendations.append("å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œå»ºè®®å®šæœŸæ¸…ç†")

        if usage.get('system_used_percent', 0) > 80:
            recommendations.append("ç³»ç»Ÿå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå»ºè®®å‡å°‘å¹¶å‘æ“ä½œ")

        if self._is_memory_growing_rapidly():
            recommendations.append("æ£€æµ‹åˆ°å†…å­˜å¿«é€Ÿå¢é•¿ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼")

        if len(self._memory_pools) > 20:
            recommendations.append("å†…å­˜æ± è¿‡å¤šï¼Œå»ºè®®åˆå¹¶æˆ–æ¸…ç†")

        if not recommendations:
            recommendations.append("å†…å­˜ä½¿ç”¨æ­£å¸¸ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")

        return recommendations


# ================== çœŸæ­£çš„å¼‚æ­¥ I/O å¤„ç†å™¨ ==================
class AsyncIOProcessor:
    """çœŸæ­£çš„å¼‚æ­¥ I/O å¤„ç†å™¨ - v1.5.1 æ·±åº¦å¼‚æ­¥ä¼˜åŒ–"""

    def __init__(self, max_concurrent: int = 10):
        self.max_concurrent = max_concurrent
        self.semaphore = threading.Semaphore(max_concurrent)
        self._loop = None
        self._executor = None

    def _get_event_loop(self):
        """è·å–æˆ–åˆ›å»ºäº‹ä»¶å¾ªç¯"""
        try:
            import asyncio
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            return loop
        except ImportError:
            return None

    def _get_executor(self):
        """è·å–çº¿ç¨‹æ± æ‰§è¡Œå™¨"""
        if self._executor is None:
            self._executor = ThreadPoolExecutor(max_workers=self.max_concurrent)
        return self._executor

    async def async_directory_scan_native(self, base_path: Path, max_depth: int = 3) -> List[Path]:
        """åŸç”Ÿå¼‚æ­¥ç›®å½•æ‰«æ"""
        import asyncio

        folders = []
        semaphore = asyncio.Semaphore(self.max_concurrent)

        async def scan_directory(path: Path, depth: int):
            if depth >= max_depth:
                return

            async with semaphore:
                try:
                    # å¼‚æ­¥æ‰«æç›®å½•
                    entries = await asyncio.get_event_loop().run_in_executor(
                        self._get_executor(),
                        lambda: list(os.scandir(path))
                    )

                    subdirs = []
                    for entry in entries:
                        if entry.is_dir(follow_symlinks=False):
                            folder_path = Path(entry.path)
                            folders.append(folder_path)
                            if depth + 1 < max_depth:
                                subdirs.append(folder_path)

                    # å¹¶å‘æ‰«æå­ç›®å½•
                    if subdirs:
                        tasks = [scan_directory(subdir, depth + 1) for subdir in subdirs]
                        await asyncio.gather(*tasks, return_exceptions=True)

                except (PermissionError, OSError):
                    pass

        await scan_directory(base_path, 0)
        return folders

    def async_directory_scan(self, base_path: Path, max_depth: int = 3) -> List[Path]:
        """å¼‚æ­¥ç›®å½•æ‰«æ - å…¼å®¹æ¥å£"""
        loop = self._get_event_loop()
        if loop is None:
            # å›é€€åˆ°çº¿ç¨‹æ± å®ç°
            return self._async_directory_scan_threaded(base_path, max_depth)

        try:
            import asyncio
            if loop.is_running():
                # å¦‚æœå¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨ run_in_executor
                future = asyncio.ensure_future(self.async_directory_scan_native(base_path, max_depth))
                return asyncio.run_coroutine_threadsafe(future, loop).result(timeout=30)
            else:
                # å¦‚æœå¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥è¿è¡Œ
                return loop.run_until_complete(self.async_directory_scan_native(base_path, max_depth))
        except Exception:
            # å¼‚å¸¸æ—¶å›é€€åˆ°çº¿ç¨‹æ± å®ç°
            return self._async_directory_scan_threaded(base_path, max_depth)

    def _async_directory_scan_threaded(self, base_path: Path, max_depth: int = 3) -> List[Path]:
        """çº¿ç¨‹æ± ç‰ˆæœ¬çš„å¼‚æ­¥ç›®å½•æ‰«æ"""
        import queue
        import threading

        result_queue = queue.Queue()
        scan_queue = queue.Queue()
        scan_queue.put((base_path, 0))

        def worker():
            while True:
                try:
                    path, depth = scan_queue.get(timeout=1)
                    if depth >= max_depth:
                        scan_queue.task_done()
                        continue

                    try:
                        with os.scandir(path) as entries:
                            for entry in entries:
                                if entry.is_dir(follow_symlinks=False):
                                    folder_path = Path(entry.path)
                                    result_queue.put(folder_path)
                                    if depth + 1 < max_depth:
                                        scan_queue.put((folder_path, depth + 1))
                    except (PermissionError, OSError):
                        pass

                    scan_queue.task_done()
                except queue.Empty:
                    break

        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        for _ in range(min(4, self.max_concurrent)):
            t = threading.Thread(target=worker)
            t.daemon = True
            t.start()
            threads.append(t)

        # ç­‰å¾…å®Œæˆ
        scan_queue.join()

        # æ”¶é›†ç»“æœ
        folders = []
        while not result_queue.empty():
            folders.append(result_queue.get())

        return folders

    async def async_file_operations_native(self, operations: List[Tuple[str, Path, Any]]) -> List[Any]:
        """åŸç”Ÿå¼‚æ­¥æ–‡ä»¶æ“ä½œ"""
        import asyncio

        semaphore = asyncio.Semaphore(self.max_concurrent)

        async def execute_operation(op_type: str, path: Path, params: Any) -> Any:
            async with semaphore:
                try:
                    # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå™¨å¤„ç† I/O æ“ä½œ
                    loop = asyncio.get_event_loop()

                    if op_type == 'size':
                        return await loop.run_in_executor(
                            self._get_executor(),
                            lambda: path.stat().st_size
                        )
                    elif op_type == 'exists':
                        return await loop.run_in_executor(
                            self._get_executor(),
                            lambda: path.exists()
                        )
                    elif op_type == 'mtime':
                        return await loop.run_in_executor(
                            self._get_executor(),
                            lambda: path.stat().st_mtime
                        )
                    elif op_type == 'hash':
                        return await self._async_calculate_hash(path, params or 'md5')
                    elif op_type == 'read':
                        return await self._async_read_file(path, params)
                    else:
                        return None
                except (OSError, IOError):
                    return None

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ“ä½œ
        tasks = [execute_operation(op_type, path, params) for op_type, path, params in operations]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        return [result if not isinstance(result, Exception) else None for result in results]

    async def _async_calculate_hash(self, file_path: Path, algorithm: str = 'md5') -> str:
        """å¼‚æ­¥è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        import hashlib
        import asyncio

        hash_obj = hashlib.new(algorithm)
        chunk_size = 64 * 1024  # 64KB chunks for async operations

        try:
            loop = asyncio.get_event_loop()

            # å¼‚æ­¥è¯»å–æ–‡ä»¶
            def read_chunk(f, size):
                return f.read(size)

            with open(file_path, 'rb') as f:
                while True:
                    chunk = await loop.run_in_executor(
                        self._get_executor(),
                        read_chunk, f, chunk_size
                    )

                    if not chunk:
                        break

                    hash_obj.update(chunk)

                    # è®©å‡ºæ§åˆ¶æƒï¼Œå…è®¸å…¶ä»–åç¨‹è¿è¡Œ
                    await asyncio.sleep(0)

            return hash_obj.hexdigest()

        except (OSError, IOError):
            return ""

    async def _async_read_file(self, file_path: Path, max_size: int = None) -> bytes:
        """å¼‚æ­¥è¯»å–æ–‡ä»¶"""
        import asyncio

        try:
            loop = asyncio.get_event_loop()

            def read_file():
                with open(file_path, 'rb') as f:
                    if max_size:
                        return f.read(max_size)
                    else:
                        return f.read()

            return await loop.run_in_executor(self._get_executor(), read_file)

        except (OSError, IOError):
            return b""

    def async_file_operations(self, operations: List[Tuple[str, Path, Any]]) -> List[Any]:
        """å¼‚æ­¥æ–‡ä»¶æ“ä½œ - å…¼å®¹æ¥å£"""
        loop = self._get_event_loop()
        if loop is None:
            # å›é€€åˆ°çº¿ç¨‹æ± å®ç°
            return self._async_file_operations_threaded(operations)

        try:
            import asyncio
            if loop.is_running():
                # å¦‚æœå¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨ run_in_executor
                future = asyncio.ensure_future(self.async_file_operations_native(operations))
                return asyncio.run_coroutine_threadsafe(future, loop).result(timeout=60)
            else:
                # å¦‚æœå¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥è¿è¡Œ
                return loop.run_until_complete(self.async_file_operations_native(operations))
        except Exception:
            # å¼‚å¸¸æ—¶å›é€€åˆ°çº¿ç¨‹æ± å®ç°
            return self._async_file_operations_threaded(operations)

    def _async_file_operations_threaded(self, operations: List[Tuple[str, Path, Any]]) -> List[Any]:
        """çº¿ç¨‹æ± ç‰ˆæœ¬çš„å¼‚æ­¥æ–‡ä»¶æ“ä½œ"""
        results = []

        def execute_operation(op_type: str, path: Path, params: Any) -> Any:
            with self.semaphore:
                try:
                    if op_type == 'size':
                        return path.stat().st_size
                    elif op_type == 'exists':
                        return path.exists()
                    elif op_type == 'mtime':
                        return path.stat().st_mtime
                    else:
                        return None
                except (OSError, IOError):
                    return None

        with ThreadPoolExecutor(max_workers=self.max_concurrent) as executor:
            futures = [
                executor.submit(execute_operation, op_type, path, params)
                for op_type, path, params in operations
            ]

            for future in as_completed(futures):
                results.append(future.result())

        return results

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self._executor:
            self._executor.shutdown(wait=True)
            self._executor = None


# ================== å¼‚æ­¥æ–‡ä»¶å¤„ç†å™¨ ==================
class AsyncFileProcessor:
    """å¼‚æ­¥æ–‡ä»¶å¤„ç†å™¨ - ä¸“é—¨å¤„ç†æ–‡ä»¶ç›¸å…³çš„å¼‚æ­¥æ“ä½œ"""

    def __init__(self, max_concurrent: int = 8, chunk_size: int = 64 * 1024):
        self.max_concurrent = max_concurrent
        self.chunk_size = chunk_size
        self.async_io = AsyncIOProcessor(max_concurrent)

    async def async_batch_file_stats(self, file_paths: List[Path]) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¼‚æ­¥è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        import asyncio

        semaphore = asyncio.Semaphore(self.max_concurrent)

        async def get_file_stats(file_path: Path) -> Dict[str, Any]:
            async with semaphore:
                try:
                    loop = asyncio.get_event_loop()

                    # å¼‚æ­¥è·å–æ–‡ä»¶çŠ¶æ€
                    stat_info = await loop.run_in_executor(
                        None, lambda: file_path.stat()
                    )

                    return {
                        'path': str(file_path),
                        'size': stat_info.st_size,
                        'mtime': stat_info.st_mtime,
                        'is_file': file_path.is_file(),
                        'exists': True
                    }
                except (OSError, IOError):
                    return {
                        'path': str(file_path),
                        'size': 0,
                        'mtime': 0,
                        'is_file': False,
                        'exists': False
                    }

        # å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡ä»¶
        tasks = [get_file_stats(path) for path in file_paths]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # è¿‡æ»¤å¼‚å¸¸ç»“æœ
        return [result for result in results if isinstance(result, dict)]

    async def async_directory_tree_scan(self, base_path: Path,
                                      max_depth: int = 3,
                                      include_files: bool = True) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰«æç›®å½•æ ‘"""
        import asyncio

        result = {
            'directories': [],
            'files': [],
            'total_size': 0,
            'file_count': 0,
            'dir_count': 0,
            'errors': []
        }

        semaphore = asyncio.Semaphore(self.max_concurrent)

        async def scan_directory(path: Path, depth: int):
            if depth >= max_depth:
                return

            async with semaphore:
                try:
                    loop = asyncio.get_event_loop()

                    # å¼‚æ­¥æ‰«æç›®å½•
                    entries = await loop.run_in_executor(
                        None, lambda: list(os.scandir(path))
                    )

                    subdirs = []
                    files = []

                    for entry in entries:
                        if entry.is_dir(follow_symlinks=False):
                            dir_path = Path(entry.path)
                            result['directories'].append(str(dir_path))
                            result['dir_count'] += 1

                            if depth + 1 < max_depth:
                                subdirs.append(dir_path)

                        elif entry.is_file(follow_symlinks=False) and include_files:
                            file_path = Path(entry.path)
                            try:
                                file_size = entry.stat().st_size
                                files.append({
                                    'path': str(file_path),
                                    'size': file_size
                                })
                                result['total_size'] += file_size
                                result['file_count'] += 1
                            except (OSError, IOError):
                                result['errors'].append(f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: {file_path}")

                    # æ‰¹é‡æ·»åŠ æ–‡ä»¶ä¿¡æ¯
                    if files:
                        result['files'].extend(files)

                    # å¹¶å‘æ‰«æå­ç›®å½•
                    if subdirs:
                        tasks = [scan_directory(subdir, depth + 1) for subdir in subdirs]
                        await asyncio.gather(*tasks, return_exceptions=True)

                except (PermissionError, OSError) as e:
                    result['errors'].append(f"æ‰«æç›®å½•å¤±è´¥ {path}: {e}")

        await scan_directory(base_path, 0)
        return result

    async def async_file_hash_batch(self, file_paths: List[Path],
                                  algorithm: str = 'md5',
                                  progress_callback=None) -> Dict[str, str]:
        """æ‰¹é‡å¼‚æ­¥è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        import asyncio
        import hashlib

        semaphore = asyncio.Semaphore(self.max_concurrent)
        results = {}
        completed = 0
        total = len(file_paths)

        async def calculate_hash(file_path: Path) -> Tuple[str, str]:
            nonlocal completed

            async with semaphore:
                try:
                    hash_obj = hashlib.new(algorithm)
                    loop = asyncio.get_event_loop()

                    def read_and_hash():
                        with open(file_path, 'rb') as f:
                            while chunk := f.read(self.chunk_size):
                                hash_obj.update(chunk)
                        return hash_obj.hexdigest()

                    file_hash = await loop.run_in_executor(None, read_and_hash)

                    completed += 1
                    if progress_callback:
                        progress_callback(completed / total, f"è®¡ç®—å“ˆå¸Œ: {file_path.name}")

                    return str(file_path), file_hash

                except (OSError, IOError):
                    completed += 1
                    return str(file_path), ""

        # å¹¶å‘è®¡ç®—æ‰€æœ‰æ–‡ä»¶å“ˆå¸Œ
        tasks = [calculate_hash(path) for path in file_paths]
        hash_results = await asyncio.gather(*tasks, return_exceptions=True)

        # æ•´ç†ç»“æœ
        for result in hash_results:
            if isinstance(result, tuple) and len(result) == 2:
                path, file_hash = result
                results[path] = file_hash

        return results

    def run_async_batch_file_stats(self, file_paths: List[Path]) -> List[Dict[str, Any]]:
        """è¿è¡Œæ‰¹é‡æ–‡ä»¶ç»Ÿè®¡ - åŒæ­¥æ¥å£"""
        loop = self.async_io._get_event_loop()
        if loop is None:
            # å›é€€åˆ°åŒæ­¥å®ç°
            return self._sync_batch_file_stats(file_paths)

        try:
            import asyncio
            if loop.is_running():
                future = asyncio.ensure_future(self.async_batch_file_stats(file_paths))
                return asyncio.run_coroutine_threadsafe(future, loop).result(timeout=60)
            else:
                return loop.run_until_complete(self.async_batch_file_stats(file_paths))
        except Exception:
            return self._sync_batch_file_stats(file_paths)

    def _sync_batch_file_stats(self, file_paths: List[Path]) -> List[Dict[str, Any]]:
        """åŒæ­¥ç‰ˆæœ¬çš„æ‰¹é‡æ–‡ä»¶ç»Ÿè®¡"""
        results = []
        for file_path in file_paths:
            try:
                stat_info = file_path.stat()
                results.append({
                    'path': str(file_path),
                    'size': stat_info.st_size,
                    'mtime': stat_info.st_mtime,
                    'is_file': file_path.is_file(),
                    'exists': True
                })
            except (OSError, IOError):
                results.append({
                    'path': str(file_path),
                    'size': 0,
                    'mtime': 0,
                    'is_file': False,
                    'exists': False
                })
        return results


# ================== å†…å­˜æ„ŸçŸ¥æµå¼å¤„ç†å™¨ ==================
class StreamFileProcessor:
    """å†…å­˜æ„ŸçŸ¥æµå¼æ–‡ä»¶å¤„ç†å™¨ - æ™ºèƒ½å¤„ç†å¤§æ–‡ä»¶é¿å…å†…å­˜æº¢å‡º"""

    def __init__(self, chunk_size: int = 1024 * 1024, memory_manager: 'MemoryManager' = None):
        self.base_chunk_size = chunk_size
        self.memory_manager = memory_manager
        self._adaptive_chunk_size = chunk_size
        self._processed_bytes = 0

    def _get_adaptive_chunk_size(self) -> int:
        """æ ¹æ®å†…å­˜ä½¿ç”¨æƒ…å†µè‡ªé€‚åº”è°ƒæ•´å—å¤§å°"""
        if not self.memory_manager:
            return self.base_chunk_size

        memory_info = self.memory_manager.get_memory_usage()
        memory_usage_percent = memory_info.get('rss_mb', 0) / self.memory_manager.max_memory_mb

        if memory_usage_percent > 0.8:
            # å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå‡å°å—å¤§å°
            self._adaptive_chunk_size = max(64 * 1024, self.base_chunk_size // 4)
        elif memory_usage_percent > 0.6:
            # å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œé€‚åº¦å‡å°å—å¤§å°
            self._adaptive_chunk_size = max(256 * 1024, self.base_chunk_size // 2)
        else:
            # å†…å­˜ä½¿ç”¨æ­£å¸¸ï¼Œä½¿ç”¨æ ‡å‡†å—å¤§å°
            self._adaptive_chunk_size = self.base_chunk_size

        return self._adaptive_chunk_size

    def calculate_file_hash(self, file_path: Path, algorithm: str = 'md5',
                          progress_callback=None) -> str:
        """å†…å­˜ä¼˜åŒ–çš„æµå¼æ–‡ä»¶å“ˆå¸Œè®¡ç®—"""
        import hashlib

        hash_obj = hashlib.new(algorithm)
        processed_bytes = 0

        try:
            file_size = file_path.stat().st_size

            with open(file_path, 'rb') as f:
                while True:
                    # åŠ¨æ€è°ƒæ•´å—å¤§å°
                    chunk_size = self._get_adaptive_chunk_size()
                    chunk = f.read(chunk_size)

                    if not chunk:
                        break

                    hash_obj.update(chunk)
                    processed_bytes += len(chunk)

                    # å®šæœŸæ£€æŸ¥å†…å­˜å¹¶æ¸…ç†
                    if processed_bytes % (10 * 1024 * 1024) == 0:  # æ¯ 10MB æ£€æŸ¥ä¸€æ¬¡
                        if self.memory_manager and self.memory_manager.should_cleanup():
                            self.memory_manager.cleanup_if_needed()

                    # è¿›åº¦å›è°ƒ
                    if progress_callback and file_size > 0:
                        progress = processed_bytes / file_size
                        progress_callback(progress)

            return hash_obj.hexdigest()

        except (OSError, IOError) as e:
            logger.warning(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: {file_path}, é”™è¯¯: {e}")
            return ""

    def get_file_size_stream(self, file_path: Path) -> int:
        """å®‰å…¨è·å–æ–‡ä»¶å¤§å°"""
        try:
            return file_path.stat().st_size
        except (OSError, IOError):
            return 0

    def copy_file_stream(self, src: Path, dst: Path, progress_callback=None) -> bool:
        """å†…å­˜ä¼˜åŒ–çš„æµå¼æ–‡ä»¶å¤åˆ¶"""
        try:
            src_size = src.stat().st_size
            copied_bytes = 0

            with open(src, 'rb') as src_file, open(dst, 'wb') as dst_file:
                while True:
                    chunk_size = self._get_adaptive_chunk_size()
                    chunk = src_file.read(chunk_size)

                    if not chunk:
                        break

                    dst_file.write(chunk)
                    copied_bytes += len(chunk)

                    # å†…å­˜æ£€æŸ¥å’Œæ¸…ç†
                    if copied_bytes % (20 * 1024 * 1024) == 0:  # æ¯ 20MB æ£€æŸ¥ä¸€æ¬¡
                        if self.memory_manager and self.memory_manager.should_cleanup():
                            self.memory_manager.cleanup_if_needed()

                    # è¿›åº¦å›è°ƒ
                    if progress_callback and src_size > 0:
                        progress = copied_bytes / src_size
                        progress_callback(progress)

            return True

        except (OSError, IOError) as e:
            logger.warning(f"æµå¼å¤åˆ¶æ–‡ä»¶å¤±è´¥: {src} -> {dst}, é”™è¯¯: {e}")
            return False

    def process_large_directory(self, directory: Path,
                              operation: str = 'size') -> Dict[str, Any]:
        """å†…å­˜ä¼˜åŒ–çš„å¤§ç›®å½•å¤„ç†"""
        results = {
            'total_size': 0,
            'file_count': 0,
            'processed_files': [],
            'errors': []
        }

        try:
            for file_path in directory.rglob('*'):
                if file_path.is_file():
                    try:
                        if operation == 'size':
                            file_size = self.get_file_size_stream(file_path)
                            results['total_size'] += file_size
                            results['file_count'] += 1

                            # è®°å½•å¤§æ–‡ä»¶
                            if file_size > 100 * 1024 * 1024:  # å¤§äº 100MB
                                results['processed_files'].append({
                                    'path': str(file_path),
                                    'size': file_size
                                })

                        # å®šæœŸå†…å­˜æ£€æŸ¥
                        if results['file_count'] % 1000 == 0:
                            if self.memory_manager and self.memory_manager.should_cleanup():
                                cleaned = self.memory_manager.cleanup_if_needed()
                                if cleaned.get('freed_mb', 0) > 0:
                                    logger.info(f"å¤„ç†å¤§ç›®å½•æ—¶æ¸…ç†å†…å­˜: {cleaned['freed_mb']:.1f}MB")

                    except (OSError, IOError) as e:
                        results['errors'].append(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        except Exception as e:
            results['errors'].append(f"ç›®å½•å¤„ç†å¤±è´¥: {e}")

        return results

    def async_calculate_directory_size(self, path: Path) -> int:
        """å¼‚æ­¥è®¡ç®—ç›®å½•å¤§å°"""
        total_size = 0
        file_operations = []

        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶æ“ä½œ
        try:
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    file_operations.append(('size', file_path, None))
        except (OSError, PermissionError):
            return 0

        # å¼‚æ­¥æ‰§è¡Œæ–‡ä»¶å¤§å°è®¡ç®—
        if file_operations:
            async_processor = AsyncIOProcessor(max_concurrent=8)
            sizes = async_processor.async_file_operations(file_operations)
            total_size = sum(size for size in sizes if size is not None)

        return total_size


# ================== é«˜æ€§èƒ½ç›¸ä¼¼åº¦è®¡ç®— ==================
class FastSimilarityCalculator:
    """é«˜æ€§èƒ½ç›¸ä¼¼åº¦è®¡ç®—å™¨"""

    @staticmethod
    def jaccard_similarity(set_a: Set[str], set_b: Set[str]) -> float:
        """Jaccard ç›¸ä¼¼åº¦è®¡ç®— - æ¯” SequenceMatcher æ›´å¿«"""
        if not set_a or not set_b:
            return 0.0

        intersection = len(set_a.intersection(set_b))
        union = len(set_a.union(set_b))

        return intersection / union if union > 0 else 0.0

    @staticmethod
    def word_overlap_ratio(search_words: Set[str], target_words: Set[str]) -> float:
        """è¯æ±‡é‡å æ¯”ä¾‹"""
        if not search_words:
            return 0.0

        overlap = len(search_words.intersection(target_words))
        return overlap / len(search_words)

    @staticmethod
    def substring_bonus(search_str: str, target_str: str) -> float:
        """å­å­—ç¬¦ä¸²åŒ¹é…å¥–åŠ± - å¢å¼ºç‰ˆæœ¬"""
        # å®Œå…¨åŒ¹é…
        if search_str in target_str:
            return 0.4  # æé«˜å¥–åŠ±
        elif target_str in search_str:
            return 0.3  # æé«˜å¥–åŠ±

        # è¿ç»­è¯åŒ¹é…å¥–åŠ±ï¼ˆé’ˆå¯¹ "The Studio" è¿™ç±»æœç´¢ï¼‰
        search_words = search_str.split()
        target_words = target_str.split()

        if len(search_words) >= 2:
            search_phrase = ' '.join(search_words)
            target_phrase = ' '.join(target_words)
            if search_phrase in target_phrase or target_phrase in search_phrase:
                return 0.35

        return 0.0


# ================== æ–‡ä»¶åŒ¹é…å™¨ ==================
class FileMatcher:
    """æ–‡ä»¶åŒ¹é…å™¨ - v1.5.1 é«˜æ€§èƒ½æœç´¢ä¼˜åŒ–ç‰ˆæœ¬"""

    VIDEO_EXTENSIONS = {
        '.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv',
        '.webm', '.m4v', '.3gp', '.ogv', '.ts', '.m2ts',
        '.mpg', '.mpeg', '.rm', '.rmvb', '.asf', '.divx'
    }

    STOP_WORDS = {
        'the', 'and', 'of', 'to', 'in', 'a', 'an', 'is', 'are',
        'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had'
    }

    SEPARATORS = ['.', '_', '-', ':', '|', '\\', '/', '+', '(', ')', '[', ']']

    def __init__(self, base_directory: str, enable_cache: bool = True,
                 cache_duration: int = 3600, min_score: float = 0.6,
                 max_workers: int = 4):
        self.base_directory = Path(base_directory)
        self.min_score = min_score
        self.max_workers = max_workers
        self.cache = SearchCache(cache_duration) if enable_cache else None
        self.folder_info_cache = SearchCache(cache_duration) if enable_cache else None

        # åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å’Œå†…å­˜ç®¡ç†
        self.performance_monitor = PerformanceMonitor()
        self.memory_manager = MemoryManager()

        # åˆå§‹åŒ–æ™ºèƒ½ç´¢å¼•
        self.smart_index = SmartIndexCache(cache_duration)

        # åˆå§‹åŒ–å¼‚æ­¥å¤„ç†å™¨
        self.async_processor = AsyncIOProcessor(max_workers)

        # ç®€åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—
        self.similarity_calc = FastSimilarityCalculator()
        self._compiled_patterns = self._compile_quality_patterns()

        if not self.base_directory.exists():
            logger.warning(f"åŸºç¡€ç›®å½•ä¸å­˜åœ¨: {self.base_directory}")

    def _compile_quality_patterns(self) -> List:
        """é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        import re
        quality_patterns = [
            r'\b(720p|1080p|4k|uhd|hd|sd|bluray|bdrip|webrip|hdtv)\b',
            r'\b(x264|x265|h264|h265|hevc)\b',
            r'\b(aac|ac3|dts|mp3)\b'
        ]
        return [re.compile(pattern, re.IGNORECASE) for pattern in quality_patterns]

    def _generate_cache_key(self, search_name: str) -> str:
        key_data = f"{search_name}:{self.base_directory}"
        return hashlib.md5(key_data.encode()).hexdigest()

    def _normalize_string(self, text: str) -> str:
        """é«˜æ€§èƒ½å­—ç¬¦ä¸²æ ‡å‡†åŒ– - v1.5.1 ä¼˜åŒ–ç‰ˆæœ¬"""
        if not text:
            return ""

        # ç¼“å­˜æ ‡å‡†åŒ–ç»“æœ
        cache_key = f"normalize:{text}"
        if self.cache:
            cached_result = self.cache.get(cache_key)
            if cached_result is not None:
                return cached_result

        text = text.lower()

        # ä½¿ç”¨é¢„ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼
        text = re.sub(r'\b(19|20)\d{2}\b', '', text)

        # ä½¿ç”¨é¢„ç¼–è¯‘çš„è´¨é‡æ ‡è¯†æ¨¡å¼
        for pattern in self._compiled_patterns:
            text = pattern.sub('', text)

        # æ‰¹é‡æ›¿æ¢åˆ†éš”ç¬¦ï¼ˆæ›´é«˜æ•ˆï¼‰
        for sep in self.SEPARATORS:
            text = text.replace(sep, ' ')

        text = re.sub(r'\s+', ' ', text).strip()

        # ä¼˜åŒ–åœç”¨è¯ç§»é™¤ - æœç´¢ä¼˜åŒ–ç‰ˆæœ¬
        words = text.split()
        # å¯¹äºçŸ­æœç´¢è¯ï¼ˆâ‰¤3ä¸ªè¯ï¼‰ï¼Œä¸ç§»é™¤åœç”¨è¯ï¼Œæé«˜åŒ¹é…å‡†ç¡®æ€§
        if len(words) > 3:
            # ä½¿ç”¨é›†åˆæ“ä½œï¼Œæ›´é«˜æ•ˆ
            word_set = set(words)
            filtered_set = word_set - self.STOP_WORDS
            if filtered_set:
                # ä¿æŒåŸå§‹é¡ºåº
                words = [word for word in words if word in filtered_set]

        result = ' '.join(words)

        # ç¼“å­˜ç»“æœ
        if self.cache:
            self.cache.set(cache_key, result)

        return result

    def similarity(self, a: str, b: str) -> float:
        """é«˜æ€§èƒ½ç›¸ä¼¼åº¦è®¡ç®— - v1.5.1 ä¼˜åŒ–ç‰ˆæœ¬"""
        # ç¼“å­˜ç›¸ä¼¼åº¦è®¡ç®—ç»“æœ
        cache_key = f"sim:{a}:{b}"
        if self.cache:
            cached_score = self.cache.get(cache_key)
            if cached_score is not None:
                return cached_score

        a_normalized = self._normalize_string(a)
        b_normalized = self._normalize_string(b)

        # å¿«é€Ÿå®Œå…¨åŒ¹é…æ£€æŸ¥
        if a_normalized == b_normalized:
            score = 1.0
        else:
            # ä½¿ç”¨æ›´å¿«çš„ç®—æ³•ç»„åˆ
            a_words = set(a_normalized.split())
            b_words = set(b_normalized.split())

            # 1. Jaccard ç›¸ä¼¼åº¦ï¼ˆæ¯” SequenceMatcher æ›´å¿«ï¼‰
            jaccard_score = self.similarity_calc.jaccard_similarity(a_words, b_words)

            # 2. è¯æ±‡é‡å æ¯”ä¾‹
            overlap_ratio = self.similarity_calc.word_overlap_ratio(a_words, b_words)

            # 3. å­å­—ç¬¦ä¸²åŒ¹é…å¥–åŠ±
            substring_bonus = self.similarity_calc.substring_bonus(a_normalized, b_normalized)

            # ç»„åˆå¾—åˆ† - ä¼˜åŒ–æƒé‡åˆ†é…
            score = jaccard_score * 0.5 + overlap_ratio * 0.3 + substring_bonus * 0.2

            # å¦‚æœè¯æ±‡é‡å åº¦å¾ˆé«˜ï¼Œç»™äºˆé¢å¤–å¥–åŠ±
            if overlap_ratio >= 0.8:
                score = max(score, 0.9)
            elif overlap_ratio >= 0.6:
                score = max(score, 0.8)
            elif overlap_ratio >= 0.4:  # æ–°å¢ä¸­ç­‰åŒ¹é…å¥–åŠ±
                score = max(score, 0.7)

        score = min(1.0, score)

        # ç¼“å­˜ç»“æœ
        if self.cache:
            self.cache.set(cache_key, score)

        return score

    def get_all_folders(self, max_depth: int = 3) -> List[Path]:
        """è·å–åŸºç¡€ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹ - å¼‚æ­¥I/Oä¼˜åŒ–ç‰ˆæœ¬"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"all_folders:{self.base_directory}:{max_depth}"
        if self.cache:
            cached_folders = self.cache.get(cache_key)
            if cached_folders is not None:
                return cached_folders

        self.performance_monitor.start_timer('folder_scanning')
        folders = []

        if not self.base_directory.exists():
            return folders

        try:
            # å°è¯•ä½¿ç”¨å¼‚æ­¥ç›®å½•æ‰«æ
            async_folders = self._try_async_folder_scan(max_depth)
            if async_folders is not None:
                folders = async_folders
            else:
                # å›é€€åˆ°åŒæ­¥æ‰«æ
                folders = self._sync_folder_scan(max_depth)

            # ç¼“å­˜ç»“æœï¼ˆå¦‚æœå†…å­˜å…è®¸ï¼‰
            if self.cache and not self.memory_manager.should_cleanup():
                self.cache.set(cache_key, folders)

        finally:
            scan_duration = self.performance_monitor.end_timer('folder_scanning')
            memory_info = self.memory_manager.get_memory_usage()

            if scan_duration > 3.0:
                logger.warning(f"æ–‡ä»¶å¤¹æ‰«æè€—æ—¶è¾ƒé•¿: {scan_duration:.2f}s, æ‰¾åˆ° {len(folders)} ä¸ªæ–‡ä»¶å¤¹")

            print(f"  ğŸ“Š å†…å­˜ä½¿ç”¨: {memory_info['rss_mb']:.1f}MB, æ‰¾åˆ° {len(folders)} ä¸ªæ–‡ä»¶å¤¹")

        return folders

    def _try_async_folder_scan(self, max_depth: int) -> Optional[List[Path]]:
        """å°è¯•å¼‚æ­¥æ–‡ä»¶å¤¹æ‰«æ - æ·»åŠ è¶…æ—¶ä¿æŠ¤"""
        try:
            # ä½¿ç”¨å¼‚æ­¥ç›®å½•æ‰«æï¼Œæ·»åŠ è¶…æ—¶é™åˆ¶
            import signal

            def timeout_handler(signum, frame):
                # å¿½ç•¥æœªä½¿ç”¨çš„å‚æ•°è­¦å‘Š
                _ = signum, frame
                raise TimeoutError("å¼‚æ­¥æ‰«æè¶…æ—¶")

            # è®¾ç½®15ç§’è¶…æ—¶
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(15)

            try:
                async_folders = self.async_processor.async_directory_scan(self.base_directory, max_depth)
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
                print(f"  âš¡ å¼‚æ­¥æ‰«æå®Œæˆ: æ‰¾åˆ° {len(async_folders)} ä¸ªæ–‡ä»¶å¤¹")
                return async_folders
            except TimeoutError:
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
                print(f"  â° å¼‚æ­¥æ‰«æè¶…æ—¶ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼")
                return None

        except Exception as e:
            logger.debug(f"å¼‚æ­¥æ‰«æå¤±è´¥ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼: {e}")
            return None

    def _sync_folder_scan(self, max_depth: int) -> List[Path]:
        """åŒæ­¥æ–‡ä»¶å¤¹æ‰«æ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ·»åŠ é™åˆ¶å’Œè¶…æ—¶"""
        folders = []
        start_time = time.time()

        # ä»é…ç½®ä¸­è·å–é™åˆ¶å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
        try:
            # å°è¯•ä»å…¨å±€é…ç½®è·å–
            from pathlib import Path as PathLib
            config_path = PathLib.home() / ".torrent_maker" / "settings.json"
            if config_path.exists():
                import json
                with open(config_path, 'r', encoding='utf-8') as f:
                    settings = json.load(f)
                max_scan_time = settings.get('max_scan_time', 30)
                max_folders = settings.get('max_scan_folders', 5000)
            else:
                max_scan_time = 30
                max_folders = 5000
        except:
            max_scan_time = 30  # æœ€å¤§æ‰«ææ—¶é—´30ç§’
            max_folders = 5000  # æœ€å¤§æ–‡ä»¶å¤¹æ•°é‡é™åˆ¶

        def _scan_directory_memory_optimized(path: Path, current_depth: int = 0):
            # æ£€æŸ¥æ—¶é—´å’Œæ•°é‡é™åˆ¶
            if (time.time() - start_time > max_scan_time or
                len(folders) >= max_folders or
                current_depth >= max_depth):
                return

            # å®šæœŸæ£€æŸ¥å†…å­˜ä½¿ç”¨
            if len(folders) % 500 == 0 and len(folders) > 0:
                cleaned = self.memory_manager.cleanup_if_needed()
                if cleaned.get('freed_mb', 0) > 0:
                    print(f"  ğŸ§¹ å†…å­˜æ¸…ç†: é‡Šæ”¾ {cleaned['freed_mb']:.1f}MB")

                # æ£€æŸ¥æ‰«ææ—¶é—´
                elapsed = time.time() - start_time
                if elapsed > 15:  # 15ç§’åå¼€å§‹è­¦å‘Š
                    print(f"  â° æ‰«æè€—æ—¶: {elapsed:.1f}s, å·²æ‰¾åˆ° {len(folders)} ä¸ªæ–‡ä»¶å¤¹")

            try:
                with os.scandir(path) as entries:
                    batch_folders = []
                    subdirs_to_scan = []

                    for entry in entries:
                        # æ£€æŸ¥æ˜¯å¦è¶…æ—¶æˆ–è¶…é‡
                        if (time.time() - start_time > max_scan_time or
                            len(folders) >= max_folders):
                            break

                        try:
                            if entry.is_dir(follow_symlinks=False):
                                # å®‰å…¨å¤„ç†æ–‡ä»¶è·¯å¾„ï¼Œé¿å…ç¼–ç é—®é¢˜
                                try:
                                    folder_path = Path(entry.path)
                                    # éªŒè¯è·¯å¾„å¯ä»¥æ­£ç¡®ç¼–ç /è§£ç 
                                    str(folder_path).encode('utf-8').decode('utf-8')
                                    batch_folders.append(folder_path)

                                    # åªæœ‰åœ¨æ·±åº¦å…è®¸çš„æƒ…å†µä¸‹æ‰æ·»åŠ åˆ°é€’å½’åˆ—è¡¨
                                    if current_depth + 1 < max_depth:
                                        subdirs_to_scan.append(folder_path)

                                    # æ‰¹é‡æ·»åŠ ï¼Œå‡å°‘å†…å­˜åˆ†é…
                                    if len(batch_folders) >= 50:  # å‡å°‘æ‰¹é‡å¤§å°
                                        folders.extend(batch_folders)
                                        batch_folders.clear()

                                except (UnicodeDecodeError, UnicodeEncodeError) as e:
                                    # è·³è¿‡æœ‰ç¼–ç é—®é¢˜çš„æ–‡ä»¶å¤¹
                                    print(f"  âš ï¸ è·³è¿‡ç¼–ç é—®é¢˜æ–‡ä»¶å¤¹: {entry.name} ({e})")
                                    continue

                        except (OSError, IOError) as e:
                            # è·³è¿‡æ— æ³•è®¿é—®çš„æ¡ç›®
                            continue

                    # æ·»åŠ å‰©ä½™çš„æ–‡ä»¶å¤¹
                    if batch_folders:
                        folders.extend(batch_folders)

                    # é€’å½’æ‰«æå­ç›®å½•ï¼ˆé™åˆ¶æ•°é‡ï¼‰
                    for subdir in subdirs_to_scan[:20]:  # é™åˆ¶æ¯ä¸ªç›®å½•æœ€å¤šæ‰«æ20ä¸ªå­ç›®å½•
                        if (time.time() - start_time > max_scan_time or
                            len(folders) >= max_folders):
                            break
                        _scan_directory_memory_optimized(subdir, current_depth + 1)

            except (PermissionError, OSError, UnicodeDecodeError, UnicodeEncodeError) as e:
                # å¢å¼ºå¼‚å¸¸å¤„ç†ï¼ŒåŒ…æ‹¬ç¼–ç é”™è¯¯
                if isinstance(e, (UnicodeDecodeError, UnicodeEncodeError)):
                    print(f"  âš ï¸ ç›®å½•ç¼–ç é—®é¢˜: {path} ({e})")
                pass

        _scan_directory_memory_optimized(self.base_directory)

        elapsed = time.time() - start_time
        status = ""
        if elapsed > max_scan_time:
            status = " (å·²è¶…æ—¶)"
        elif len(folders) >= max_folders:
            status = " (å·²è¾¾åˆ°æ•°é‡é™åˆ¶)"

        print(f"  ğŸ”„ åŒæ­¥æ‰«æå®Œæˆ: æ‰¾åˆ° {len(folders)} ä¸ªæ–‡ä»¶å¤¹, è€—æ—¶ {elapsed:.1f}s{status}")
        return folders

    def fuzzy_search(self, search_name: str, max_results: int = 10) -> List[Tuple[str, float]]:
        """æ™ºèƒ½æ¨¡ç³Šæœç´¢ - v1.5.1 é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        self.performance_monitor.start_timer('fuzzy_search')

        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(search_name)
            if self.cache:
                cached_result = self.cache.get(cache_key)
                if cached_result is not None:
                    return cached_result[:max_results]

            all_folders = self.get_all_folders()
            if not all_folders:
                return []

            # é¢„å¤„ç†æœç´¢åç§°
            normalized_search = self._normalize_string(search_name)
            search_words = set(normalized_search.split())

            # æ„å»ºæˆ–æ›´æ–°æ™ºèƒ½ç´¢å¼•
            if self.smart_index.is_expired():
                self.smart_index.build_index(all_folders, self._normalize_string)

            # ä½¿ç”¨æ™ºèƒ½ç´¢å¼•è¿›è¡Œé¢„ç­›é€‰
            candidate_folders = self.smart_index.get_candidate_folders(search_words)

            # å¦‚æœé¢„ç­›é€‰ç»“æœå¤ªå°‘ï¼Œå›é€€åˆ°å…¨é‡æœç´¢
            if len(candidate_folders) < max_results * 2:
                candidate_paths = all_folders
                print(f"  ğŸ” é¢„ç­›é€‰ç»“æœè¾ƒå°‘({len(candidate_folders)})ï¼Œä½¿ç”¨å…¨é‡æœç´¢")
            else:
                candidate_paths = [Path(path) for path in candidate_folders]
                print(f"  ğŸ¯ æ™ºèƒ½é¢„ç­›é€‰: {len(all_folders)} â†’ {len(candidate_paths)} ä¸ªå€™é€‰")

            matches = []

            def process_folder_fast(folder_path: Path) -> Optional[Tuple[str, float]]:
                """å¿«é€Ÿæ–‡ä»¶å¤¹å¤„ç† - å¢å¼ºç¼–ç å®‰å…¨"""
                try:
                    folder_name = folder_path.name
                    # éªŒè¯æ–‡ä»¶å¤¹åç§°å¯ä»¥æ­£ç¡®ç¼–ç /è§£ç 
                    folder_name.encode('utf-8').decode('utf-8')
                    str(folder_path).encode('utf-8').decode('utf-8')

                    similarity_score = self.similarity(search_name, folder_name)

                    if similarity_score >= self.min_score:
                        return (str(folder_path), similarity_score)
                    return None
                except (UnicodeDecodeError, UnicodeEncodeError) as e:
                    # è·³è¿‡æœ‰ç¼–ç é—®é¢˜çš„æ–‡ä»¶å¤¹
                    print(f"  âš ï¸ è·³è¿‡ç¼–ç é—®é¢˜æ–‡ä»¶å¤¹: {folder_path} ({e})")
                    return None
                except Exception:
                    return None

            # æ™ºèƒ½å¹¶å‘ç­–ç•¥
            folder_count = len(candidate_paths)
            if folder_count <= 50:
                # å°‘é‡æ–‡ä»¶å¤¹ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†
                for folder in candidate_paths:
                    result = process_folder_fast(folder)
                    if result:
                        matches.append(result)
            else:
                # å¤§é‡æ–‡ä»¶å¤¹ï¼Œä½¿ç”¨å¹¶è¡Œå¤„ç†
                batch_size = min(500, folder_count)

                for i in range(0, folder_count, batch_size):
                    batch_folders = candidate_paths[i:i + batch_size]

                    with ThreadPoolExecutor(max_workers=min(self.max_workers, 4)) as executor:
                        future_to_folder = {
                            executor.submit(process_folder_fast, folder): folder
                            for folder in batch_folders
                        }

                        for future in as_completed(future_to_folder):
                            result = future.result()
                            if result:
                                matches.append(result)

            # æ™ºèƒ½æ’åºï¼šç›¸ä¼¼åº¦ + è·¯å¾„é•¿åº¦ï¼ˆæ›´çŸ­çš„è·¯å¾„ä¼˜å…ˆï¼‰
            matches.sort(key=lambda x: (x[1], -len(x[0])), reverse=True)

            # ç¼“å­˜ç»“æœ
            if self.cache:
                self.cache.set(cache_key, matches)

            return matches[:max_results]

        finally:
            search_duration = self.performance_monitor.end_timer('fuzzy_search')
            matches_count = len(matches) if 'matches' in locals() else 0
            print(f"  ğŸ” æœç´¢è€—æ—¶: {search_duration:.3f}s, æ‰¾åˆ° {matches_count} ä¸ªåŒ¹é…é¡¹")

    def get_folder_info(self, folder_path: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶å¤¹è¯¦ç»†ä¿¡æ¯ - å¸¦ç¼“å­˜ä¼˜åŒ–"""
        if not os.path.exists(folder_path):
            return {'exists': False}

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"folder_info:{folder_path}"
        if self.folder_info_cache:
            cached_info = self.folder_info_cache.get(cache_key)
            if cached_info is not None:
                return cached_info

        self.performance_monitor.start_timer('folder_info_calculation')

        try:
            total_files = 0
            total_size = 0

            try:
                # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•è®¡ç®—æ–‡ä»¶ä¿¡æ¯
                path_obj = Path(folder_path)
                for file_path in path_obj.rglob('*'):
                    if file_path.is_file():
                        total_files += 1
                        try:
                            total_size += file_path.stat().st_size
                        except (OSError, IOError):
                            pass
            except PermissionError:
                result = {'exists': True, 'readable': False}
                if self.folder_info_cache:
                    self.folder_info_cache.set(cache_key, result)
                return result

            size_str = self.format_size(total_size)

            result = {
                'exists': True,
                'readable': True,
                'total_files': total_files,
                'total_size': total_size,
                'size_str': size_str
            }

            # ç¼“å­˜ç»“æœ
            if self.folder_info_cache:
                self.folder_info_cache.set(cache_key, result)

            return result

        finally:
            self.performance_monitor.end_timer('folder_info_calculation')

    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} PB"

    def is_video_file(self, filename: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶"""
        return Path(filename).suffix.lower() in self.VIDEO_EXTENSIONS

    def match_folders(self, search_name: str) -> List[Dict[str, Any]]:
        """æœç´¢å¹¶è¿”å›åŒ¹é…çš„æ–‡ä»¶å¤¹ä¿¡æ¯"""
        matches = self.fuzzy_search(search_name)
        result = []

        for folder_path, score in matches:
            folder_info = self.get_folder_info(folder_path)
            if folder_info['exists']:
                episode_info = self.extract_episode_info_simple(folder_path)
                season_info = episode_info.get('season_info', '')
                total_episodes = episode_info.get('total_episodes', 0)

                result.append({
                    'path': folder_path,
                    'name': os.path.basename(folder_path),
                    'score': int(score * 100),
                    'file_count': folder_info.get('total_files', 0),
                    'size': folder_info.get('size_str', 'æœªçŸ¥'),
                    'readable': folder_info.get('readable', True),
                    'episodes': season_info,
                    'video_count': total_episodes
                })

        return result

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æœç´¢æ€§èƒ½ç»Ÿè®¡ - v1.5.1 å¢å¼ºç‰ˆ"""
        stats = self.performance_monitor.get_all_stats()
        memory_info = self.memory_manager.get_memory_usage()

        # è®¡ç®—æœç´¢æ•ˆç‡æŒ‡æ ‡
        search_stats = stats.get('fuzzy_search', {})
        folder_scan_stats = stats.get('folder_scanning', {})

        return {
            'search_performance': {
                'average_search_time': search_stats.get('average', 0),
                'total_searches': search_stats.get('count', 0),
                'fastest_search': search_stats.get('min', 0),
                'slowest_search': search_stats.get('max', 0)
            },
            'folder_scanning': {
                'average_scan_time': folder_scan_stats.get('average', 0),
                'total_scans': folder_scan_stats.get('count', 0)
            },
            'memory_usage': memory_info,
            'cache_performance': {
                'smart_index_expired': self.smart_index.is_expired(),
                'cache_enabled': self.cache is not None
            },
            'optimization_level': self._calculate_optimization_level(search_stats, memory_info)
        }

    def _calculate_optimization_level(self, search_stats: Dict, memory_info: Dict) -> str:
        """è®¡ç®—ä¼˜åŒ–ç­‰çº§"""
        avg_search_time = search_stats.get('average', 0)
        memory_usage = memory_info.get('rss_mb', 0)

        if avg_search_time < 0.5 and memory_usage < 200:
            return "ä¼˜ç§€ (A+)"
        elif avg_search_time < 1.0 and memory_usage < 300:
            return "è‰¯å¥½ (B+)"
        elif avg_search_time < 2.0 and memory_usage < 400:
            return "ä¸€èˆ¬ (C+)"
        else:
            return "éœ€è¦ä¼˜åŒ– (D)"

    def cleanup_resources(self) -> Dict[str, int]:
        """æ¸…ç†èµ„æº"""
        cleaned_stats = {}

        # æ¸…ç†å†…å­˜
        cleaned_stats['memory_items'] = self.memory_manager.cleanup_memory()

        # æ¸…ç†ç¼“å­˜
        if self.cache:
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç¼“å­˜æ¸…ç†é€»è¾‘
            cleaned_stats['cache_items'] = 0

        # é‡å»ºç´¢å¼•
        if self.smart_index.is_expired():
            cleaned_stats['index_rebuilt'] = 1
        else:
            cleaned_stats['index_rebuilt'] = 0

        return cleaned_stats

    def extract_episode_info_simple(self, folder_path: str) -> Dict[str, Any]:
        """ç®€å•çš„å‰§é›†ä¿¡æ¯æå–"""
        if not os.path.exists(folder_path) or not os.path.isdir(folder_path):
            return {'episodes': [], 'season_info': '', 'total_episodes': 0}

        episodes = []
        seasons = set()

        try:
            for _, _, files in os.walk(folder_path):
                for file in files:
                    if self.is_video_file(file):
                        episode_info = self.parse_episode_from_filename(file)
                        if episode_info:
                            episodes.append(episode_info)
                            if episode_info['season']:
                                seasons.add(episode_info['season'])
        except (PermissionError, OSError):
            return {'episodes': [], 'season_info': 'æ— æ³•è®¿é—®', 'total_episodes': 0}

        episodes.sort(key=lambda x: (x['season'] or 0, x['episode'] or 0))
        season_info = self.generate_season_summary(episodes, seasons)

        return {
            'episodes': episodes,
            'season_info': season_info,
            'total_episodes': len(episodes)
        }

    def parse_episode_from_filename(self, filename: str) -> Optional[Dict[str, Any]]:
        """ä»æ–‡ä»¶åä¸­è§£æå‰§é›†ä¿¡æ¯"""
        import re

        patterns = [
            (r'[Ss](\d{1,2})[Ee](\d{1,3})', 'season_episode'),
            (r'[Ss]eason\s*(\d{1,2})\s*[Ee]pisode\s*(\d{1,3})', 'season_episode'),
            (r'ç¬¬(\d{1,2})å­£ç¬¬(\d{1,3})é›†', 'season_episode'),
            (r'(\d{1,2})x(\d{1,3})', 'season_episode'),
            (r'(?:[Ee][Pp]\.?\s*(\d{1,3})|ç¬¬(\d{1,3})é›†)', 'episode_only'),
        ]

        for pattern, pattern_type in patterns:
            match = re.search(pattern, filename)
            if match:
                try:
                    if pattern_type == 'season_episode':
                        season = int(match.group(1))
                        episode = int(match.group(2))
                        if 1 <= season <= 50 and 1 <= episode <= 500:
                            return {
                                'season': season,
                                'episode': episode,
                                'filename': filename,
                                'pattern_type': pattern_type
                            }
                    elif pattern_type == 'episode_only':
                        episode = int(match.group(1) or match.group(2))
                        if 1 <= episode <= 500:
                            return {
                                'season': None,
                                'episode': episode,
                                'filename': filename,
                                'pattern_type': pattern_type
                            }
                except ValueError:
                    continue

        return None

    def generate_season_summary(self, episodes: list, seasons: set) -> str:
        """ç”Ÿæˆå­£åº¦æ‘˜è¦ä¿¡æ¯"""
        if not episodes:
            return "æ— å‰§é›†ä¿¡æ¯"

        if not seasons or None in seasons:
            episode_numbers = [ep['episode'] for ep in episodes if ep.get('episode')]
            if episode_numbers:
                return self._format_episode_range(episode_numbers)
            else:
                return f"{len(episodes)}ä¸ªè§†é¢‘"

        season_summaries = []
        for season in sorted(seasons):
            season_episodes = [ep for ep in episodes if ep.get('season') == season]
            episode_numbers = [ep['episode'] for ep in season_episodes if ep.get('episode')]

            if episode_numbers:
                episode_range = self._format_episode_range(episode_numbers)
                season_summary = f"S{season:02d}{episode_range}"
                season_summaries.append(season_summary)

        return ', '.join(season_summaries) if season_summaries else f"{len(episodes)}ä¸ªè§†é¢‘"

    def _format_episode_range(self, episode_numbers: List[int]) -> str:
        """æ ¼å¼åŒ–é›†æ•°èŒƒå›´"""
        if not episode_numbers:
            return ""

        episode_numbers = sorted(set(episode_numbers))

        if len(episode_numbers) == 1:
            return f"E{episode_numbers[0]:02d}"

        is_fully_continuous = all(
            episode_numbers[i] == episode_numbers[i-1] + 1
            for i in range(1, len(episode_numbers))
        )

        if is_fully_continuous:
            return f"E{episode_numbers[0]:02d}-E{episode_numbers[-1]:02d}"
        else:
            groups = []
            start = episode_numbers[0]
            end = episode_numbers[0]

            for i in range(1, len(episode_numbers)):
                if episode_numbers[i] == end + 1:
                    end = episode_numbers[i]
                else:
                    if start == end:
                        groups.append(f"E{start:02d}")
                    else:
                        groups.append(f"E{start:02d}-E{end:02d}")
                    start = episode_numbers[i]
                    end = episode_numbers[i]

            if start == end:
                groups.append(f"E{start:02d}")
            else:
                groups.append(f"E{start:02d}-E{end:02d}")

            return ",".join(groups)


# ================== ç§å­åˆ›å»ºå™¨ ==================
class TorrentCreator:
    """ç§å­åˆ›å»ºå™¨ - v1.7.0é«˜æ€§èƒ½Pythonå¼•æ“ç‰ˆæœ¬"""

    DEFAULT_PIECE_SIZE = "auto"
    DEFAULT_COMMENT = f"Created by Torrent Maker v{VERSION}"
    PIECE_SIZES = [16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    # Piece Size æŸ¥æ‰¾è¡¨ - æé€Ÿä¼˜åŒ–ç‰ˆæœ¬ï¼ˆæ›´å¤§piece sizeï¼‰
    PIECE_SIZE_LOOKUP = {
        # æ–‡ä»¶å¤§å°èŒƒå›´ (MB) -> (piece_size_kb, log2_value)
        (0, 50): (128, 17),          # å°æ–‡ä»¶: 128KB pieces
        (50, 200): (256, 18),        # ä¸­å°æ–‡ä»¶: 256KB pieces
        (200, 500): (512, 19),       # ä¸­ç­‰æ–‡ä»¶: 512KB pieces
        (500, 1000): (1024, 20),     # è¾ƒå¤§æ–‡ä»¶: 1MB pieces
        (1000, 2000): (2048, 21),    # å¤§æ–‡ä»¶: 2MB pieces
        (2000, 5000): (4096, 22),    # å¾ˆå¤§æ–‡ä»¶: 4MB pieces
        (5000, 10000): (8192, 23),   # è¶…å¤§æ–‡ä»¶: 8MB pieces
        (10000, 20000): (16384, 24), # å·¨å¤§æ–‡ä»¶: 16MB pieces
        (20000, 50000): (32768, 25), # è¶…å·¨å¤§æ–‡ä»¶: 32MB pieces
        (50000, float('inf')): (65536, 26)  # æå¤§æ–‡ä»¶: 64MB pieces
    }

    def __init__(self, tracker_links: List[str], output_dir: str = "output",
                 piece_size: Union[str, int] = "auto", private: bool = False,
                 comment: str = None, max_workers: int = 4, config_manager=None):
        self.tracker_links = list(tracker_links) if tracker_links else []
        self.output_dir = Path(output_dir)
        self.piece_size = piece_size
        self.private = private
        self.comment = comment or self.DEFAULT_COMMENT
        self.max_workers = max_workers
        self.config_manager = config_manager

        # åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å’Œå†…å­˜ç®¡ç†
        self.performance_monitor = PerformanceMonitor()
        self.memory_manager = MemoryManager()

        # ç›®å½•å¤§å°ç¼“å­˜
        self.size_cache = DirectorySizeCache()

        # åˆå§‹åŒ– piece size ç¼“å­˜
        self._piece_size_cache = {}

        # åˆå§‹åŒ–å¼‚æ­¥å¤„ç†å™¨
        self.async_processor = AsyncIOProcessor(max_workers)
        self.stream_processor = StreamFileProcessor(memory_manager=self.memory_manager)

        # æ£€æµ‹ mktorrent å¯ç”¨æ€§
        self.mktorrent_available = self._check_mktorrent()
        if not self.mktorrent_available:
            raise TorrentCreationError("mktorrent ä¸å¯ç”¨ï¼Œè¯·å®‰è£… mktorrent: apt-get install mktorrent æˆ– brew install mktorrent")

    def _check_mktorrent(self) -> bool:
        return shutil.which('mktorrent') is not None







    def _ensure_output_dir(self) -> None:
        try:
            self.output_dir.mkdir(parents=True, exist_ok=True)
        except OSError as e:
            raise TorrentCreationError(f"æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {e}")

    def _calculate_piece_size(self, total_size: int) -> int:
        """æ™ºèƒ½è®¡ç®—åˆé€‚çš„pieceå¤§å° - é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        # æ£€æŸ¥ç¼“å­˜
        size_mb = total_size // (1024 * 1024)
        cache_key = f"size_{size_mb}"

        if cache_key in self._piece_size_cache:
            return self._piece_size_cache[cache_key]

        # ä½¿ç”¨æŸ¥æ‰¾è¡¨å¿«é€Ÿç¡®å®š piece size
        for (min_size, max_size), (_, log2_value) in self.PIECE_SIZE_LOOKUP.items():
            if min_size <= size_mb < max_size:
                self._piece_size_cache[cache_key] = log2_value
                return log2_value

        # å›é€€åˆ°ä¼ ç»Ÿè®¡ç®—æ–¹æ³•ï¼ˆç”¨äºæç«¯æƒ…å†µï¼‰
        target_pieces = 1500
        optimal_piece_size = total_size // (target_pieces * 1024)

        for size in self.PIECE_SIZES:
            if size >= optimal_piece_size:
                import math
                log2_value = int(math.log2(size * 1024))
                self._piece_size_cache[cache_key] = log2_value
                return log2_value

        # è¿”å›æœ€å¤§pieceå¤§å°çš„æŒ‡æ•°å€¼
        import math
        log2_value = int(math.log2(self.PIECE_SIZES[-1] * 1024))
        self._piece_size_cache[cache_key] = log2_value
        return log2_value

    def _get_optimal_piece_size_fast(self, total_size: int) -> Tuple[int, int]:
        """å¿«é€Ÿè·å–æœ€ä¼˜ piece sizeï¼ˆKB å’Œ log2 å€¼ï¼‰"""
        size_mb = total_size // (1024 * 1024)

        # ç›´æ¥æŸ¥è¡¨ï¼ŒO(1) æ—¶é—´å¤æ‚åº¦
        for (min_size, max_size), (piece_size_kb, log2_value) in self.PIECE_SIZE_LOOKUP.items():
            if min_size <= size_mb < max_size:
                return piece_size_kb, log2_value

        # é»˜è®¤è¿”å›æœ€å¤§å€¼
        return 4096, 22

    def _get_directory_size(self, path: Path) -> int:
        """è·å–ç›®å½•å¤§å° - ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–"""
        self.performance_monitor.start_timer('directory_size_calculation')
        try:
            size = self.size_cache.get_directory_size(path)
            return size
        finally:
            duration = self.performance_monitor.end_timer('directory_size_calculation')
            if duration > 5.0:  # å¦‚æœè®¡ç®—æ—¶é—´è¶…è¿‡5ç§’ï¼Œè®°å½•è­¦å‘Š
                logger.warning(f"ç›®å½•å¤§å°è®¡ç®—è€—æ—¶è¾ƒé•¿: {duration:.2f}s for {path}")

    def _sanitize_filename(self, filename: str) -> str:
        import re
        unsafe_chars = r'[<>:"/\\|?*]'
        sanitized = re.sub(unsafe_chars, '_', filename)
        sanitized = sanitized.strip(' .')
        return sanitized if sanitized else "torrent"

    def _format_duration(self, duration_seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆæ”¯æŒåˆ†é’Ÿ:ç§’å’Œå°æ—¶:åˆ†é’Ÿ:ç§’æ ¼å¼ï¼‰"""
        total_seconds = int(duration_seconds)
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        seconds = total_seconds % 60

        if hours > 0:
            return f"{hours}:{minutes:02d}:{seconds:02d}"
        else:
            return f"{minutes}:{seconds:02d}"

    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} PB"

    def _calculate_creation_speed(self, file_size_bytes: int, duration_seconds: float) -> str:
        """è®¡ç®—åˆ¶ç§é€Ÿåº¦"""
        if duration_seconds <= 0:
            return "N/A"

        speed_bytes_per_sec = file_size_bytes / duration_seconds

        # è½¬æ¢ä¸ºåˆé€‚çš„å•ä½
        if speed_bytes_per_sec >= 1024 * 1024 * 1024:  # GB/s
            speed = speed_bytes_per_sec / (1024 * 1024 * 1024)
            return f"{speed:.2f} GB/s"
        elif speed_bytes_per_sec >= 1024 * 1024:  # MB/s
            speed = speed_bytes_per_sec / (1024 * 1024)
            return f"{speed:.2f} MB/s"
        elif speed_bytes_per_sec >= 1024:  # KB/s
            speed = speed_bytes_per_sec / 1024
            return f"{speed:.2f} KB/s"
        else:  # B/s
            return f"{speed_bytes_per_sec:.2f} B/s"

    def _detect_optimal_threads(self, file_size_bytes: int = 0) -> dict:
        """æ™ºèƒ½æ£€æµ‹æœ€ä¼˜çº¿ç¨‹æ•°é…ç½®"""
        import os

        # è·å–ç³»ç»Ÿä¿¡æ¯
        cpu_count = os.cpu_count() or 4
        load_avg = 0.0
        memory_usage_percent = 50.0  # é»˜è®¤å€¼

        if hasattr(os, 'getloadavg'):
            try:
                load_avg = os.getloadavg()[0]
            except OSError:
                pass  # åœ¨æŸäº›å®¹å™¨ç¯å¢ƒä¸‹å¯èƒ½å¤±è´¥

        try:
            import psutil
            memory_usage_percent = psutil.virtual_memory().percent
        except (ImportError, AttributeError):
            try:
                # å½“ psutil ä¸å¯ç”¨æ—¶ï¼Œå›é€€åˆ°è¯»å– /proc/meminfo (ä»…é™Linux)
                with open('/proc/meminfo', 'r') as f:
                    meminfo = f.read()
                total_mem_match = re.search(r'MemTotal:\s+(\d+)', meminfo)
                available_mem_match = re.search(r'MemAvailable:\s+(\d+)', meminfo)
                if total_mem_match and available_mem_match:
                    total_mem = int(total_mem_match.group(1))
                    available_mem = int(available_mem_match.group(1))
                    if total_mem > 0:
                        memory_usage_percent = (1 - available_mem / total_mem) * 100
            except (IOError, AttributeError, ValueError):
                pass # æ— æ³•è·å–å†…å­˜ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼

        # 1. åŸºç¡€çº¿ç¨‹æ•°
        base_threads = cpu_count

        # 2. æ ¹æ®æ–‡ä»¶å¤§å°è°ƒæ•´ç­–ç•¥
        file_size_gb = file_size_bytes / (1024 * 1024 * 1024) if file_size_bytes > 0 else 0
        if file_size_gb > 0:
            if file_size_gb < 2:  # å°æ–‡ä»¶ (<2GB)
                thread_limit = max(4, cpu_count // 2)
                base_threads = min(base_threads, thread_limit, 8)
            elif file_size_gb < 50: # ä¸­ç­‰æ–‡ä»¶ (2GB-50GB)
                thread_limit = max(6, int(cpu_count * 0.75))
                base_threads = min(base_threads, thread_limit)

        # 3. æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´
        load_per_core = load_avg / cpu_count if cpu_count > 0 else 0
        if load_per_core > 0.7:  # å½“æ¯æ ¸å¿ƒçš„å¹³å‡è´Ÿè½½ > 0.7 æ—¶ï¼Œè®¤ä¸ºç³»ç»Ÿç¹å¿™
            reduction_factor = 1.0 - min(0.5, (load_per_core - 0.7))
            base_threads = max(2, int(base_threads * reduction_factor))

        # 4. æ ¹æ®å†…å­˜ä½¿ç”¨æƒ…å†µè°ƒæ•´
        if memory_usage_percent > 85:  # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
            base_threads = max(2, int(base_threads * 0.8))

        # 5. mktorrent çš„æœ€ä¼˜çº¿ç¨‹æ•°ä¸Šé™, å¯¹äºé«˜æ€§èƒ½æœºå™¨æ”¾å®½åˆ°16
        optimal_threads = min(base_threads, 16)
        optimal_threads = max(optimal_threads, 2) # ç¡®ä¿è‡³å°‘ä½¿ç”¨2ä¸ªçº¿ç¨‹

        return {
            'cpu_count': cpu_count,
            'optimal_threads': int(optimal_threads),
            'load_avg': load_avg,
            'memory_usage_percent': memory_usage_percent,
            'file_size_gb': file_size_gb,
            'recommendation': self._get_thread_recommendation(int(optimal_threads), cpu_count, file_size_bytes, load_per_core)
        }

    def _get_thread_recommendation(self, optimal_threads: int, cpu_count: int, file_size_bytes: int, load_per_core: float) -> str:
        """è·å–çº¿ç¨‹é…ç½®å»ºè®®"""
        file_size_gb = file_size_bytes / (1024 * 1024 * 1024) if file_size_bytes > 0 else 0

        if load_per_core > 0.7:
            return f"ç³»ç»Ÿè´Ÿè½½è¾ƒé«˜ (æ¯æ ¸è´Ÿè½½ {load_per_core:.2f})ï¼Œå·²è‡ªåŠ¨å‡å°‘çº¿ç¨‹"
        elif optimal_threads >= cpu_count * 0.9:
            return "ç³»ç»Ÿèµ„æºå……è¶³ï¼Œä½¿ç”¨æœ€å¤§åŒ–çº¿ç¨‹ä»¥æå‡æ€§èƒ½"
        elif file_size_gb > 50:
            return "è¶…å¤§æ–‡ä»¶å¤„ç†ï¼Œå·²å¯ç”¨æ›´å¤šçº¿ç¨‹åŠ é€Ÿ"
        elif file_size_gb > 2:
            return "æ–‡ä»¶è¾ƒå¤§ï¼Œå·²æ™ºèƒ½åˆ†é…è¾ƒå¤šçº¿ç¨‹"
        elif file_size_gb > 0:
            return "å°æ–‡ä»¶åˆ¶ç§ï¼Œå·²ä¼˜åŒ–çº¿ç¨‹æ•°ä»¥å¹³è¡¡å¼€é”€å’Œæ€§èƒ½"
        elif optimal_threads < cpu_count * 0.5 and optimal_threads < 8:
            return "æ ¹æ®ç³»ç»Ÿç»¼åˆçŠ¶æ€ï¼Œä½¿ç”¨ä¿å®ˆçº¿ç¨‹ç­–ç•¥"
        else:
            return "æ ¹æ®ç³»ç»ŸçŠ¶æ€å’Œæ–‡ä»¶å¤§å°æ™ºèƒ½è°ƒæ•´"

    def _show_performance_suggestions(self, file_size_bytes: int, total_duration: float, mktorrent_duration: float):
        """æ˜¾ç¤ºæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        file_size_gb = file_size_bytes / (1024 * 1024 * 1024)
        suggestions = []

        # åŸºäºåˆ¶ç§é€Ÿåº¦çš„å»ºè®®
        speed_mbps = (file_size_bytes / (1024 * 1024)) / total_duration if total_duration > 0 else 0

        if speed_mbps < 50:  # ä½äº50MB/s
            suggestions.append("åˆ¶ç§é€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®æ£€æŸ¥ç£ç›˜æ€§èƒ½æˆ–å‡å°‘ç³»ç»Ÿè´Ÿè½½")
        elif speed_mbps > 500:  # é«˜äº500MB/s
            suggestions.append("åˆ¶ç§é€Ÿåº¦ä¼˜ç§€ï¼å½“å‰é…ç½®è¡¨ç°è‰¯å¥½")

        # åŸºäºæ–‡ä»¶å¤§å°çš„å»ºè®®
        if file_size_gb > 50:
            suggestions.append("å¤§æ–‡ä»¶åˆ¶ç§ï¼Œå»ºè®®ä½¿ç”¨SSDå­˜å‚¨ä»¥æå‡æ€§èƒ½")
        elif file_size_gb < 0.1:
            suggestions.append("å°æ–‡ä»¶åˆ¶ç§ï¼Œå½“å‰é…ç½®å·²è¶³å¤Ÿ")

        # åŸºäºæ•ˆç‡çš„å»ºè®®
        efficiency = (mktorrent_duration / total_duration) * 100 if total_duration > 0 else 0
        if efficiency < 70:
            suggestions.append("å‡†å¤‡é˜¶æ®µè€—æ—¶è¾ƒé•¿ï¼Œå¯èƒ½æ˜¯ç£ç›˜I/Oæˆ–æ–‡ä»¶æ‰«æå¯¼è‡´")
        elif efficiency > 95:
            suggestions.append("mktorrentæ‰§è¡Œæ•ˆç‡å¾ˆé«˜ï¼Œç³»ç»Ÿé…ç½®ä¼˜ç§€")

        # æ˜¾ç¤ºå»ºè®®
        if suggestions:
            print(f"\n  ğŸ’¡ æ€§èƒ½å»ºè®®:")
            for i, suggestion in enumerate(suggestions, 1):
                print(f"     {i}. {suggestion}")
        else:
            print(f"\n  ğŸ’¡ æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œæ— ç‰¹æ®Šå»ºè®®")

    def _build_command(self, source_path: Path, output_file: Path,
                      piece_size: int = None, file_size_bytes: int = 0) -> List[str]:
        """æ„å»ºä¼˜åŒ–çš„ mktorrent å‘½ä»¤"""
        command = ['mktorrent']

        # æ·»åŠ  tracker é“¾æ¥
        for tracker in self.tracker_links:
            command.extend(['-a', tracker])

        # è®¾ç½®è¾“å‡ºæ–‡ä»¶
        command.extend(['-o', str(output_file)])

        # è®¾ç½®æ³¨é‡Šï¼ˆç®€åŒ–ä»¥å‡å°‘å¼€é”€ï¼‰
        comment = f"{self.comment}"
        command.extend(['-c', comment])

        # è®¾ç½® piece å¤§å°
        if piece_size:
            command.extend(['-l', str(piece_size)])

        # æ™ºèƒ½å¤šçº¿ç¨‹å¤„ç†
        thread_info = self._detect_optimal_threads(file_size_bytes)
        thread_count = thread_info['optimal_threads']

        command.extend(['-t', str(thread_count)])
        
        # æ˜¾ç¤ºè¯¦ç»†çš„çº¿ç¨‹é…ç½®ä¿¡æ¯
        print(f"  ğŸ–¥ï¸  ç³»ç»ŸCPUæ ¸å¿ƒæ•°: {thread_info['cpu_count']}")
        print(f"  ğŸ§µ æœ€ä¼˜çº¿ç¨‹æ•°: {thread_count}")
        if thread_info['load_avg'] > 0:
            print(f"  ğŸ“Š ç³»ç»Ÿè´Ÿè½½: {thread_info['load_avg']:.2f}")
        print(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡: {thread_info['memory_usage_percent']:.1f}%")
        if thread_info['file_size_gb'] > 0:
            print(f"  ğŸ“ æ–‡ä»¶å¤§å°: {thread_info['file_size_gb']:.2f} GB")
        print(f"  ğŸ’¡ é…ç½®å»ºè®®: {thread_info['recommendation']}")
        
        # ç§æœ‰ç§å­æ ‡è®°
        if self.private:
            command.append('-p')

        # å‡å°‘è¾“å‡ºä¿¡æ¯ä»¥æé«˜æ€§èƒ½ï¼ˆç§»é™¤ -v å‚æ•°ï¼‰
        # command.append('-v')  # æ³¨é‡Šæ‰è¯¦ç»†è¾“å‡º

        # æ·»åŠ æºè·¯å¾„
        command.append(str(source_path))

        return command

    def _get_mktorrent_version(self) -> str:
        """è·å– mktorrent ç‰ˆæœ¬ä¿¡æ¯"""
        try:
            result = subprocess.run(['mktorrent', '--help'],
                                  capture_output=True, text=True, timeout=5)
            if result.stdout:
                # ä»å¸®åŠ©ä¿¡æ¯ä¸­æå–ç‰ˆæœ¬
                lines = result.stdout.split('\n')
                for line in lines:
                    if 'mktorrent' in line and '(' in line:
                        return line.strip()
            return "mktorrent (version unknown)"
        except Exception:
            return "mktorrent (version unknown)"

    def create_torrent(self, source_path: Union[str, Path],
                      custom_name: str = None,
                      progress_callback = None) -> Optional[str]:
        """åˆ›å»ºç§å­æ–‡ä»¶ - ä½¿ç”¨ mktorrent"""
        # è®°å½•åˆ¶ç§å¼€å§‹æ—¶é—´
        creation_start_time = time.time()
        start_time_str = datetime.now().strftime("%H:%M:%S")

        try:
            source_path = Path(source_path)

            if not source_path.exists():
                raise TorrentCreationError(f"æºè·¯å¾„ä¸å­˜åœ¨: {source_path}")

            self._ensure_output_dir()

            if custom_name:
                torrent_name = self._sanitize_filename(custom_name)
            else:
                torrent_name = self._sanitize_filename(source_path.name)

            # ä½¿ç”¨å¾®ç§’çº§æ—¶é—´æˆ³ç¡®ä¿æ–‡ä»¶åå”¯ä¸€æ€§
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            output_file = self.output_dir / f"{torrent_name}_{timestamp}.torrent"
            
            # æ–‡ä»¶å†²çªæ£€æµ‹å’Œé‡è¯•æœºåˆ¶
            retry_count = 0
            while output_file.exists() and retry_count < 5:
                retry_count += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                output_file = self.output_dir / f"{torrent_name}_{timestamp}_retry{retry_count}.torrent"

            # è®¡ç®—æ–‡ä»¶å¤§å°å’Œpieceå¤§å°
            if self.piece_size == "auto":
                if source_path.is_dir():
                    total_size = self._get_directory_size(source_path)
                else:
                    total_size = source_path.stat().st_size

                piece_size_log2 = self._calculate_piece_size(total_size)
                piece_size_kb = (2 ** piece_size_log2) // 1024
                print(f"  ğŸ¯ è‡ªåŠ¨é€‰æ‹© Piece å¤§å°: {piece_size_kb}KB (æ–‡ä»¶å¤§å°: {self._format_file_size(total_size)})")
            elif isinstance(self.piece_size, int):
                # å¦‚æœç”¨æˆ·è®¾ç½®çš„æ˜¯KBå€¼ï¼Œéœ€è¦è½¬æ¢ä¸ºlog2
                import math
                piece_size_bytes = self.piece_size * 1024
                piece_size_log2 = int(math.log2(piece_size_bytes))
                # è·å–æ–‡ä»¶å¤§å°ç”¨äºæ€§èƒ½ç»Ÿè®¡
                if source_path.is_dir():
                    total_size = self._get_directory_size(source_path)
                else:
                    total_size = source_path.stat().st_size
            else:
                piece_size_log2 = 18  # é»˜è®¤256KB
                # è·å–æ–‡ä»¶å¤§å°ç”¨äºæ€§èƒ½ç»Ÿè®¡
                if source_path.is_dir():
                    total_size = self._get_directory_size(source_path)
                else:
                    total_size = source_path.stat().st_size

            print(f"  â° åˆ¶ç§å¼€å§‹æ—¶é—´: {start_time_str}")

            # ä½¿ç”¨ mktorrent åˆ›å»ºç§å­
            result_path = self._create_torrent_mktorrent(source_path, output_file, piece_size_log2, progress_callback, total_size, creation_start_time)

            return result_path

        except Exception as e:
            # å³ä½¿å‡ºé”™ä¹Ÿæ˜¾ç¤ºè€—æ—¶
            creation_duration = time.time() - creation_start_time
            print(f"  âŒ åˆ¶ç§å¤±è´¥ï¼Œè€—æ—¶: {self._format_duration(creation_duration)}")
            raise TorrentCreationError(f"åˆ›å»ºç§å­æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")



    def _create_torrent_mktorrent(self, source_path: Path, output_file: Path,
                                 piece_size_log2: int, progress_callback,
                                 file_size_bytes: int = 0, creation_start_time: float = None) -> str:
        """ä½¿ç”¨ mktorrent åˆ›å»ºç§å­"""
        # è®°å½•mktorrentæ‰§è¡Œå¼€å§‹æ—¶é—´
        mktorrent_start_time = time.time()

        command = self._build_command(source_path, output_file, piece_size_log2, file_size_bytes)

        # è®°å½•è°ƒè¯•ä¿¡æ¯
        if piece_size_log2:
            actual_piece_size = 2 ** piece_size_log2
            print(f"  ğŸ”§ Pieceå¤§å°: 2^{piece_size_log2} = {actual_piece_size} bytes ({actual_piece_size // 1024} KB)")

        if progress_callback:
            progress_callback(f"æ­£åœ¨ä½¿ç”¨mktorrentåˆ›å»ºç§å­æ–‡ä»¶: {source_path.name}")

        print(f"  ğŸš€ å¼€å§‹æ‰§è¡Œ mktorrent...")

        # æ‰§è¡Œmktorrentå‘½ä»¤
        try:
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                check=True,
                timeout=3600,
                env=dict(os.environ, LANG='C', LC_ALL='C')
            )

            # è®°å½•æ‰§è¡Œç»“æœï¼ˆå¦‚æœéœ€è¦è°ƒè¯•ï¼‰
            if result.stderr:
                logger.warning(f"mktorrent stderr: {result.stderr}")

        except subprocess.CalledProcessError as e:
            error_msg = f"mktorrentæ‰§è¡Œå¤±è´¥: {e}"
            if e.stderr:
                error_msg += f"\né”™è¯¯ä¿¡æ¯: {e.stderr}"
            raise TorrentCreationError(error_msg)

        except subprocess.TimeoutExpired:
            raise TorrentCreationError("ç§å­åˆ›å»ºè¶…æ—¶")

        # è®¡ç®—mktorrentæ‰§è¡Œæ—¶é—´
        mktorrent_duration = time.time() - mktorrent_start_time

        if not output_file.exists():
            raise TorrentCreationError("ç§å­æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼šè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")

        # éªŒè¯ç§å­æ–‡ä»¶
        if not self.validate_torrent(output_file):
            raise TorrentCreationError("ç§å­æ–‡ä»¶éªŒè¯å¤±è´¥")

        # è®¡ç®—æ€»åˆ¶ç§æ—¶é—´å’Œæ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        if creation_start_time:
            total_duration = time.time() - creation_start_time
            end_time_str = datetime.now().strftime("%H:%M:%S")

            # è·å–ç§å­æ–‡ä»¶å¤§å°
            torrent_file_size = output_file.stat().st_size if output_file.exists() else 0

            print(f"\n  ğŸ‰ åˆ¶ç§å®Œæˆï¼")
            print(f"  âœ… å®Œæˆæ—¶é—´: {end_time_str}")
            print(f"  â±ï¸  æ€»è€—æ—¶: {self._format_duration(total_duration)}")
            print(f"  ğŸ”§ mktorrentè€—æ—¶: {self._format_duration(mktorrent_duration)}")

            # è®¡ç®—å‡†å¤‡æ—¶é—´ï¼ˆæ€»æ—¶é—´ - mktorrentæ—¶é—´ï¼‰
            prep_duration = total_duration - mktorrent_duration
            if prep_duration > 0.1:  # åªæœ‰å½“å‡†å¤‡æ—¶é—´è¶…è¿‡0.1ç§’æ—¶æ‰æ˜¾ç¤º
                print(f"  âš™ï¸  å‡†å¤‡è€—æ—¶: {self._format_duration(prep_duration)}")

            # æ˜¾ç¤ºè¯¦ç»†æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
            if file_size_bytes > 0:
                file_size_str = self._format_file_size(file_size_bytes)
                creation_speed = self._calculate_creation_speed(file_size_bytes, total_duration)
                mktorrent_speed = self._calculate_creation_speed(file_size_bytes, mktorrent_duration)

                print(f"\n  ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
                print(f"     ğŸ“ æºæ–‡ä»¶å¤§å°: {file_size_str}")
                print(f"     ğŸ“„ ç§å­æ–‡ä»¶å¤§å°: {self._format_file_size(torrent_file_size)}")
                print(f"     ğŸš€ æ€»ä½“åˆ¶ç§é€Ÿåº¦: {creation_speed}")
                print(f"     âš¡ mktorrenté€Ÿåº¦: {mktorrent_speed}")

                # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
                efficiency = (mktorrent_duration / total_duration) * 100 if total_duration > 0 else 0
                print(f"     ğŸ“ˆ åˆ¶ç§æ•ˆç‡: {efficiency:.1f}% (mktorrentå æ¯”)")

                # æä¾›æ€§èƒ½å»ºè®®
                self._show_performance_suggestions(file_size_bytes, total_duration, mktorrent_duration)

        if progress_callback:
            progress_callback(f"ç§å­æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {output_file.name}")

        return str(output_file)

    def create_torrents_batch(self, source_paths: List[Union[str, Path]],
                             progress_callback = None) -> List[Tuple[str, Optional[str], Optional[str]]]:
        """æ‰¹é‡åˆ›å»ºç§å­æ–‡ä»¶ - é«˜æ€§èƒ½å¹¶å‘å¤„ç†"""
        if not source_paths:
            return []

        results = []
        total_count = len(source_paths)

        # æ ¹æ®ä»»åŠ¡æ•°é‡é€‰æ‹©æœ€ä¼˜å¹¶å‘ç­–ç•¥
        if total_count <= 2:
            # å°‘é‡ä»»åŠ¡ä½¿ç”¨ä¸²è¡Œå¤„ç†ï¼Œé¿å…å¹¶å‘å¼€é”€
            for i, source_path in enumerate(source_paths):
                try:
                    if progress_callback:
                        progress_callback(f"æ­£åœ¨å¤„ç† ({i + 1}/{total_count}): {Path(source_path).name}")
                    result_path = self.create_torrent(source_path)
                    results.append((str(source_path), result_path, None))
                except Exception as e:
                    results.append((str(source_path), None, str(e)))
            return results

        def create_single_with_error_handling(args):
            index, source_path = args
            try:
                if progress_callback:
                    progress_callback(f"æ­£åœ¨å¤„ç† ({index + 1}/{total_count}): {Path(source_path).name}")

                result_path = self.create_torrent(source_path)
                return (str(source_path), result_path, None)
            except Exception as e:
                return (str(source_path), None, str(e))

        # å¯¹äº CPU å¯†é›†å‹ä»»åŠ¡ï¼Œä¼˜å…ˆä½¿ç”¨è¿›ç¨‹æ± 
        use_process_pool = total_count > 4 and self.max_workers > 2

        if use_process_pool:
            # ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†å¤§æ‰¹é‡ä»»åŠ¡
            try:
                with ProcessPoolExecutor(max_workers=min(self.max_workers, total_count, 4)) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_path = {
                        executor.submit(create_single_with_error_handling, (i, path)): path
                        for i, path in enumerate(source_paths)
                    }

                    # æ”¶é›†ç»“æœ
                    for future in as_completed(future_to_path):
                        try:
                            result = future.result()
                            results.append(result)
                        except Exception as e:
                            source_path = future_to_path[future]
                            results.append((str(source_path), None, str(e)))
            except Exception as e:
                # è¿›ç¨‹æ± å¤±è´¥æ—¶å›é€€åˆ°çº¿ç¨‹æ± 
                logger.warning(f"è¿›ç¨‹æ± æ‰§è¡Œå¤±è´¥ï¼Œå›é€€åˆ°çº¿ç¨‹æ± : {e}")
                use_process_pool = False

        if not use_process_pool:
            # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†ä¸­ç­‰æ‰¹é‡ä»»åŠ¡
            with ThreadPoolExecutor(max_workers=min(self.max_workers, total_count)) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_path = {
                    executor.submit(create_single_with_error_handling, (i, path)): path
                    for i, path in enumerate(source_paths)
                }

                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_path):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        source_path = future_to_path[future]
                        results.append((str(source_path), None, str(e)))

        return results

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯ - v1.5.1 ç¬¬äºŒé˜¶æ®µå¢å¼ºç‰ˆ"""
        stats = self.performance_monitor.get_all_stats()
        cache_stats = self.size_cache.get_cache_stats()
        memory_info = self.memory_manager.get_memory_usage()

        # è®¡ç®—æ€§èƒ½æ”¹è¿›æŒ‡æ ‡
        creation_stats = stats.get('total_torrent_creation', {})
        mktorrent_stats = stats.get('mktorrent_execution', {})
        piece_calc_stats = stats.get('piece_size_calculation', {})

        return {
            'performance': stats,
            'cache': cache_stats,
            'memory_management': {
                'current_usage_mb': memory_info.get('rss_mb', 0),
                'memory_limit_mb': self.memory_manager.max_memory_mb,
                'memory_efficiency': self._calculate_memory_efficiency(memory_info),
                'cleanup_needed': self.memory_manager.should_cleanup()
            },
            'piece_size_cache': {
                'cached_calculations': len(self._piece_size_cache),
                'cache_entries': list(self._piece_size_cache.keys())[:5]  # æ˜¾ç¤ºå‰5ä¸ª
            },
            'async_processing': {
                'max_concurrent_operations': self.async_processor.max_concurrent,
                'stream_chunk_size_mb': self.stream_processor.base_chunk_size / (1024 * 1024)
            },
            'summary': {
                'total_torrents_created': creation_stats.get('count', 0),
                'average_creation_time': creation_stats.get('average', 0),
                'average_mktorrent_time': mktorrent_stats.get('average', 0),
                'average_size_calculation_time': stats.get('directory_size_calculation', {}).get('average', 0),
                'average_piece_calculation_time': piece_calc_stats.get('average', 0),
                'cache_hit_rate': cache_stats.get('hit_rate', 0),
                'memory_usage_mb': memory_info.get('rss_mb', 0),
                'performance_grade': self._calculate_performance_grade_v2(creation_stats, cache_stats, memory_info)
            },
            'optimization_suggestions': self._generate_optimization_suggestions_v2(stats, cache_stats, memory_info)
        }

    def _calculate_memory_efficiency(self, memory_info: Dict) -> str:
        """è®¡ç®—å†…å­˜ä½¿ç”¨æ•ˆç‡"""
        usage_mb = memory_info.get('rss_mb', 0)
        limit_mb = self.memory_manager.max_memory_mb

        if usage_mb == 0:
            return "æœªçŸ¥"

        efficiency = (limit_mb - usage_mb) / limit_mb
        if efficiency > 0.7:
            return "ä¼˜ç§€"
        elif efficiency > 0.5:
            return "è‰¯å¥½"
        elif efficiency > 0.3:
            return "ä¸€èˆ¬"
        else:
            return "éœ€è¦ä¼˜åŒ–"

    def _calculate_performance_grade_v2(self, creation_stats: Dict, cache_stats: Dict, memory_info: Dict) -> str:
        """è®¡ç®—æ€§èƒ½ç­‰çº§ - v1.5.1 ç¬¬äºŒé˜¶æ®µç‰ˆæœ¬"""
        avg_time = creation_stats.get('average', 0)
        hit_rate = cache_stats.get('hit_rate', 0)
        memory_mb = memory_info.get('rss_mb', 0)

        # ç»¼åˆè¯„åˆ†ç³»ç»Ÿ
        time_score = 100 if avg_time < 10 else max(0, 100 - (avg_time - 10) * 3)
        cache_score = hit_rate * 100
        memory_score = max(0, 100 - memory_mb / 5)  # 500MB ä¸ºæ»¡åˆ†

        total_score = (time_score * 0.4 + cache_score * 0.3 + memory_score * 0.3)

        if total_score >= 90:
            return "ä¼˜ç§€ (A+)"
        elif total_score >= 80:
            return "è‰¯å¥½ (B+)"
        elif total_score >= 70:
            return "ä¸€èˆ¬ (C+)"
        elif total_score >= 60:
            return "åŠæ ¼ (D+)"
        else:
            return "éœ€è¦ä¼˜åŒ– (F)"

    def _generate_optimization_suggestions_v2(self, stats: Dict, cache_stats: Dict, memory_info: Dict) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®® - v1.5.1 ç¬¬äºŒé˜¶æ®µç‰ˆæœ¬"""
        suggestions = []

        # æ£€æŸ¥åˆ›å»ºæ—¶é—´
        creation_avg = stats.get('total_torrent_creation', {}).get('average', 0)
        if creation_avg > 30:
            suggestions.append("ç§å­åˆ›å»ºæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®æ£€æŸ¥ç£ç›˜æ€§èƒ½æˆ–å‡å°‘æ–‡ä»¶æ•°é‡")
        elif creation_avg > 15:
            suggestions.append("ç§å­åˆ›å»ºæ—¶é—´åé•¿ï¼Œå¯ä»¥è€ƒè™‘è°ƒæ•´ piece size æˆ–å¯ç”¨æ›´å¤šå¹¶å‘")

        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        hit_rate = cache_stats.get('hit_rate', 0)
        if hit_rate < 0.3:
            suggestions.append("ç¼“å­˜å‘½ä¸­ç‡å¾ˆä½ï¼Œå»ºè®®å¢åŠ ç¼“å­˜æ—¶é—´æˆ–æ£€æŸ¥é‡å¤æ“ä½œæ¨¡å¼")
        elif hit_rate < 0.6:
            suggestions.append("ç¼“å­˜å‘½ä¸­ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥")

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        memory_mb = memory_info.get('rss_mb', 0)
        if memory_mb > 400:
            suggestions.append("å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œå»ºè®®å¯ç”¨å†…å­˜æ¸…ç†æˆ–å‡å°‘ç¼“å­˜å¤§å°")
        elif memory_mb > 300:
            suggestions.append("å†…å­˜ä½¿ç”¨åé«˜ï¼Œå»ºè®®ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ")

        # æ£€æŸ¥ mktorrent æ‰§è¡Œæ—¶é—´ - é€‚åº”æ–°çš„ piece size ç­–ç•¥
        mktorrent_avg = stats.get('mktorrent_execution', {}).get('average', 0)
        if mktorrent_avg > 60:  # æé«˜é˜ˆå€¼ï¼Œé€‚åº”å¤§ piece size
            suggestions.append("mktorrent æ‰§è¡Œæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®æ£€æŸ¥ CPU æ€§èƒ½æˆ–ç£ç›˜ I/O æ€§èƒ½")

        # æ£€æŸ¥ç›®å½•æ‰«ææ€§èƒ½
        scan_avg = stats.get('directory_size_calculation', {}).get('average', 0)
        if scan_avg > 5:
            suggestions.append("ç›®å½•æ‰«æè¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨ SSD æˆ–å‡å°‘æ‰«ææ·±åº¦")

        if not suggestions:
            suggestions.append("ğŸ‰ æ€§èƒ½è¡¨ç°ä¼˜ç§€ï¼æ‰€æœ‰æŒ‡æ ‡éƒ½åœ¨æœ€ä½³èŒƒå›´å†…")

        return suggestions

    def _calculate_performance_grade(self, creation_stats: Dict, cache_stats: Dict) -> str:
        """è®¡ç®—æ€§èƒ½ç­‰çº§ - å…¼å®¹æ€§æ–¹æ³•"""
        return self._calculate_performance_grade_v2(creation_stats, cache_stats, {'rss_mb': 0})

    def _generate_optimization_suggestions(self, stats: Dict, cache_stats: Dict) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®® - å…¼å®¹æ€§æ–¹æ³•"""
        return self._generate_optimization_suggestions_v2(stats, cache_stats, {'rss_mb': 0})

    def clear_caches(self) -> Dict[str, int]:
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜ - v1.5.1 ç¬¬äºŒé˜¶æ®µå¢å¼ºç‰ˆ"""
        cleared_counts = {}

        # æ¸…ç†ç›®å½•å¤§å°ç¼“å­˜
        self.size_cache.clear_cache()
        cleared_counts['directory_size_cache'] = 0

        # æ¸…ç† piece size ç¼“å­˜
        piece_cache_count = len(self._piece_size_cache)
        self._piece_size_cache.clear()
        cleared_counts['piece_size_cache'] = piece_cache_count

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        expired_count = self.size_cache.cleanup_expired()
        cleared_counts['expired_entries'] = expired_count

        # v1.5.1 æ–°å¢ï¼šæ·±åº¦å†…å­˜ç®¡ç†æ¸…ç†
        memory_cleaned = self.memory_manager.cleanup_memory()
        cleared_counts.update(memory_cleaned)

        # è·å–å†…å­˜åˆ†æ
        memory_analysis = self.memory_manager.get_memory_analysis()
        cleared_counts['memory_analysis'] = {
            'freed_mb': memory_cleaned.get('freed_mb', 0),
            'trend': memory_analysis['memory_trend']['trend'],
            'recommendations': memory_analysis['recommendations'][:2]  # åªæ˜¾ç¤ºå‰2ä¸ªå»ºè®®
        }

        return cleared_counts

    def get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯ - v1.5.1 æ–°å¢"""
        memory_info = self.memory_manager.get_memory_usage()

        return {
            'version': VERSION,
            'optimization_level': f'{VERSION_NAME} - Single File',
            'features': [
                'Smart Piece Size Calculation',
                'LRU Directory Cache',
                'Multi-threaded mktorrent',
                'Intelligent Search Index',
                'Memory Management',
                'Async I/O Processing',
                'Stream File Processing'
            ],
            'memory_info': memory_info,
            'performance_grade': self._calculate_performance_grade_v2({}, {}, memory_info),
            'cache_status': {
                'directory_cache_size': len(self.size_cache._cache) if hasattr(self.size_cache, '_cache') else 0,
                'piece_cache_size': len(self._piece_size_cache)
            }
        }

    def validate_torrent(self, torrent_path: Union[str, Path]) -> bool:
        """éªŒè¯ç§å­æ–‡ä»¶çš„æœ‰æ•ˆæ€§"""
        try:
            torrent_path = Path(torrent_path)

            if not torrent_path.exists():
                return False

            if not torrent_path.suffix.lower() == '.torrent':
                return False

            file_size = torrent_path.stat().st_size
            if file_size == 0:
                return False

            try:
                with open(torrent_path, 'rb') as f:
                    header = f.read(10)
                    if not header.startswith(b'd'):
                        return False
            except Exception:
                return False

            return True

        except Exception:
            return False


# ================== æœç´¢å†å²ç®¡ç† ==================
class SearchHistory:
    """æœç´¢å†å²ç®¡ç†å™¨"""

    def __init__(self, config_dir: str = None, max_history: int = 50):
        """åˆå§‹åŒ–æœç´¢å†å²ç®¡ç†å™¨"""
        if config_dir is None:
            config_dir = os.path.expanduser("~/.torrent_maker")

        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(parents=True, exist_ok=True)

        self.history_file = self.config_dir / "search_history.json"
        self.max_history = max_history
        self.history: List[Dict[str, Any]] = []

        self._load_history()

    def _load_history(self):
        """åŠ è½½æœç´¢å†å²"""
        try:
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.history = data.get('history', [])
                    self._cleanup_old_history()
            else:
                self.history = []
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æœç´¢å†å²å¤±è´¥: {e}")
            self.history = []

    def _save_history(self):
        """ä¿å­˜æœç´¢å†å²"""
        try:
            data = {
                'history': self.history,
                'last_updated': datetime.now().isoformat()
            }
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æœç´¢å†å²å¤±è´¥: {e}")

    def _cleanup_old_history(self):
        """æ¸…ç†è¿‡æœŸçš„å†å²è®°å½•"""
        try:
            from datetime import timedelta
            cutoff_time = datetime.now() - timedelta(days=30)

            self.history = [
                item for item in self.history
                if datetime.fromisoformat(item.get('timestamp', '1970-01-01'))
                > cutoff_time
            ]

            if len(self.history) > self.max_history:
                self.history = self.history[-self.max_history:]

        except Exception as e:
            print(f"âš ï¸ æ¸…ç†å†å²è®°å½•å¤±è´¥: {e}")

    def add_search(self, query: str, results_count: int = 0,
                   resource_folder: str = None) -> None:
        """æ·»åŠ æœç´¢è®°å½•"""
        if not query or not query.strip():
            return

        query = query.strip()

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æœç´¢
        recent_queries = [item['query'] for item in self.history[-10:]]
        if query in recent_queries:
            for item in reversed(self.history):
                if item['query'] == query:
                    item['timestamp'] = datetime.now().isoformat()
                    item['count'] = item.get('count', 0) + 1
                    item['last_results_count'] = results_count
                    if resource_folder:
                        item['resource_folder'] = resource_folder
                    break
        else:
            record = {
                'query': query,
                'timestamp': datetime.now().isoformat(),
                'results_count': results_count,
                'count': 1,
                'last_results_count': results_count
            }

            if resource_folder:
                record['resource_folder'] = resource_folder

            self.history.append(record)

        if len(self.history) > self.max_history:
            self.history = self.history[-self.max_history:]

        self._save_history()

    def get_recent_searches(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„æœç´¢è®°å½•"""
        sorted_history = sorted(
            self.history,
            key=lambda x: x.get('timestamp', ''),
            reverse=True
        )
        return sorted_history[:limit]

    def get_recent_queries(self, limit: int = 10) -> List[str]:
        """è·å–æœ€è¿‘çš„æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²"""
        recent_searches = self.get_recent_searches(limit)
        return [item['query'] for item in recent_searches]

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æœç´¢å†å²ç»Ÿè®¡ä¿¡æ¯"""
        if not self.history:
            return {
                'total_searches': 0,
                'unique_queries': 0,
                'average_results': 0,
                'most_searched': None,
                'recent_activity': 0
            }

        total_searches = sum(item.get('count', 1) for item in self.history)
        unique_queries = len(self.history)

        results_counts = [item.get('last_results_count', 0) for item in self.history]
        average_results = sum(results_counts) / len(results_counts) if results_counts else 0

        most_searched = max(self.history, key=lambda x: x.get('count', 0))

        from datetime import timedelta
        recent_cutoff = datetime.now() - timedelta(days=7)
        recent_activity = sum(
            1 for item in self.history
            if datetime.fromisoformat(item.get('timestamp', '1970-01-01')) > recent_cutoff
        )

        return {
            'total_searches': total_searches,
            'unique_queries': unique_queries,
            'average_results': round(average_results, 1),
            'most_searched': most_searched,
            'recent_activity': recent_activity
        }

    def get_popular_queries(self, limit: int = 10) -> List[str]:
        """è·å–çƒ­é—¨æœç´¢æŸ¥è¯¢"""
        if not self.history:
            return []
        
        # æŒ‰æœç´¢æ¬¡æ•°æ’åº
        sorted_history = sorted(
            self.history,
            key=lambda x: x.get('count', 0),
            reverse=True
        )
        return [item['query'] for item in sorted_history[:limit]]

    def clear_history(self) -> bool:
        """æ¸…ç©ºæœç´¢å†å²"""
        try:
            self.history = []
            self._save_history()
            return True
        except Exception as e:
            print(f"âŒ æ¸…ç©ºæœç´¢å†å²å¤±è´¥: {e}")
            return False


# ================== ä¸»ç¨‹åº ==================
class TorrentMakerApp:
    """Torrent Maker ä¸»åº”ç”¨ç¨‹åº - v1.6.0 å½»åº•é‡æ„ç‰ˆ"""

    def __init__(self):
        self.config = ConfigManager()
        self.config_manager = self.config  # ä¸ºäº†å…¼å®¹æ€§æ·»åŠ åˆ«å
        self.matcher = None
        self.creator = None
        self.queue_manager = None  # é˜Ÿåˆ—ç®¡ç†å™¨
        self.status_display = QueueStatusDisplay()  # é˜Ÿåˆ—çŠ¶æ€æ˜¾ç¤ºç®¡ç†å™¨
        
        # é˜Ÿåˆ—æ˜¾ç¤ºé…ç½®
        self.queue_display_config = {
            'default_mode': 'standard',  # compact, standard, detailed
            'auto_update_interval': 2.0,  # è‡ªåŠ¨æ›´æ–°é—´éš”(ç§’)
            'show_progress': True,  # æ˜¯å¦æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
            'show_statistics': True,  # æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            'compact_on_start': True,  # ä»»åŠ¡å¯åŠ¨æ—¶ä½¿ç”¨ç®€æ´æ¨¡å¼
        }
        
        # åˆå§‹åŒ–å¢å¼ºåŠŸèƒ½æ¨¡å—
        if ENHANCED_FEATURES_AVAILABLE:
            self.search_history = SearchHistory()
            self.search_suggester = SmartSearchSuggester(self.search_history)
            self.path_completer = PathCompleter()
            self.progress_monitor = None  # å°†åœ¨éœ€è¦æ—¶åˆå§‹åŒ–
        else:
            self.search_history = None
            self.search_suggester = None
            self.path_completer = None
            self.progress_monitor = None
            
        self._init_components()

    def _init_components(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        try:
            # åˆå§‹åŒ–æ–‡ä»¶åŒ¹é…å™¨
            resource_folder = self.config.get_resource_folder()
            enable_cache = self.config.settings.get('enable_cache', True)
            cache_duration = self.config.settings.get('cache_duration', 3600)
            max_workers = self.config.settings.get('max_concurrent_operations', 4)

            self.matcher = FileMatcher(
                resource_folder,
                enable_cache=enable_cache,
                cache_duration=cache_duration,
                max_workers=max_workers
            )

            # åˆå§‹åŒ–ç§å­åˆ›å»ºå™¨
            trackers = self.config.get_trackers()
            output_folder = self.config.get_output_folder()

            self.creator = TorrentCreator(
                tracker_links=trackers,
                output_dir=output_folder,
                max_workers=max_workers,
                config_manager=self.config
            )
            
            # åˆå§‹åŒ–é˜Ÿåˆ—ç®¡ç†å™¨ï¼ˆå·²å†…ç½®ï¼‰
            try:
                # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿é˜Ÿåˆ—æ–‡ä»¶ä¿å­˜åœ¨æ­£ç¡®ä½ç½®
                queue_file = os.path.expanduser("~/.torrent_maker/torrent_queue.json")
                self.queue_manager = TorrentQueueManager(
                    self.creator,
                    max_concurrent=max_workers,
                    save_file=queue_file
                )
                # è®¾ç½®å›è°ƒå‡½æ•°
                self.queue_manager.set_callbacks(
                    on_task_start=self._on_queue_task_start,
                    on_task_complete=self._on_queue_task_complete,
                    on_task_failed=self._on_queue_task_failed,
                    on_progress_update=self._on_queue_progress_update
                )
            except Exception as e:
                print(f"âš ï¸ é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
                self.queue_manager = None

        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            sys.exit(1)

    def _check_queue_status_before_operation(self, operation_name: str) -> bool:
        """åœ¨æ‰§è¡Œæ“ä½œå‰æ£€æŸ¥é˜Ÿåˆ—è¿è¡ŒçŠ¶æ€"""
        if not self.queue_manager:
            return True  # å¦‚æœæ²¡æœ‰é˜Ÿåˆ—ç®¡ç†å™¨ï¼Œå…è®¸æ“ä½œ
            
        if self.queue_manager.is_running():
            print(f"\nâš ï¸ é˜Ÿåˆ—æ­£åœ¨è¿è¡Œä¸­")
            print(f"å½“å‰æ­£åœ¨æ‰§è¡Œåˆ¶ç§ä»»åŠ¡ï¼Œå»ºè®®ç­‰å¾…å®Œæˆåå†è¿›è¡Œ{operation_name}æ“ä½œã€‚")
            print("\né€‰æ‹©æ“ä½œ:")
            print("1. ğŸ”„ ç»§ç»­æ“ä½œï¼ˆå¯èƒ½å½±å“é˜Ÿåˆ—æ€§èƒ½ï¼‰")
            print("2. ğŸ“Š æŸ¥çœ‹é˜Ÿåˆ—çŠ¶æ€")
            print("3. â¸ï¸ æš‚åœé˜Ÿåˆ—åç»§ç»­")
            print("4. ğŸ”™ è¿”å›ä¸»èœå•")
            
            while True:
                choice = input("\nè¯·é€‰æ‹© (1-4): ").strip()
                if choice == '1':
                    print(f"\nâš¡ ç»§ç»­æ‰§è¡Œ{operation_name}æ“ä½œ...")
                    return True
                elif choice == '2':
                    self._display_enhanced_queue_status()
                    continue
                elif choice == '3':
                    if self.queue_manager.pause_queue():
                        print("\nâ¸ï¸ é˜Ÿåˆ—å·²æš‚åœ")
                        return True
                    else:
                        print("\nâŒ æš‚åœé˜Ÿåˆ—å¤±è´¥")
                        return False
                elif choice == '4':
                    return False
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        return True

    def _display_enhanced_queue_status(self):
        """æ˜¾ç¤ºå¢å¼ºçš„é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯ï¼ˆä½¿ç”¨è¯¦ç»†æ¨¡å¼ï¼‰"""
        self.status_display.display_status(self.queue_manager, mode="detailed", force_update=True)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = status['statistics']
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»ä»»åŠ¡æ•°: {status['total_tasks']}")
        print(f"  å·²å®Œæˆ: {stats['completed_tasks']}")
        print(f"  å¤±è´¥: {stats['failed_tasks']}")
        print(f"  æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        if stats['average_processing_time'] > 0:
            print(f"  å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.1f}ç§’")
        
        print("\n" + "=" * 60)

    def _add_queue_task_interactive(self, queue_manager):
        """äº¤äº’å¼æ·»åŠ é˜Ÿåˆ—ä»»åŠ¡"""
        print("\n" + "=" * 50)
        print("           â• æ·»åŠ åˆ¶ç§ä»»åŠ¡")
        print("=" * 50)
        
        # è·å–æ–‡ä»¶è·¯å¾„
        if self.path_completer:
            file_path = self.path_completer.get_input("è¯·è¾“å…¥æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„: ")
        else:
            file_path = input("è¯·è¾“å…¥æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
        
        if not file_path:
            print("âŒ è·¯å¾„ä¸èƒ½ä¸ºç©º")
            return
            
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {file_path}")
            return
        
        # é€‰æ‹©é¢„è®¾é…ç½®
        print("\né€‰æ‹©é¢„è®¾é…ç½®:")
        presets = ['standard', 'high_quality', 'fast', 'custom']
        for i, preset in enumerate(presets, 1):
            print(f"{i}. {preset}")
        
        preset_choice = input("\nè¯·é€‰æ‹©é¢„è®¾ (1-4, é»˜è®¤1): ").strip()
        try:
            preset_index = int(preset_choice) - 1 if preset_choice else 0
            if 0 <= preset_index < len(presets):
                preset = presets[preset_index]
            else:
                preset = 'standard'
        except ValueError:
            preset = 'standard'
        
        # é€‰æ‹©ä¼˜å…ˆçº§
        print("\né€‰æ‹©ä»»åŠ¡ä¼˜å…ˆçº§:")
        print("1. ä½")
        print("2. æ™®é€š")
        print("3. é«˜")
        
        priority_choice = input("\nè¯·é€‰æ‹©ä¼˜å…ˆçº§ (1-3, é»˜è®¤2): ").strip()
        try:
            priority_index = int(priority_choice) - 1 if priority_choice else 1
            priorities = [TaskPriority.LOW, TaskPriority.NORMAL, TaskPriority.HIGH]
            if 0 <= priority_index < len(priorities):
                priority = priorities[priority_index]
            else:
                priority = TaskPriority.NORMAL
        except ValueError:
            priority = TaskPriority.NORMAL
        
        # æ·»åŠ ä»»åŠ¡
        try:
            task_id = queue_manager.add_torrent_task(file_path, preset, priority)
            print(f"\nâœ… ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—")
            print(f"ğŸ“‹ ä»»åŠ¡ID: {task_id}")
            print(f"ğŸ“ è·¯å¾„: {file_path}")
            print(f"âš™ï¸ é¢„è®¾: {preset}")
            print(f"ğŸ”¥ ä¼˜å…ˆçº§: {priority.value}")
        except Exception as e:
            print(f"âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥: {e}")
    
    def _parse_task_selection(self, input_str: str, max_index: int) -> tuple[list[int], str]:
        """è§£æä»»åŠ¡é€‰æ‹©è¾“å…¥
        
        Args:
            input_str: ç”¨æˆ·è¾“å…¥å­—ç¬¦ä¸²
            max_index: æœ€å¤§ä»»åŠ¡ç´¢å¼•
            
        Returns:
            tuple: (ç´¢å¼•åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        input_str = input_str.strip().lower()
        
        # å¤„ç†ç‰¹æ®Šå‘½ä»¤
        if input_str in ['0', 'cancel', 'å–æ¶ˆ']:
            return [], "cancelled"
        if input_str in ['all', '*', 'å…¨éƒ¨']:
            return list(range(max_index)), ""
            
        try:
            indices = set()
            
            # åˆ†å‰²é€—å·åˆ†éš”çš„éƒ¨åˆ†
            parts = [part.strip() for part in input_str.split(',')]
            
            for part in parts:
                if '-' in part:
                    # å¤„ç†èŒƒå›´ (å¦‚ 1-5)
                    range_parts = part.split('-')
                    if len(range_parts) != 2 or not range_parts[0] or not range_parts[1]:
                        return [], f"æ— æ•ˆçš„èŒƒå›´æ ¼å¼: {part}"
                    
                    try:
                        start = int(range_parts[0]) - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                        end = int(range_parts[1]) - 1
                    except ValueError:
                        return [], f"æ— æ•ˆçš„èŒƒå›´æ ¼å¼: {part}"
                    
                    if start > end:
                        return [], f"èŒƒå›´èµ·å§‹å€¼ä¸èƒ½å¤§äºç»“æŸå€¼: {part}"
                    if start < 0 or end >= max_index:
                        return [], f"èŒƒå›´è¶…å‡ºæœ‰æ•ˆç´¢å¼• (1-{max_index}): {part}"
                        
                    indices.update(range(start, end + 1))
                else:
                    # å¤„ç†å•ä¸ªæ•°å­—
                    index = int(part) - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                    if index < 0 or index >= max_index:
                        return [], f"ç´¢å¼•è¶…å‡ºèŒƒå›´ (1-{max_index}): {part}"
                    indices.add(index)
                    
            return sorted(list(indices)), ""
            
        except ValueError:
            return [], "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ã€èŒƒå›´æˆ–é€—å·åˆ†éš”çš„ç»„åˆ"
        except Exception as e:
            return [], f"è§£æè¾“å…¥æ—¶å‡ºé”™: {e}"
    
    def _confirm_batch_deletion(self, tasks_to_delete: list, task_list: list) -> bool:
        """ç¡®è®¤æ‰¹é‡åˆ é™¤æ“ä½œ
        
        Args:
            tasks_to_delete: è¦åˆ é™¤çš„ä»»åŠ¡ç´¢å¼•åˆ—è¡¨
            task_list: å®Œæ•´ä»»åŠ¡åˆ—è¡¨
            
        Returns:
            bool: ç”¨æˆ·æ˜¯å¦ç¡®è®¤åˆ é™¤
        """
        if len(tasks_to_delete) == 1:
            # å•ä¸ªä»»åŠ¡åˆ é™¤
            task = task_list[tasks_to_delete[0]]
            if task.status == TaskStatus.RUNNING:
                print(f"\nâš ï¸ ä»»åŠ¡ '{task.name}' æ­£åœ¨è¿è¡Œä¸­")
                confirm = input("ç¡®è®¤è¦å¼ºåˆ¶åˆ é™¤æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å—? (y/N): ").strip().lower()
                return confirm in ['y', 'yes', 'æ˜¯']
            else:
                confirm = input(f"\nç¡®è®¤åˆ é™¤ä»»åŠ¡ '{task.name}'? (y/N): ").strip().lower()
                return confirm in ['y', 'yes', 'æ˜¯']
        else:
            # æ‰¹é‡åˆ é™¤ç¡®è®¤
            print(f"\nğŸ“‹ å°†è¦åˆ é™¤ {len(tasks_to_delete)} ä¸ªä»»åŠ¡:")
            print("-" * 60)
            
            running_count = 0
            for i, task_index in enumerate(tasks_to_delete[:10], 1):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                task = task_list[task_index]
                status_icon = {
                    TaskStatus.WAITING: 'â³',
                    TaskStatus.RUNNING: 'ğŸ”„',
                    TaskStatus.COMPLETED: 'âœ…',
                    TaskStatus.FAILED: 'âŒ',
                    TaskStatus.CANCELLED: 'ğŸš«'
                }.get(task.status, 'â“')
                
                if task.status == TaskStatus.RUNNING:
                    running_count += 1
                    
                print(f"{i:2d}. {task.name[:40]:<40} {status_icon}{task.status.value}")
                
            if len(tasks_to_delete) > 10:
                print(f"    ... è¿˜æœ‰ {len(tasks_to_delete) - 10} ä¸ªä»»åŠ¡")
                
            print("-" * 60)
            
            if running_count > 0:
                print(f"âš ï¸ è­¦å‘Š: å…¶ä¸­ {running_count} ä¸ªä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œåˆ é™¤å°†å¼ºåˆ¶åœæ­¢")
                
            confirm = input(f"\nç¡®è®¤æ‰¹é‡åˆ é™¤è¿™ {len(tasks_to_delete)} ä¸ªä»»åŠ¡? (y/N): ").strip().lower()
            return confirm in ['y', 'yes', 'æ˜¯']

    def _remove_queue_task_interactive(self, queue_manager):
        """äº¤äº’å¼åˆ é™¤é˜Ÿåˆ—ä»»åŠ¡ï¼ˆæ”¯æŒæ‰¹é‡åˆ é™¤ï¼‰"""
        print("\n" + "=" * 50)
        print("           â– åˆ é™¤é˜Ÿåˆ—ä»»åŠ¡")
        print("=" * 50)
        
        # è·å–æ‰€æœ‰ä»»åŠ¡
        all_tasks = queue_manager.get_all_tasks()
        if not all_tasks:
            print("\nğŸ“­ é˜Ÿåˆ—ä¸ºç©ºï¼Œæ²¡æœ‰ä»»åŠ¡å¯åˆ é™¤")
            return
        
        # æ˜¾ç¤ºä»»åŠ¡åˆ—è¡¨
        print("\nğŸ“‹ å½“å‰ä»»åŠ¡åˆ—è¡¨:")
        print("-" * 80)
        print(f"{'åºå·':<4} {'ä»»åŠ¡åç§°':<30} {'çŠ¶æ€':<10} {'ä¼˜å…ˆçº§':<8}")
        print("-" * 80)
        
        task_list = []
        for i, task in enumerate(all_tasks, 1):
            status_icon = {
                TaskStatus.WAITING: 'â³',
                TaskStatus.RUNNING: 'ğŸ”„',
                TaskStatus.COMPLETED: 'âœ…',
                TaskStatus.FAILED: 'âŒ',
                TaskStatus.CANCELLED: 'ğŸš«'
            }.get(task.status, 'â“')
            
            print(f"{i:<4} {task.name[:29]:<30} {status_icon}{task.status.value:<9} {task.priority.value:<8}")
            task_list.append(task)
        
        print("-" * 80)
        
        # æ˜¾ç¤ºè¾“å…¥æç¤º
        print("\nğŸ’¡ æ”¯æŒçš„è¾“å…¥æ ¼å¼:")
        print("   å•ä¸ª: 5          åˆ é™¤ç¬¬5ä¸ªä»»åŠ¡")
        print("   èŒƒå›´: 1-12       åˆ é™¤ç¬¬1åˆ°12ä¸ªä»»åŠ¡")
        print("   åˆ—è¡¨: 1,3,5      åˆ é™¤ç¬¬1ã€3ã€5ä¸ªä»»åŠ¡")
        print("   æ··åˆ: 1-3,5,8-10 åˆ é™¤ç¬¬1-3ã€5ã€8-10ä¸ªä»»åŠ¡")
        print("   å…¨éƒ¨: all æˆ– *   åˆ é™¤æ‰€æœ‰ä»»åŠ¡")
        print("   å–æ¶ˆ: 0 æˆ– cancel")
        
        # è·å–ç”¨æˆ·é€‰æ‹©
        choice = input(f"\nè¯·é€‰æ‹©è¦åˆ é™¤çš„ä»»åŠ¡ (æ”¯æŒä¸Šè¿°æ ¼å¼): ").strip()
        
        # è§£æç”¨æˆ·è¾“å…¥
        task_indices, error_msg = self._parse_task_selection(choice, len(task_list))
        
        if error_msg == "cancelled":
            print("âŒ å·²å–æ¶ˆåˆ é™¤æ“ä½œ")
            return
        elif error_msg:
            print(f"âŒ {error_msg}")
            return
        elif not task_indices:
            print("âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•ä»»åŠ¡")
            return
            
        # ç¡®è®¤åˆ é™¤
        if not self._confirm_batch_deletion(task_indices, task_list):
            print("âŒ å·²å–æ¶ˆåˆ é™¤æ“ä½œ")
            return
            
        # æ‰§è¡Œæ‰¹é‡åˆ é™¤
        success_count = 0
        failed_count = 0
        
        print(f"\nğŸ”„ å¼€å§‹åˆ é™¤ {len(task_indices)} ä¸ªä»»åŠ¡...")
        
        for i, task_index in enumerate(task_indices, 1):
            task = task_list[task_index]
            print(f"[{i}/{len(task_indices)}] åˆ é™¤: {task.name[:40]}...", end=" ")
            
            try:
                if queue_manager.remove_task(task.id):
                    print("âœ…")
                    success_count += 1
                else:
                    print("âŒ")
                    failed_count += 1
            except Exception as e:
                print(f"âŒ ({e})")
                failed_count += 1
                
        # æ˜¾ç¤ºåˆ é™¤ç»“æœç»Ÿè®¡
        print(f"\nğŸ“Š åˆ é™¤å®Œæˆ:")
        print(f"   âœ… æˆåŠŸ: {success_count} ä¸ª")
        if failed_count > 0:
            print(f"   âŒ å¤±è´¥: {failed_count} ä¸ª")
        print(f"   ğŸ“‹ æ€»è®¡: {len(task_indices)} ä¸ª")

    def display_header(self):
        """æ˜¾ç¤ºç¨‹åºå¤´éƒ¨ä¿¡æ¯"""
        print("ğŸ¬" + "=" * 60)
        print(f"           {FULL_VERSION_INFO}")
        print("           åŸºäº mktorrent çš„ç§å­åˆ¶ä½œå·¥å…·")
        print("=" * 62)
        print()
        print(f"ğŸ¯ v{VERSION} {VERSION_NAME}æ›´æ–°:")
        print("  ğŸ¨ ç‰ˆæœ¬ä¿¡æ¯æ˜¾ç¤ºä¼˜åŒ–ï¼ˆç®€æ´æ¸…æ™°çš„ç•Œé¢å±•ç¤ºï¼‰")
        print("  ğŸ”§ é¢„è®¾é…ç½®æ–‡ä»¶è‡ªåŠ¨åˆå§‹åŒ–ï¼ˆè§£å†³æ–‡ä»¶ç¼ºå¤±é—®é¢˜ï¼‰")
        print("  âš¡ é˜Ÿåˆ—ç®¡ç†å‚æ•°ä¿®å¤ï¼ˆæå‡ç³»ç»Ÿç¨³å®šæ€§ï¼‰")
        print("  ğŸ“‹ ç¨‹åºå¯åŠ¨æµç¨‹ä¼˜åŒ–ï¼ˆæ›´å¿«çš„å“åº”é€Ÿåº¦ï¼‰")
        print("  ğŸš€ ç”¨æˆ·ä½“éªŒæŒç»­æ”¹è¿›ï¼ˆä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½å±•ç¤ºï¼‰")
        print()

    def display_menu(self):
        """æ˜¾ç¤ºä¸»èœå•"""
        print("ğŸ“‹ ä¸»èœå•:")
        print("  1. ğŸ” æœç´¢å¹¶åˆ¶ä½œç§å­")
        print("  2. âš¡ å¿«é€Ÿåˆ¶ç§ (ç›´æ¥è¾“å…¥è·¯å¾„)")
        print("  3. ğŸ“ æ‰¹é‡åˆ¶ç§")
        print("  4. âš™ï¸  é…ç½®ç®¡ç†")
        print("  5. ğŸ“Š æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡")
        print("  6. ğŸ”„ é˜Ÿåˆ—ç®¡ç†")
        if ENHANCED_FEATURES_AVAILABLE:
            print("  7. ğŸ“ æœç´¢å†å²ç®¡ç†")
            print("  8. â“ å¸®åŠ©")
            print("  0. ğŸšª é€€å‡º")
        else:
            print("  7. â“ å¸®åŠ©")
            print("  0. ğŸšª é€€å‡º")
        print()

    def search_and_create(self):
        """æœç´¢å¹¶åˆ¶ä½œç§å­"""
        # æ£€æŸ¥é˜Ÿåˆ—è¿è¡ŒçŠ¶æ€
        if not self._check_queue_status_before_operation("æœç´¢å¹¶åˆ¶ç§"):
            return
            
        while True:
            # æ˜¾ç¤ºæœç´¢å»ºè®®ï¼ˆå¦‚æœæœ‰å¢å¼ºåŠŸèƒ½ï¼‰
            recent_searches = []
            if self.search_history:
                recent_searches = self.search_history.get_recent_queries(5)
                if recent_searches:
                    print("\nğŸ“ æœ€è¿‘æœç´¢:")
                    for i, search in enumerate(recent_searches, 1):
                        # å…¼å®¹ä¸åŒçš„æ•°æ®ç»“æ„
                        if isinstance(search, str):
                            print(f"  {i}. {search}")
                        elif hasattr(search, 'query'):
                            result_count = getattr(search, 'result_count', 0)
                            print(f"  {i}. {search.query} (ç»“æœ: {result_count})")
                        else:
                            print(f"  {i}. {search}")
                    print()
            
            # è·å–ç”¨æˆ·è¾“å…¥ï¼ˆæ”¯æŒè·¯å¾„è¡¥å…¨å’Œå¿«æ·é”®é€‰æ‹©ï¼‰
            if recent_searches:
                prompt = "ğŸ” è¯·è¾“å…¥è¦æœç´¢çš„å½±è§†å‰§åç§° (è¾“å…¥æ•°å­—1-5é€‰æ‹©å†å²æœç´¢ï¼Œå›è½¦è¿”å›ä¸»èœå•): "
            else:
                prompt = "ğŸ” è¯·è¾“å…¥è¦æœç´¢çš„å½±è§†å‰§åç§° (å›è½¦è¿”å›ä¸»èœå•): "
            
            if self.path_completer:
                search_name = self.path_completer.get_input(prompt)
            else:
                search_name = input(prompt).strip()
                
            if not search_name:
                break
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¿«æ·é”®é€‰æ‹©ï¼ˆæ•°å­—1-5ï¼‰
            if search_name.isdigit() and recent_searches:
                choice_num = int(search_name)
                if 1 <= choice_num <= len(recent_searches):
                    selected_search = recent_searches[choice_num - 1]
                    # å…¼å®¹ä¸åŒçš„æ•°æ®ç»“æ„
                    if isinstance(selected_search, str):
                        search_name = selected_search
                    elif hasattr(selected_search, 'query'):
                        search_name = selected_search.query
                    else:
                        search_name = str(selected_search)
                    print(f"\nâœ¨ å·²é€‰æ‹©å†å²æœç´¢: {search_name}")
                else:
                    print(f"âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-{len(recent_searches)}ä¹‹é—´çš„æ•°å­—")
                    continue

            print(f"\nğŸ”„ æ­£åœ¨æœç´¢ '{search_name}'...")
            start_time = time.time()

            try:
                results = self.matcher.match_folders(search_name)
                search_time = time.time() - start_time
                
                # è®°å½•æœç´¢å†å²
                if self.search_history:
                    self.search_history.add_search(search_name, len(results), search_time)

                if not results:
                    print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¤¹ (æœç´¢è€—æ—¶: {search_time:.3f}s)")
                    
                    # æä¾›æ™ºèƒ½æœç´¢å»ºè®®
                    if self.search_suggester:
                        suggestions = self.search_suggester.get_search_suggestions(search_name)
                        if suggestions:
                            print("\nğŸ’¡ æœç´¢å»ºè®®:")
                            for suggestion in suggestions:
                                print(f"  â€¢ {suggestion}")
                    
                    # è¯¢é—®æ˜¯å¦ç»§ç»­æœç´¢
                    while True:
                        continue_choice = input("æ˜¯å¦ç»§ç»­æœç´¢å…¶ä»–å†…å®¹ï¼Ÿ(y/n): ").strip().lower()
                        if continue_choice in ['n', 'no', 'å¦']:
                            return  # è¿”å›ä¸»èœå•
                        elif continue_choice in ['y', 'yes', 'æ˜¯', '']:
                            break  # ç»§ç»­æœç´¢å¾ªç¯
                        else:
                            print("è¯·è¾“å…¥ y(æ˜¯) æˆ– n(å¦)")
                    continue

                print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…ç»“æœ (æœç´¢è€—æ—¶: {search_time:.3f}s)")
                print()

                # æ˜¾ç¤ºæœç´¢ç»“æœ
                for i, result in enumerate(results, 1):
                    status = "âœ…" if result['readable'] else "âŒ"
                    print(f"  {i:2d}. {status} {result['name']}")
                    print(f"      ğŸ“Š åŒ¹é…åº¦: {result['score']}% | ğŸ“ æ–‡ä»¶: {result['file_count']}ä¸ª | ğŸ’¾ å¤§å°: {result['size']}")
                    if result['episodes']:
                        print(f"      ğŸ¬ å‰§é›†: {result['episodes']}")
                    # æ˜¾ç¤ºæ–‡ä»¶å¤¹è·¯å¾„
                    folder_path = result['path']
                    # å¦‚æœè·¯å¾„å¤ªé•¿ï¼Œæ˜¾ç¤ºç›¸å¯¹è·¯å¾„æˆ–ç¼©çŸ­è·¯å¾„
                    if len(folder_path) > 80:
                        # å°è¯•æ˜¾ç¤ºç›¸å¯¹äºèµ„æºæ–‡ä»¶å¤¹çš„è·¯å¾„
                        resource_folder = self.config.get_resource_folder()
                        if folder_path.startswith(resource_folder):
                            relative_path = os.path.relpath(folder_path, resource_folder)
                            print(f"      ğŸ“‚ è·¯å¾„: .../{relative_path}")
                        else:
                            # å¦‚æœè·¯å¾„å¤ªé•¿ï¼Œæ˜¾ç¤ºå¼€å¤´å’Œç»“å°¾
                            print(f"      ğŸ“‚ è·¯å¾„: {folder_path[:30]}...{folder_path[-30:]}")
                    else:
                        print(f"      ğŸ“‚ è·¯å¾„: {folder_path}")
                    print()

                # é€‰æ‹©æ–‡ä»¶å¤¹
                choice = input("è¯·é€‰æ‹©è¦åˆ¶ä½œç§å­çš„æ–‡ä»¶å¤¹ç¼–å· (æ”¯æŒå¤šé€‰ï¼Œå¦‚: 1,3,5ï¼Œå›è½¦è·³è¿‡): ").strip()
                if not choice:
                    # è¯¢é—®æ˜¯å¦ç»§ç»­æœç´¢
                    while True:
                        continue_choice = input("æ˜¯å¦ç»§ç»­æœç´¢å…¶ä»–å†…å®¹ï¼Ÿ(y/n): ").strip().lower()
                        if continue_choice in ['n', 'no', 'å¦']:
                            return  # è¿”å›ä¸»èœå•
                        elif continue_choice in ['y', 'yes', 'æ˜¯', '']:
                            break  # ç»§ç»­æœç´¢å¾ªç¯
                        else:
                            print("è¯·è¾“å…¥ y(æ˜¯) æˆ– n(å¦)")
                    continue

                # è§£æé€‰æ‹©å¹¶æ‰§è¡Œæ‰¹é‡åˆ¶ç§
                selected_results = self._parse_selection(choice, results)
                if selected_results:
                    self._execute_batch_creation(selected_results)
                else:
                    print("âŒ æ— æ•ˆçš„é€‰æ‹©æ ¼å¼")
                    # è¯¢é—®æ˜¯å¦ç»§ç»­æœç´¢
                    while True:
                        continue_choice = input("æ˜¯å¦ç»§ç»­æœç´¢å…¶ä»–å†…å®¹ï¼Ÿ(y/n): ").strip().lower()
                        if continue_choice in ['n', 'no', 'å¦']:
                            return  # è¿”å›ä¸»èœå•
                        elif continue_choice in ['y', 'yes', 'æ˜¯', '']:
                            break  # ç»§ç»­æœç´¢å¾ªç¯
                        else:
                            print("è¯·è¾“å…¥ y(æ˜¯) æˆ– n(å¦)")
                    continue

                # è¯¢é—®æ˜¯å¦ç»§ç»­æœç´¢
                while True:
                    continue_choice = input("\næ˜¯å¦ç»§ç»­æœç´¢å…¶ä»–å†…å®¹ï¼Ÿ(y/n): ").strip().lower()
                    if continue_choice in ['n', 'no', 'å¦']:
                        return  # è¿”å›ä¸»èœå•
                    elif continue_choice in ['y', 'yes', 'æ˜¯', '']:
                        break  # ç»§ç»­æœç´¢å¾ªç¯
                    else:
                        print("è¯·è¾“å…¥ y(æ˜¯) æˆ– n(å¦)")

            except (UnicodeDecodeError, UnicodeEncodeError) as e:
                print(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿç¼–ç é”™è¯¯: {e}")
                print("ğŸ’¡ å»ºè®®: æ£€æŸ¥èµ„æºæ–‡ä»¶å¤¹ä¸­æ˜¯å¦æœ‰åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡ä»¶å")
                print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ: å¯ä»¥å°è¯•é‡å‘½åæœ‰é—®é¢˜çš„æ–‡ä»¶å¤¹ï¼Œæˆ–æ¸…ç†ç¼“å­˜")

                # æä¾›æ¸…ç†ç¼“å­˜é€‰é¡¹
                clear_cache = input("æ˜¯å¦æ¸…ç†ç¼“å­˜å¹¶é‡è¯•ï¼Ÿ(y/n): ").strip().lower()
                if clear_cache in ['y', 'yes', 'æ˜¯']:
                    try:
                        if hasattr(self.matcher, 'cache') and self.matcher.cache:
                            self.matcher.cache._cache.clear()
                            print("âœ… ç¼“å­˜å·²æ¸…ç†")
                        if hasattr(self.matcher, 'folder_info_cache') and self.matcher.folder_info_cache:
                            self.matcher.folder_info_cache._cache.clear()
                            print("âœ… æ–‡ä»¶å¤¹ä¿¡æ¯ç¼“å­˜å·²æ¸…ç†")
                        continue  # é‡æ–°å°è¯•æœç´¢
                    except Exception as cache_e:
                        print(f"âš ï¸ æ¸…ç†ç¼“å­˜æ—¶å‡ºé”™: {cache_e}")

                # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿè¯¢é—®æ˜¯å¦ç»§ç»­
                while True:
                    continue_choice = input("\næ˜¯å¦ç»§ç»­æœç´¢å…¶ä»–å†…å®¹ï¼Ÿ(y/n): ").strip().lower()
                    if continue_choice in ['n', 'no', 'å¦']:
                        return  # è¿”å›ä¸»èœå•
                    elif continue_choice in ['y', 'yes', 'æ˜¯', '']:
                        break  # ç»§ç»­æœç´¢å¾ªç¯
                    else:
                        print("è¯·è¾“å…¥ y(æ˜¯) æˆ– n(å¦)")

            except Exception as e:
                print(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                print(f"âŒ é”™è¯¯ç±»å‹: {type(e).__name__}")

                # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿè¯¢é—®æ˜¯å¦ç»§ç»­
                while True:
                    continue_choice = input("\næ˜¯å¦ç»§ç»­æœç´¢å…¶ä»–å†…å®¹ï¼Ÿ(y/n): ").strip().lower()
                    if continue_choice in ['n', 'no', 'å¦']:
                        return  # è¿”å›ä¸»èœå•
                    elif continue_choice in ['y', 'yes', 'æ˜¯', '']:
                        break  # ç»§ç»­æœç´¢å¾ªç¯
                    else:
                        print("è¯·è¾“å…¥ y(æ˜¯) æˆ– n(å¦)")

    def _create_single_torrent(self, folder_info: Dict[str, Any]) -> bool:
        """åˆ›å»ºå•ä¸ªç§å­æ–‡ä»¶"""
        try:
            folder_path = folder_info['path']
            folder_name = folder_info['name']

            # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
            print(f"\n" + "="*60)
            print(f"ğŸ”„ å¼€å§‹åˆ¶ç§: {folder_name}")
            print(f"ğŸ“ æºè·¯å¾„: {folder_path}")
            print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
            print("="*60)

            # åˆå§‹åŒ–è¿›åº¦ç›‘æ§
            if ENHANCED_FEATURES_AVAILABLE and self.progress_monitor is None:
                self.progress_monitor = TorrentProgressMonitor()
            
            def progress_callback(message):
                print(f"  ğŸ“ˆ {message}")
                if self.progress_monitor:
                    self.progress_monitor.update_progress(message)

            # è®°å½•å¼€å§‹æ—¶é—´ç”¨äºæ€»ä½“ç»Ÿè®¡
            start_time = time.time()
            
            # å¯åŠ¨è¿›åº¦ç›‘æ§
            if self.progress_monitor:
                self.progress_monitor.start_monitoring(folder_name, folder_path)

            torrent_path = self.creator.create_torrent(
                folder_path,
                folder_name,
                progress_callback
            )
            
            # åœæ­¢è¿›åº¦ç›‘æ§
            if self.progress_monitor:
                self.progress_monitor.stop_monitoring()

            if torrent_path and self.creator.validate_torrent(torrent_path):
                # è®¡ç®—æ€»è€—æ—¶
                total_time = time.time() - start_time

                print(f"\nğŸ‰ åˆ¶ç§æˆåŠŸå®Œæˆ!")
                print(f"âœ… ç§å­æ–‡ä»¶: {os.path.basename(torrent_path)}")
                print(f"ğŸ“ ä¿å­˜ä½ç½®: {os.path.dirname(torrent_path)}")
                print(f"â±ï¸  æ€»è€—æ—¶: {self.creator._format_duration(total_time)}")
                print("="*60)
                return True
            else:
                print(f"\nâŒ åˆ¶ç§å¤±è´¥!")
                print(f"âŒ ç§å­åˆ›å»ºå¤±è´¥æˆ–éªŒè¯å¤±è´¥")
                print("="*60)
                return False

        except Exception as e:
            print(f"\nâŒ åˆ¶ç§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯!")
            print(f"âŒ é”™è¯¯ä¿¡æ¯: {e}")
            print("="*60)
            return False

    def quick_create(self):
        """å¿«é€Ÿåˆ¶ç§"""
        # æ£€æŸ¥é˜Ÿåˆ—è¿è¡ŒçŠ¶æ€
        if not self._check_queue_status_before_operation("å¿«é€Ÿåˆ¶ç§"):
            return
            
        print("\n" + "="*60)
        print("âš¡ å¿«é€Ÿåˆ¶ç§æ¨¡å¼")
        print("="*60)
        print("æ”¯æŒæ ¼å¼:")
        print("  - å•ä¸ªè·¯å¾„: /path/to/folder")
        print("  - å¤šä¸ªè·¯å¾„: /path1;/path2;/path3")
        print("="*60)

        # ä½¿ç”¨è·¯å¾„è¡¥å…¨åŠŸèƒ½è·å–è¾“å…¥
        if self.path_completer:
            paths_input = self.path_completer.get_input("è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„: ")
        else:
            paths_input = input("è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
            
        if not paths_input:
            return

        paths = [p.strip() for p in paths_input.split(';') if p.strip()]

        # æ˜¾ç¤ºä»»åŠ¡æ¦‚è§ˆ
        print(f"\nğŸ“‹ ä»»åŠ¡æ¦‚è§ˆ:")
        print(f"   ğŸ“ å¾…å¤„ç†è·¯å¾„æ•°: {len(paths)}")
        print(f"   â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")

        # è®°å½•æ€»å¼€å§‹æ—¶é—´
        total_start_time = time.time()
        success_count = 0

        for i, path in enumerate(paths, 1):
            expanded_path = os.path.expanduser(path)
            if os.path.exists(expanded_path):
                print(f"\n[{i}/{len(paths)}] å¤„ç†è·¯å¾„: {expanded_path}")
                folder_info = {
                    'path': expanded_path,
                    'name': os.path.basename(expanded_path)
                }
                if self._create_single_torrent(folder_info):
                    success_count += 1
            else:
                print(f"\n[{i}/{len(paths)}] âŒ è·¯å¾„ä¸å­˜åœ¨: {expanded_path}")

        # æ˜¾ç¤ºæ€»ç»“
        total_duration = time.time() - total_start_time
        print(f"\n" + "="*60)
        print(f"ğŸ‰ å¿«é€Ÿåˆ¶ç§ä»»åŠ¡å®Œæˆ!")
        print(f"âœ… æˆåŠŸ: {success_count}/{len(paths)}")
        if success_count < len(paths):
            print(f"âŒ å¤±è´¥: {len(paths) - success_count}/{len(paths)}")
        print(f"â±ï¸  æ€»è€—æ—¶: {self.creator._format_duration(total_duration)}")
        print(f"ğŸ å®Œæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        print("="*60)

    def batch_create(self):
        """ç»Ÿä¸€çš„æ‰¹é‡åˆ¶ç§åŠŸèƒ½"""
        # æ£€æŸ¥é˜Ÿåˆ—è¿è¡ŒçŠ¶æ€
        if not self._check_queue_status_before_operation("æ‰¹é‡åˆ¶ç§"):
            return
            
        print("\nğŸ“¦ æ‰¹é‡åˆ¶ç§")
        print("=" * 50)
        print("é€‰æ‹©æ‰¹é‡åˆ¶ç§æ–¹å¼:")
        print("1. ğŸ” æœç´¢å¹¶é€‰æ‹©æ–‡ä»¶å¤¹")
        print("2. ğŸ“ ç›´æ¥è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„")
        print("0. ğŸ”™ è¿”å›ä¸»èœå•")
        print()

        choice = input("è¯·é€‰æ‹©æ–¹å¼ (0-2): ").strip()

        if choice == '0':
            return
        elif choice == '1':
            self._batch_create_from_search()
        elif choice == '2':
            self._batch_create_from_paths()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

    def _batch_create_from_search(self):
        """ä»æœç´¢ç»“æœä¸­æ‰¹é‡åˆ¶ç§"""
        print("\nğŸ” æœç´¢æ–‡ä»¶å¤¹è¿›è¡Œæ‰¹é‡åˆ¶ç§")
        print("=" * 40)

        search_name = input("è¯·è¾“å…¥è¦æœç´¢çš„å½±è§†å‰§åç§°: ").strip()
        if not search_name:
            print("âŒ æœç´¢åç§°ä¸èƒ½ä¸ºç©º")
            return

        print(f"\nğŸ”„ æ­£åœ¨æœç´¢ '{search_name}'...")
        start_time = time.time()

        try:
            results = self.matcher.match_folders(search_name)
            search_time = time.time() - start_time

            if not results:
                print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¤¹ (æœç´¢è€—æ—¶: {search_time:.3f}s)")
                return

            print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…ç»“æœ (æœç´¢è€—æ—¶: {search_time:.3f}s)")
            print()

            # æ˜¾ç¤ºæœç´¢ç»“æœ
            for i, result in enumerate(results, 1):
                status = "âœ…" if result['readable'] else "âŒ"
                print(f"  {i:2d}. {status} {result['name']}")
                print(f"      ğŸ“Š åŒ¹é…åº¦: {result['score']}% | ğŸ“ æ–‡ä»¶: {result['file_count']}ä¸ª | ğŸ’¾ å¤§å°: {result['size']}")
                if result['episodes']:
                    print(f"      ğŸ¬ å‰§é›†: {result['episodes']}")
                print(f"      ğŸ“‚ è·¯å¾„: {self._format_path_display(result['path'])}")
                print()

            # é€‰æ‹©æ–‡ä»¶å¤¹è¿›è¡Œæ‰¹é‡åˆ¶ç§
            choice = input("è¯·é€‰æ‹©è¦åˆ¶ä½œç§å­çš„æ–‡ä»¶å¤¹ç¼–å· (æ”¯æŒå¤šé€‰ï¼Œå¦‚: 1,3,5 æˆ– 1-5ï¼Œå›è½¦å–æ¶ˆ): ").strip()
            if not choice:
                print("âŒ å·²å–æ¶ˆæ‰¹é‡åˆ¶ç§")
                return

            # è§£æé€‰æ‹©
            selected_results = self._parse_selection(choice, results)
            if not selected_results:
                print("âŒ æ— æ•ˆçš„é€‰æ‹©")
                return

            # æ‰§è¡Œæ‰¹é‡åˆ¶ç§
            self._execute_batch_creation(selected_results)

        except Exception as e:
            print(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

    def _batch_create_from_paths(self):
        """ä»ç›´æ¥è¾“å…¥çš„è·¯å¾„æ‰¹é‡åˆ¶ç§"""
        print("\nğŸ“ ç›´æ¥è¾“å…¥è·¯å¾„è¿›è¡Œæ‰¹é‡åˆ¶ç§")
        print("=" * 40)
        print("ğŸ’¡ æç¤ºï¼šè¾“å…¥å¤šä¸ªæ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ¯è¡Œä¸€ä¸ª")
        print("ğŸ’¡ è¾“å…¥ç©ºè¡Œç»“æŸè¾“å…¥")
        print("ğŸ’¡ æ”¯æŒæ‹–æ‹½æ–‡ä»¶å¤¹åˆ°ç»ˆç«¯")
        print()

        paths = []
        print("è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œç©ºè¡Œç»“æŸï¼‰:")

        while True:
            path = input(f"è·¯å¾„ {len(paths) + 1}: ").strip()
            if not path:
                break

            # æ¸…ç†è·¯å¾„
            path = path.strip('"\'')
            path = os.path.expanduser(path)

            if not os.path.exists(path):
                print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")
                continue

            if not os.path.isdir(path):
                print(f"âš ï¸ ä¸æ˜¯æ–‡ä»¶å¤¹ï¼Œè·³è¿‡: {path}")
                continue

            paths.append(path)
            print(f"âœ… å·²æ·»åŠ : {os.path.basename(path)}")

        if not paths:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è·¯å¾„")
            return

        # è½¬æ¢ä¸ºç»“æœæ ¼å¼ä»¥ä¾¿ç»Ÿä¸€å¤„ç†
        results = []
        for path in paths:
            results.append({
                'path': path,
                'name': os.path.basename(path),
                'readable': True
            })

        # æ‰§è¡Œæ‰¹é‡åˆ¶ç§
        self._execute_batch_creation(results)

    def _format_path_display(self, folder_path: str) -> str:
        """æ ¼å¼åŒ–è·¯å¾„æ˜¾ç¤º"""
        # å¦‚æœè·¯å¾„å¤ªé•¿ï¼Œæ˜¾ç¤ºç›¸å¯¹è·¯å¾„æˆ–ç¼©çŸ­è·¯å¾„
        if len(folder_path) > 80:
            # å°è¯•æ˜¾ç¤ºç›¸å¯¹äºèµ„æºæ–‡ä»¶å¤¹çš„è·¯å¾„
            resource_folder = self.config.get_resource_folder()
            if folder_path.startswith(resource_folder):
                relative_path = os.path.relpath(folder_path, resource_folder)
                return f".../{relative_path}"
            else:
                # å¦‚æœè·¯å¾„å¤ªé•¿ï¼Œæ˜¾ç¤ºå¼€å¤´å’Œç»“å°¾
                return f"{folder_path[:30]}...{folder_path[-30:]}"
        else:
            return folder_path

    def _parse_selection(self, choice: str, results: list) -> list:
        """è§£æç”¨æˆ·é€‰æ‹©çš„æ–‡ä»¶å¤¹"""
        selected_results = []
        try:
            selected_indices = []
            for part in choice.split(','):
                part = part.strip()
                if '-' in part:
                    start, end = map(int, part.split('-'))
                    selected_indices.extend(range(start, end + 1))
                else:
                    selected_indices.append(int(part))

            # éªŒè¯é€‰æ‹©å¹¶æ”¶é›†ç»“æœ
            for idx in selected_indices:
                if 1 <= idx <= len(results):
                    selected_results.append(results[idx - 1])
                else:
                    print(f"âš ï¸ å¿½ç•¥æ— æ•ˆç¼–å·: {idx}")

        except ValueError:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©æ ¼å¼")
            return []

        return selected_results

    def _execute_batch_creation(self, selected_results: list):
        """æ‰§è¡Œæ‰¹é‡åˆ¶ç§ - é›†æˆé˜Ÿåˆ—ç®¡ç†"""
        if not selected_results:
            print("âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•æ–‡ä»¶å¤¹")
            return

        print(f"\nğŸ“‹ å°†è¦å¤„ç† {len(selected_results)} ä¸ªæ–‡ä»¶å¤¹:")
        for i, result in enumerate(selected_results, 1):
            print(f"  {i}. {result['name']}")

        # é¢„è®¾æ¨¡å¼é€‰æ‹©
        print("\nğŸ¯ é€‰æ‹©åˆ¶ç§é¢„è®¾æ¨¡å¼:")
        if hasattr(self.config, 'display_presets_menu'):
            self.config.display_presets_menu()
            preset_choice = input("\nè¯·é€‰æ‹©é¢„è®¾æ¨¡å¼ (å›è½¦ä½¿ç”¨æ ‡å‡†æ¨¡å¼): ").strip()
            
            available_presets = self.config.get_available_presets() if hasattr(self.config, 'get_available_presets') else ['standard']
            if preset_choice and preset_choice in available_presets:
                selected_preset = preset_choice
            else:
                selected_preset = 'standard'
        else:
            selected_preset = 'standard'
        
        print(f"âœ… å·²é€‰æ‹©é¢„è®¾: {selected_preset}")

        # é˜Ÿåˆ—ç®¡ç†é€‰é¡¹
        print("\nâš™ï¸ é˜Ÿåˆ—ç®¡ç†é€‰é¡¹:")
        print("1. ğŸš€ ç«‹å³å¼€å§‹ (ä¼ ç»Ÿæ¨¡å¼)")
        print("2. ğŸ“‹ æ·»åŠ åˆ°é˜Ÿåˆ— (æ¨è)")
        
        queue_choice = input("è¯·é€‰æ‹©å¤„ç†æ–¹å¼ (1-2, é»˜è®¤2): ").strip()
        use_queue = queue_choice != '1'
        
        if use_queue:
            self._execute_batch_with_queue(selected_results, selected_preset)
        else:
            self._execute_batch_traditional(selected_results, selected_preset)
    
    def _execute_batch_with_queue(self, selected_results: list, preset: str):
        """ä½¿ç”¨é˜Ÿåˆ—ç®¡ç†æ‰§è¡Œæ‰¹é‡åˆ¶ç§"""
        try:
            # ä½¿ç”¨å†…éƒ¨å®šä¹‰çš„é˜Ÿåˆ—ç®¡ç†å™¨
            # TorrentQueueManager å’Œ TaskPriority å·²åœ¨æ–‡ä»¶ä¸­å®šä¹‰
            
            # åˆå§‹åŒ–é˜Ÿåˆ—ç®¡ç†å™¨
            max_concurrent = self.config.get_setting('max_concurrent_operations', 4) if hasattr(self.config, 'get_setting') else 4
            # ä½¿ç”¨ä¸ä¸»é˜Ÿåˆ—ç®¡ç†å™¨ç›¸åŒçš„æ–‡ä»¶è·¯å¾„
            queue_file = os.path.expanduser("~/.torrent_maker/torrent_queue.json")
            queue_manager = TorrentQueueManager(
                torrent_creator=self.creator,
                max_concurrent=max_concurrent,
                save_file=queue_file
            )
            
            # è®¾ç½®å›è°ƒå‡½æ•°
            queue_manager.on_task_start = self._on_queue_task_start
            queue_manager.on_task_complete = self._on_queue_task_complete
            queue_manager.on_task_failed = self._on_queue_task_failed
            queue_manager.on_progress_update = self._on_queue_progress_update
            
            print(f"\nğŸ“‹ æ·»åŠ  {len(selected_results)} ä¸ªä»»åŠ¡åˆ°é˜Ÿåˆ—...")
            
            # æ‰¹é‡æ·»åŠ ä»»åŠ¡
            task_ids = []
            for result in selected_results:
                task_id = queue_manager.add_torrent_task(
                    file_path=result['path'],
                    preset=preset,
                    priority=TaskPriority.NORMAL
                )
                task_ids.append(task_id)
            
            print(f"âœ… å·²æ·»åŠ  {len(task_ids)} ä¸ªä»»åŠ¡åˆ°é˜Ÿåˆ—")
            
            # è¯¢é—®ç”¨æˆ·åç»­æ“ä½œ
            print("\nğŸ“‹ ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—ï¼Œè¯·é€‰æ‹©åç»­æ“ä½œ:")
            print("1. ğŸ” ç»§ç»­æœç´¢")
            print("2. ğŸš€ å¯åŠ¨é˜Ÿåˆ—")
            print("3. âš™ï¸ è¿›å…¥é˜Ÿåˆ—ç®¡ç†")
            print("4. ğŸ  è¿”å›ä¸»èœå•")
            
            while True:
                choice = input("è¯·é€‰æ‹©æ“ä½œ (1-4, é»˜è®¤1): ").strip()
                if not choice:
                    choice = '1'
                
                if choice == '1':
                    print("ğŸ” ç»§ç»­æœç´¢...")
                    return  # è¿”å›åˆ°æœç´¢æµç¨‹
                elif choice == '2':
                    print("ğŸš€ å¯åŠ¨é˜Ÿåˆ—...")
                    queue_manager.start_queue()
                    print("âœ… é˜Ÿåˆ—å·²å¯åŠ¨")
                    return
                elif choice == '3':
                    print("âš™ï¸ è¿›å…¥é˜Ÿåˆ—ç®¡ç†...")
                    self._show_queue_management_interface(queue_manager, task_ids)
                    return
                elif choice == '4':
                    print("ğŸ  è¿”å›ä¸»èœå•")
                    return
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4")
            
        except ImportError:
            print("âš ï¸ é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
            self._execute_batch_traditional(selected_results, preset)
        except Exception as e:
            print(f"âŒ é˜Ÿåˆ—ç®¡ç†åˆå§‹åŒ–å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼")
            self._execute_batch_traditional(selected_results, preset)
    
    def _execute_batch_traditional(self, selected_results: list, preset: str):
        """ä¼ ç»Ÿæ‰¹é‡åˆ¶ç§æ¨¡å¼"""
        confirm = input(f"\nç¡®è®¤æ‰¹é‡åˆ¶ç§è¿™ {len(selected_results)} ä¸ªæ–‡ä»¶å¤¹? (y/N): ").strip().lower()
        if confirm not in ['y', 'yes', 'æ˜¯']:
            print("âŒ å·²å–æ¶ˆæ‰¹é‡åˆ¶ç§")
            return

        # åº”ç”¨é¢„è®¾é…ç½®
        if hasattr(self.config, 'apply_preset'):
            self.config.apply_preset(preset)
            print(f"âœ… å·²åº”ç”¨é¢„è®¾é…ç½®: {preset}")

        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡åˆ¶ç§...")
        print("=" * 50)

        # æ‰¹é‡åˆ›å»ºç§å­
        success_count = 0
        for i, result in enumerate(selected_results, 1):
            print(f"\n[{i}/{len(selected_results)}] æ­£åœ¨å¤„ç†: {result['name']}")
            if self._create_single_torrent(result):
                success_count += 1

        print(f"\nğŸ‰ æ‰¹é‡åˆ¶ç§å®Œæˆ!")
        print(f"âœ… æˆåŠŸ: {success_count}/{len(selected_results)}")
        if success_count < len(selected_results):
            print(f"âŒ å¤±è´¥: {len(selected_results) - success_count}")
        print(f"âœ… æˆåŠŸç‡: {success_count/len(selected_results)*100:.1f}%")
    

    
    def _display_queue_status(self, status: dict = None, mode: str = "standard"):
        """æ˜¾ç¤ºé˜Ÿåˆ—çŠ¶æ€ï¼ˆç»Ÿä¸€æ¥å£ï¼‰"""
        self.status_display.display_status(self.queue_manager, mode=mode, force_update=True)
    
    def _display_task_list(self, queue_manager, task_ids: list):
        """æ˜¾ç¤ºä»»åŠ¡åˆ—è¡¨"""
        print("\nğŸ“‹ ä»»åŠ¡åˆ—è¡¨:")
        print("-" * 80)
        print(f"{'åºå·':<4} {'ä»»åŠ¡åç§°':<25} {'çŠ¶æ€':<10} {'è¿›åº¦':<8} {'é¢„è®¾':<10}")
        print("-" * 80)
        
        for i, task_id in enumerate(task_ids[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            task = queue_manager.get_task(task_id)
            if task:
                status_icon = {
                    'waiting': 'â³',
                    'running': 'ğŸ”„',
                    'completed': 'âœ…',
                    'failed': 'âŒ',
                    'paused': 'â¸ï¸',
                    'cancelled': 'ğŸš«'
                }.get(task.status.value, 'â“')
                
                progress_str = f"{task.progress*100:.1f}%" if task.progress > 0 else "-"
                
                print(f"{i:<4} {task.name[:24]:<25} {status_icon}{task.status.value:<9} {progress_str:<8} {task.preset:<10}")
        
        if len(task_ids) > 10:
            print(f"... è¿˜æœ‰ {len(task_ids) - 10} ä¸ªä»»åŠ¡")
        print("-" * 80)
    
    def _show_detailed_statistics(self, queue_manager):
        """æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 50)
        print("           ğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 50)
        
        status = queue_manager.get_queue_status()
        stats = status['statistics']
        status_counts = status['status_counts']
        
        print("ğŸ“‹ ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ:")
        for status_name, count in status_counts.items():
            if count > 0:
                icon = {
                    'waiting': 'â³',
                    'running': 'ğŸ”„',
                    'completed': 'âœ…',
                    'failed': 'âŒ',
                    'paused': 'â¸ï¸',
                    'cancelled': 'ğŸš«'
                }.get(status_name, 'â“')
                print(f"  {icon} {status_name}: {count}")
        
        print(f"\nâ±ï¸ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ€»å¤„ç†æ—¶é—´: {stats['total_processing_time']:.1f}ç§’")
        if stats['completed_tasks'] > 0:
            print(f"  å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.1f}ç§’")
            success_rate = (stats['completed_tasks'] / (stats['completed_tasks'] + stats['failed_tasks'])) * 100
            print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
        
        print("=" * 50)
    
    def _export_queue_report(self, queue_manager):
        """å¯¼å‡ºé˜Ÿåˆ—æŠ¥å‘Š"""
        try:
            import json
            from datetime import datetime
            
            # ç”ŸæˆæŠ¥å‘Šæ•°æ®
            report_data = {
                'export_time': datetime.now().isoformat(),
                'queue_status': queue_manager.get_queue_status(),
                'tasks': []
            }
            
            # æ·»åŠ ä»»åŠ¡è¯¦æƒ…
            for task in queue_manager.get_all_tasks():
                task_data = task.to_dict()
                report_data['tasks'].append(task_data)
            
            # ä¿å­˜æŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            report_file = f"queue_report_{timestamp}.json"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ é˜Ÿåˆ—æŠ¥å‘Šå·²å¯¼å‡º: {report_file}")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")
    
    # é˜Ÿåˆ—å›è°ƒå‡½æ•°
    def _on_queue_task_start(self, task):
        """ä»»åŠ¡å¼€å§‹å›è°ƒï¼ˆç®€åŒ–è¾“å‡ºï¼‰"""
        # æ ¹æ®é…ç½®å†³å®šæ˜¾ç¤ºæ¨¡å¼
        mode = "compact" if self.queue_display_config.get('compact_on_start', True) else self.queue_display_config.get('default_mode', 'standard')
        self.status_display.display_status(self.queue_manager, mode=mode)
    
    def _on_queue_task_complete(self, task):
        """ä»»åŠ¡å®Œæˆå›è°ƒï¼ˆä¼˜åŒ–è¾“å‡ºï¼‰"""
        duration = task.actual_duration if task.actual_duration > 0 else 0
        print(f"âœ… {task.name} å®Œæˆ ({duration:.1f}s)")
        # æ˜¾ç¤ºç®€æ´çŠ¶æ€æ›´æ–°
        self.status_display.display_status(self.queue_manager, mode="compact")
    
    def _on_queue_task_failed(self, task, error_message: str):
        """ä»»åŠ¡å¤±è´¥å›è°ƒï¼ˆä¼˜åŒ–è¾“å‡ºï¼‰"""
        print(f"âŒ {task.name} å¤±è´¥: {error_message}")
        # æ˜¾ç¤ºç®€æ´çŠ¶æ€æ›´æ–°
        self.status_display.display_status(self.queue_manager, mode="compact")
        
        # ä½¿ç”¨é”™è¯¯å¤„ç†å™¨å¤„ç†é”™è¯¯
        try:
            from error_handler import handle_error
            handle_error(Exception(error_message), f"åˆ¶ç§ä»»åŠ¡å¤±è´¥: {task.name}")
        except ImportError:
            pass  # é”™è¯¯å¤„ç†å™¨ä¸å¯ç”¨
    
    def _on_queue_progress_update(self, task):
        """è¿›åº¦æ›´æ–°å›è°ƒ"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„è¿›åº¦æ˜¾ç¤ºé€»è¾‘
        # ä¸ºäº†é¿å…è¾“å‡ºè¿‡å¤šï¼Œè¿™é‡Œæš‚æ—¶ä¸è¾“å‡ºè¿›åº¦ä¿¡æ¯
        pass
    
    def _show_queue_management_interface(self, queue_manager=None, task_ids=None):
        """æ˜¾ç¤ºé˜Ÿåˆ—ç®¡ç†ç•Œé¢å…¥å£"""
        # ä½¿ç”¨ä¼ å…¥çš„é˜Ÿåˆ—ç®¡ç†å™¨æˆ–é»˜è®¤çš„é˜Ÿåˆ—ç®¡ç†å™¨
        if queue_manager is None:
            queue_manager = self.queue_manager
        
        # æ£€æŸ¥é˜Ÿåˆ—ç®¡ç†å™¨æ˜¯å¦å¯ç”¨
        if queue_manager is None:
            print("âŒ é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½ä¸å¯ç”¨ï¼Œåˆå§‹åŒ–æ—¶å‡ºç°é”™è¯¯")
            input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            return
        
        print("\n" + "=" * 60)
        print("           ğŸ”„ é˜Ÿåˆ—ç®¡ç†")
        print("=" * 60)
        
        # æ˜¾ç¤ºé˜Ÿåˆ—çŠ¶æ€
        self._display_queue_status(mode="standard")
        
        print("\nğŸ”§ é˜Ÿåˆ—ç®¡ç†é€‰é¡¹:")
        print("1. ğŸ“‹ æŸ¥çœ‹é˜Ÿåˆ—è¯¦æƒ…")
        print("2. âš¡ å¯åŠ¨é˜Ÿåˆ—")
        print("3. â¸ï¸ æš‚åœé˜Ÿåˆ—")
        print("4. â¹ï¸ åœæ­¢é˜Ÿåˆ—")
        print("5. ğŸ—‘ï¸ æ¸…ç†å·²å®Œæˆä»»åŠ¡")
        print("6. ğŸ“Š æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡")
        print("7. ğŸ’¾ å¯¼å‡ºé˜Ÿåˆ—æŠ¥å‘Š")
        print("8. â• æ·»åŠ åˆ¶ç§ä»»åŠ¡")
        print("9. â– åˆ é™¤ä»»åŠ¡")
        print("0. ğŸ”™ è¿”å›ä¸»èœå•")
        print("=" * 60)
        
        choice = input("è¯·é€‰æ‹©æ“ä½œ (0-9): ").strip()
        
        try:
            if choice == '0':
                return
            elif choice == '1':
                self._show_queue_details()
            elif choice == '2':
                queue_manager.start_queue()
                # ä½¿ç”¨ç»Ÿä¸€çŠ¶æ€æ˜¾ç¤ºæ¥å£ï¼Œé¿å…é‡å¤ä¿¡æ¯
                self.status_display.display_status(queue_manager, mode="standard", force_update=True)
            elif choice == '3':
                queue_manager.pause_queue()
                print("â¸ï¸ é˜Ÿåˆ—å·²æš‚åœ")
            elif choice == '4':
                queue_manager.stop_queue()
                print("â¹ï¸ é˜Ÿåˆ—å·²åœæ­¢")
            elif choice == '5':
                count = queue_manager.clear_completed_tasks()
                print(f"ğŸ—‘ï¸ å·²æ¸…ç† {count} ä¸ªå·²å®Œæˆä»»åŠ¡")
            elif choice == '6':
                self._show_detailed_statistics(queue_manager)
            elif choice == '7':
                self._export_queue_report(queue_manager)
            elif choice == '8':
                self._add_queue_task_interactive(queue_manager)
            elif choice == '9':
                self._remove_queue_task_interactive(queue_manager)
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
        
        except Exception as e:
            print(f"âŒ é˜Ÿåˆ—ç®¡ç†å‡ºé”™: {e}")
        
        if choice != '0':
            input("\næŒ‰å›è½¦é”®ç»§ç»­...")
    
    def _show_queue_details(self):
        """æ˜¾ç¤ºé˜Ÿåˆ—è¯¦æƒ…"""
        if self.queue_manager is None:
            print("âŒ é˜Ÿåˆ—ç®¡ç†å™¨ä¸å¯ç”¨")
            return
        
        print("\n" + "=" * 60)
        print("           ğŸ“‹ é˜Ÿåˆ—è¯¦æƒ…")
        print("=" * 60)
        
        # è·å–æ‰€æœ‰ä»»åŠ¡
        all_tasks = self.queue_manager.get_all_tasks()
        
        if not all_tasks:
            print("\nğŸ“­ é˜Ÿåˆ—ä¸ºç©º")
            return
        
        # æŒ‰çŠ¶æ€åˆ†ç»„æ˜¾ç¤º
        # TaskStatus å·²åœ¨æ–‡ä»¶ä¸­å®šä¹‰
        
        status_groups = {
            TaskStatus.WAITING: "â³ ç­‰å¾…ä¸­",
            TaskStatus.RUNNING: "ğŸ”„ è¿è¡Œä¸­",
            TaskStatus.COMPLETED: "âœ… å·²å®Œæˆ",
            TaskStatus.FAILED: "âŒ å¤±è´¥",
            TaskStatus.CANCELLED: "ğŸš« å·²å–æ¶ˆ"
        }
        
        for status, status_name in status_groups.items():
            tasks = [task for task in all_tasks if task.status == status]
            if tasks:
                print(f"\n{status_name} ({len(tasks)} ä¸ªä»»åŠ¡):")
                for i, task in enumerate(tasks[:10], 1):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                    print(f"  {i}. {task.name}")
                    if hasattr(task, 'progress') and task.progress > 0:
                        print(f"     è¿›åº¦: {task.progress:.1f}%")
                if len(tasks) > 10:
                    print(f"     ... è¿˜æœ‰ {len(tasks) - 10} ä¸ªä»»åŠ¡")
        
        # æ˜¾ç¤ºé˜Ÿåˆ—ç»Ÿè®¡
        status = self.queue_manager.get_queue_status()
        stats = status['statistics']
        print(f"\nğŸ“Š é˜Ÿåˆ—ç»Ÿè®¡:")
        print(f"  æ€»ä»»åŠ¡æ•°: {status['total_tasks']}")
        print(f"  å·²å®Œæˆ: {stats['completed_tasks']}")
        print(f"  å¤±è´¥: {stats['failed_tasks']}")
        print(f"  æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        if stats['average_processing_time'] > 0:
            print(f"  å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.1f}ç§’")
    
    def _preset_management(self):
        """é¢„è®¾æ¨¡å¼ç®¡ç†ç•Œé¢"""
        while True:
            print("\n" + "=" * 50)
            print("           âš¡ é¢„è®¾æ¨¡å¼ç®¡ç†")
            print("=" * 50)
            
            # æ˜¾ç¤ºå½“å‰å¯ç”¨é¢„è®¾
            presets = self.config_manager.get_available_presets()
            if presets:
                print("\nğŸ“‹ å¯ç”¨é¢„è®¾æ¨¡å¼:")
                self.config_manager.display_presets_menu()
            else:
                print("\nâŒ æ— å¯ç”¨é¢„è®¾æ¨¡å¼")
            
            print("\nğŸ”§ ç®¡ç†é€‰é¡¹:")
            print("1. ğŸ“– æŸ¥çœ‹é¢„è®¾è¯¦æƒ…")
            print("2. âš¡ åº”ç”¨é¢„è®¾")
            print("3. ğŸ’¾ ä¿å­˜å½“å‰é…ç½®ä¸ºé¢„è®¾")
            print("4. ğŸ—‘ï¸ åˆ é™¤è‡ªå®šä¹‰é¢„è®¾")
            print("5. ğŸ” è‡ªåŠ¨æ£€æµ‹æ¨èé¢„è®¾")
            print("0. ğŸ”™ è¿”å›é…ç½®ç®¡ç†")
            print("=" * 50)
            
            choice = input("è¯·é€‰æ‹©æ“ä½œ (0-5): ").strip()
            
            try:
                if choice == '0':
                    break
                elif choice == '1':
                    self._view_preset_details()
                elif choice == '2':
                    self._apply_preset_interactive()
                elif choice == '3':
                    self._save_custom_preset()
                elif choice == '4':
                    self._delete_custom_preset()
                elif choice == '5':
                    self._auto_detect_preset()
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-5 ä¹‹é—´çš„æ•°å­—")
            
            except Exception as e:
                print(f"âŒ æ“ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                print("è¯·é‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ")
            
            if choice != '0':
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
    
    def _view_preset_details(self):
        """æŸ¥çœ‹é¢„è®¾è¯¦æƒ…"""
        presets = self.config_manager.get_available_presets()
        if not presets:
            print("\nâŒ æ— å¯ç”¨é¢„è®¾æ¨¡å¼")
            return
        
        print("\nè¯·é€‰æ‹©è¦æŸ¥çœ‹çš„é¢„è®¾:")
        for i, preset_name in enumerate(presets, 1):
            print(f"{i}. {preset_name}")
        
        try:
            choice = int(input("\nè¯·è¾“å…¥é¢„è®¾ç¼–å·: ").strip())
            if 1 <= choice <= len(presets):
                preset_name = presets[choice - 1]
                preset_info = self.config_manager.get_preset_info(preset_name)
                
                if preset_info:
                    print(f"\nğŸ“‹ é¢„è®¾è¯¦æƒ…: {preset_name}")
                    print("=" * 40)
                    print(f"æè¿°: {preset_info.get('description', 'æ— æè¿°')}")
                    print(f"ç±»å‹: {'ç³»ç»Ÿé¢„è®¾' if preset_info.get('is_system', True) else 'è‡ªå®šä¹‰é¢„è®¾'}")
                    print(f"æ¨èåœºæ™¯: {preset_info.get('recommended_for', 'é€šç”¨')}")
                    
                    print("\nâš™ï¸ é…ç½®å‚æ•°:")
                    settings = preset_info.get('settings', {})
                    for key, value in settings.items():
                        print(f"  {key}: {value}")
                else:
                    print(f"âŒ æ— æ³•è·å–é¢„è®¾ '{preset_name}' çš„è¯¦æƒ…")
            else:
                print("âŒ æ— æ•ˆçš„é¢„è®¾ç¼–å·")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def _apply_preset_interactive(self):
        """äº¤äº’å¼åº”ç”¨é¢„è®¾"""
        presets = self.config_manager.get_available_presets()
        if not presets:
            print("\nâŒ æ— å¯ç”¨é¢„è®¾æ¨¡å¼")
            return
        
        print("\nè¯·é€‰æ‹©è¦åº”ç”¨çš„é¢„è®¾:")
        for i, preset_name in enumerate(presets, 1):
            preset_info = self.config_manager.get_preset_info(preset_name)
            description = preset_info.get('description', 'æ— æè¿°') if preset_info else 'æ— æè¿°'
            print(f"{i}. {preset_name} - {description}")
        
        try:
            choice = int(input("\nè¯·è¾“å…¥é¢„è®¾ç¼–å·: ").strip())
            if 1 <= choice <= len(presets):
                preset_name = presets[choice - 1]
                
                # ç¡®è®¤åº”ç”¨
                confirm = input(f"\nç¡®è®¤åº”ç”¨é¢„è®¾ '{preset_name}'? (y/N): ").strip().lower()
                if confirm in ['y', 'yes', 'æ˜¯']:
                    if self.config_manager.apply_preset(preset_name):
                        print(f"âœ… é¢„è®¾ '{preset_name}' åº”ç”¨æˆåŠŸ")
                        print("ğŸ’¡ æç¤º: æ–°é…ç½®å°†åœ¨ä¸‹æ¬¡åˆ¶ç§æ—¶ç”Ÿæ•ˆ")
                    else:
                        print(f"âŒ é¢„è®¾ '{preset_name}' åº”ç”¨å¤±è´¥")
                else:
                    print("âŒ æ“ä½œå·²å–æ¶ˆ")
            else:
                print("âŒ æ— æ•ˆçš„é¢„è®¾ç¼–å·")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def _save_custom_preset(self):
        """ä¿å­˜è‡ªå®šä¹‰é¢„è®¾"""
        print("\nğŸ’¾ ä¿å­˜å½“å‰é…ç½®ä¸ºè‡ªå®šä¹‰é¢„è®¾")
        print("=" * 40)
        
        preset_name = input("è¯·è¾“å…¥é¢„è®¾åç§°: ").strip()
        if not preset_name:
            print("âŒ é¢„è®¾åç§°ä¸èƒ½ä¸ºç©º")
            return
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing_presets = self.config_manager.get_available_presets()
        if preset_name in existing_presets:
            confirm = input(f"é¢„è®¾ '{preset_name}' å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–? (y/N): ").strip().lower()
            if confirm not in ['y', 'yes', 'æ˜¯']:
                print("âŒ æ“ä½œå·²å–æ¶ˆ")
                return
        
        description = input("è¯·è¾“å…¥é¢„è®¾æè¿° (å¯é€‰): ").strip()
        recommended_for = input("è¯·è¾“å…¥æ¨èä½¿ç”¨åœºæ™¯ (å¯é€‰): ").strip()
        
        if self.config_manager.save_custom_preset(preset_name, description, recommended_for):
            print(f"âœ… è‡ªå®šä¹‰é¢„è®¾ '{preset_name}' ä¿å­˜æˆåŠŸ")
        else:
            print(f"âŒ è‡ªå®šä¹‰é¢„è®¾ '{preset_name}' ä¿å­˜å¤±è´¥")
    
    def _delete_custom_preset(self):
        """åˆ é™¤è‡ªå®šä¹‰é¢„è®¾"""
        presets = self.config_manager.get_available_presets()
        custom_presets = []
        
        # ç­›é€‰å‡ºè‡ªå®šä¹‰é¢„è®¾
        for preset_name in presets:
            preset_info = self.config_manager.get_preset_info(preset_name)
            if preset_info and not preset_info.get('is_system', True):
                custom_presets.append(preset_name)
        
        if not custom_presets:
            print("\nâŒ æ— è‡ªå®šä¹‰é¢„è®¾å¯åˆ é™¤")
            return
        
        print("\nğŸ—‘ï¸ å¯åˆ é™¤çš„è‡ªå®šä¹‰é¢„è®¾:")
        for i, preset_name in enumerate(custom_presets, 1):
            preset_info = self.config_manager.get_preset_info(preset_name)
            description = preset_info.get('description', 'æ— æè¿°') if preset_info else 'æ— æè¿°'
            print(f"{i}. {preset_name} - {description}")
        
        try:
            choice = int(input("\nè¯·è¾“å…¥è¦åˆ é™¤çš„é¢„è®¾ç¼–å·: ").strip())
            if 1 <= choice <= len(custom_presets):
                preset_name = custom_presets[choice - 1]
                
                # ç¡®è®¤åˆ é™¤
                confirm = input(f"\nç¡®è®¤åˆ é™¤é¢„è®¾ '{preset_name}'? (y/N): ").strip().lower()
                if confirm in ['y', 'yes', 'æ˜¯']:
                    if self.config_manager.delete_custom_preset(preset_name):
                        print(f"âœ… è‡ªå®šä¹‰é¢„è®¾ '{preset_name}' åˆ é™¤æˆåŠŸ")
                    else:
                        print(f"âŒ è‡ªå®šä¹‰é¢„è®¾ '{preset_name}' åˆ é™¤å¤±è´¥")
                else:
                    print("âŒ æ“ä½œå·²å–æ¶ˆ")
            else:
                print("âŒ æ— æ•ˆçš„é¢„è®¾ç¼–å·")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def _auto_detect_preset(self):
        """è‡ªåŠ¨æ£€æµ‹æ¨èé¢„è®¾"""
        print("\nğŸ” è‡ªåŠ¨æ£€æµ‹æ¨èé¢„è®¾")
        print("=" * 40)
        
        # è·å–èµ„æºæ–‡ä»¶å¤¹
        resource_folder = self.config_manager.get_resource_folder()
        if not resource_folder or not os.path.exists(resource_folder):
            print("âŒ è¯·å…ˆè®¾ç½®æœ‰æ•ˆçš„èµ„æºæ–‡ä»¶å¤¹")
            return
        
        try:
            # è®¡ç®—æ–‡ä»¶å¤¹æ€»å¤§å°
            total_size = 0
            file_count = 0
            
            print("æ­£åœ¨åˆ†æèµ„æºæ–‡ä»¶å¤¹...")
            for root, dirs, files in os.walk(resource_folder):
                for file in files:
                    file_path = os.path.join(root, file)
                    try:
                        total_size += os.path.getsize(file_path)
                        file_count += 1
                    except (OSError, IOError):
                        continue
            
            if total_size == 0:
                print("âŒ èµ„æºæ–‡ä»¶å¤¹ä¸ºç©ºæˆ–æ— æ³•è®¿é—®")
                return
            
            # è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
            size_gb = total_size / (1024 ** 3)
            
            print(f"ğŸ“Š åˆ†æç»“æœ:")
            print(f"  æ–‡ä»¶æ€»æ•°: {file_count:,}")
            print(f"  æ€»å¤§å°: {size_gb:.2f} GB")
            
            # è‡ªåŠ¨æ£€æµ‹æ¨èé¢„è®¾
            recommended_preset = self.config_manager.auto_detect_preset(total_size)
            
            if recommended_preset:
                preset_info = self.config_manager.get_preset_info(recommended_preset)
                description = preset_info.get('description', 'æ— æè¿°') if preset_info else 'æ— æè¿°'
                
                print(f"\nğŸ’¡ æ¨èé¢„è®¾: {recommended_preset}")
                print(f"   æè¿°: {description}")
                
                # è¯¢é—®æ˜¯å¦åº”ç”¨
                confirm = input(f"\næ˜¯å¦åº”ç”¨æ¨èé¢„è®¾ '{recommended_preset}'? (y/N): ").strip().lower()
                if confirm in ['y', 'yes', 'æ˜¯']:
                    if self.config_manager.apply_preset(recommended_preset):
                        print(f"âœ… é¢„è®¾ '{recommended_preset}' åº”ç”¨æˆåŠŸ")
                    else:
                        print(f"âŒ é¢„è®¾ '{recommended_preset}' åº”ç”¨å¤±è´¥")
                else:
                    print("âŒ æ“ä½œå·²å–æ¶ˆ")
            else:
                print("\nâŒ æ— æ³•ç¡®å®šæ¨èé¢„è®¾ï¼Œå»ºè®®æ‰‹åŠ¨é€‰æ‹©")
        
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

    def config_management(self):
        """é…ç½®ç®¡ç†"""
        while True:
            print("\n" + "=" * 50)
            print("           âš™ï¸ é…ç½®ç®¡ç†")
            print("=" * 50)
            print("1. ğŸ“ æŸ¥çœ‹å½“å‰é…ç½®")
            print("2. ğŸ”§ è®¾ç½®èµ„æºæ–‡ä»¶å¤¹")
            print("3. ğŸ“‚ è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹")
            print("4. ğŸŒ ç®¡ç† Tracker")
            print("5. ğŸ”„ é‡æ–°åŠ è½½é…ç½®")
            print("6. ğŸ“¤ å¯¼å‡ºé…ç½®")
            print("7. ğŸ“¥ å¯¼å…¥é…ç½®")
            print("8. ğŸ§¹ æ¸…ç†ç¼“å­˜")
            print("9. ğŸ”„ é‡ç½®ä¸ºé»˜è®¤é…ç½®")
            print("10. âš¡ é¢„è®¾æ¨¡å¼ç®¡ç†")
            print("0. ğŸ”™ è¿”å›ä¸»èœå•")
            print("=" * 50)

            choice = input("è¯·é€‰æ‹©æ“ä½œ (0-10): ").strip()

            try:
                if choice == '0':
                    break
                elif choice == '1':
                    self._show_current_config()
                elif choice == '2':
                    self._set_resource_folder()
                elif choice == '3':
                    self._set_output_folder()
                elif choice == '4':
                    self._manage_trackers()
                elif choice == '5':
                    self._reload_config()
                elif choice == '6':
                    self._export_config()
                elif choice == '7':
                    self._import_config()
                elif choice == '8':
                    self._clear_cache()
                elif choice == '9':
                    self._reset_config()
                elif choice == '10':
                    self._preset_management()
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-10 ä¹‹é—´çš„æ•°å­—")

            except Exception as e:
                print(f"âŒ æ“ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                print("è¯·é‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ")

            if choice != '0':
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")

    def _show_current_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®"""
        print("\n" + "=" * 60)
        print("           ğŸ“‹ å½“å‰é…ç½®ä¿¡æ¯")
        print("=" * 60)

        # åŸºæœ¬è·¯å¾„é…ç½®
        resource_folder = self.config.get_resource_folder()
        output_folder = self.config.get_output_folder()

        print(f"ğŸ“ èµ„æºæ–‡ä»¶å¤¹: {resource_folder}")
        print(f"   {'âœ… å­˜åœ¨' if os.path.exists(resource_folder) else 'âŒ ä¸å­˜åœ¨'}")

        print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}")
        print(f"   {'âœ… å­˜åœ¨' if os.path.exists(output_folder) else 'âš ï¸ å°†è‡ªåŠ¨åˆ›å»º'}")

        # Tracker é…ç½®
        trackers = self.config.get_trackers()
        print(f"ğŸŒ Tracker é…ç½®: {len(trackers)} ä¸ª")
        if trackers:
            print("   å‰3ä¸ª Tracker:")
            for i, tracker in enumerate(trackers[:3], 1):
                print(f"   {i}. {tracker}")
            if len(trackers) > 3:
                print(f"   ... è¿˜æœ‰ {len(trackers) - 3} ä¸ª")
        else:
            print("   âŒ æœªé…ç½®ä»»ä½• Tracker")

        # é«˜çº§é…ç½®
        print("\nğŸ”§ é«˜çº§é…ç½®:")
        try:
            if hasattr(self.config, 'get_setting'):
                tolerance = self.config.get_setting('file_search_tolerance', 60)
                max_results = self.config.get_setting('max_search_results', 10)
                cache_enabled = self.config.get_setting('enable_cache', True)
                max_concurrent = self.config.get_setting('max_concurrent_operations', 4)
            else:
                # å¦‚æœ get_setting æ–¹æ³•ä¸å­˜åœ¨ï¼Œç›´æ¥ä» settings å­—å…¸è·å–
                tolerance = self.config.settings.get('file_search_tolerance', 60)
                max_results = self.config.settings.get('max_search_results', 10)
                cache_enabled = self.config.settings.get('enable_cache', True)
                max_concurrent = self.config.settings.get('max_concurrent_operations', 4)

            print(f"   ğŸ” æœç´¢å®¹é”™ç‡: {tolerance}%")
            print(f"   ğŸ“Š æœ€å¤§æœç´¢ç»“æœ: {max_results}")
            print(f"   ğŸ’¾ ç¼“å­˜çŠ¶æ€: {'å¯ç”¨' if cache_enabled else 'ç¦ç”¨'}")
            print(f"   âš¡ æœ€å¤§å¹¶å‘æ“ä½œ: {max_concurrent}")

        except Exception as e:
            print(f"   âš ï¸ è·å–è¯¦ç»†é…ç½®ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            print("   åŸºæœ¬é…ç½®ä¿¡æ¯å·²æ˜¾ç¤º")

        # é…ç½®æ–‡ä»¶çŠ¶æ€
        print("\nğŸ“„ é…ç½®æ–‡ä»¶çŠ¶æ€:")
        if hasattr(self.config, 'settings_path'):
            settings_path = self.config.settings_path
            trackers_path = self.config.trackers_path
            print(f"   âš™ï¸ è®¾ç½®æ–‡ä»¶: {settings_path}")
            print(f"      {'âœ… å­˜åœ¨' if os.path.exists(settings_path) else 'âŒ ä¸å­˜åœ¨'}")
            print(f"   ğŸŒ Trackeræ–‡ä»¶: {trackers_path}")
            print(f"      {'âœ… å­˜åœ¨' if os.path.exists(trackers_path) else 'âŒ ä¸å­˜åœ¨'}")
        else:
            print("   ğŸ“ é…ç½®ç›®å½•: ~/.torrent_maker/")

        print("=" * 60)

    def _set_resource_folder(self):
        """è®¾ç½®èµ„æºæ–‡ä»¶å¤¹"""
        print(f"\nğŸ“ å½“å‰èµ„æºæ–‡ä»¶å¤¹: {self.config.get_resource_folder()}")
        new_path = input("è¯·è¾“å…¥æ–°çš„èµ„æºæ–‡ä»¶å¤¹è·¯å¾„ (å›è½¦å–æ¶ˆ): ").strip()
        if new_path:
            if self.config.set_resource_folder(new_path):
                print("âœ… èµ„æºæ–‡ä»¶å¤¹è®¾ç½®æˆåŠŸ")
                # é‡æ–°åˆå§‹åŒ–æ–‡ä»¶åŒ¹é…å™¨
                enable_cache = True
                cache_duration = 3600
                max_workers = 4

                if hasattr(self.config, 'get_setting'):
                    enable_cache = self.config.get_setting('enable_cache', True)
                    cache_duration = self.config.get_setting('cache_duration', 3600)
                    max_workers = self.config.get_setting('max_concurrent_operations', 4)
                elif hasattr(self.config, 'settings'):
                    enable_cache = self.config.settings.get('enable_cache', True)
                    cache_duration = self.config.settings.get('cache_duration', 3600)
                    max_workers = self.config.settings.get('max_concurrent_operations', 4)

                # ä½¿ç”¨æ–°è®¾ç½®çš„è·¯å¾„ç›´æ¥åˆ›å»º FileMatcher
                new_resource_folder = self.config.settings['resource_folder']
                self.matcher = FileMatcher(
                    new_resource_folder,
                    enable_cache=enable_cache,
                    cache_duration=cache_duration,
                    max_workers=max_workers
                )
                print(f"ğŸ”„ æ–‡ä»¶åŒ¹é…å™¨å·²é‡æ–°åˆå§‹åŒ–ï¼Œä½¿ç”¨è·¯å¾„: {new_resource_folder}")
            else:
                print("âŒ è®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨")

    def _set_output_folder(self):
        """è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹"""
        print(f"\nğŸ“‚ å½“å‰è¾“å‡ºæ–‡ä»¶å¤¹: {self.config.get_output_folder()}")
        new_path = input("è¯·è¾“å…¥æ–°çš„è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ (å›è½¦å–æ¶ˆ): ").strip()
        if new_path:
            if self.config.set_output_folder(new_path):
                print("âœ… è¾“å‡ºæ–‡ä»¶å¤¹è®¾ç½®æˆåŠŸ")
                # é‡æ–°åˆå§‹åŒ–ç§å­åˆ›å»ºå™¨
                self.creator = TorrentCreator(
                    self.config.get_trackers(),
                    self.config.get_output_folder()
                )
            else:
                print("âŒ è®¾ç½®å¤±è´¥")

    def _manage_trackers(self):
        """ç®¡ç† Tracker"""
        while True:
            print("\nğŸŒ Tracker ç®¡ç†")
            print("=" * 30)
            trackers = self.config.get_trackers()
            if trackers:
                for i, tracker in enumerate(trackers, 1):
                    print(f"  {i:2d}. {tracker}")
            else:
                print("  (æ—  Tracker)")

            print("\næ“ä½œé€‰é¡¹:")
            print("1. â• æ·»åŠ  Tracker")
            print("2. â– åˆ é™¤ Tracker")
            print("0. ğŸ”™ è¿”å›")

            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-2): ").strip()

            if choice == '0':
                break
            elif choice == '1':
                tracker_url = input("è¯·è¾“å…¥ Tracker URL: ").strip()
                if tracker_url:
                    if self.config.add_tracker(tracker_url):
                        print("âœ… Tracker æ·»åŠ æˆåŠŸ")
                        # æ›´æ–°ç§å­åˆ›å»ºå™¨çš„ tracker åˆ—è¡¨
                        self.creator = TorrentCreator(
                            self.config.get_trackers(),
                            self.config.get_output_folder()
                        )
                    else:
                        print("âŒ æ·»åŠ å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ— æ•ˆURLæˆ–å·²å­˜åœ¨")
            elif choice == '2':
                if not trackers:
                    print("âŒ æ²¡æœ‰å¯åˆ é™¤çš„ Tracker")
                    continue
                try:
                    idx = int(input("è¯·è¾“å…¥è¦åˆ é™¤çš„ Tracker ç¼–å·: ").strip())
                    if 1 <= idx <= len(trackers):
                        tracker_to_remove = trackers[idx - 1]
                        if self.config.remove_tracker(tracker_to_remove):
                            print("âœ… Tracker åˆ é™¤æˆåŠŸ")
                            # æ›´æ–°ç§å­åˆ›å»ºå™¨çš„ tracker åˆ—è¡¨
                            self.creator = TorrentCreator(
                                self.config.get_trackers(),
                                self.config.get_output_folder()
                            )
                        else:
                            print("âŒ åˆ é™¤å¤±è´¥")
                    else:
                        print("âŒ æ— æ•ˆçš„ç¼–å·")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")

    def _reload_config(self):
        """é‡æ–°åŠ è½½é…ç½®"""
        try:
            # é‡æ–°åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
            self.config = ConfigManager()

            # é‡æ–°åˆå§‹åŒ–å…¶ä»–ç»„ä»¶
            enable_cache = True
            if hasattr(self.config, 'get_setting'):
                enable_cache = self.config.get_setting('enable_cache', True)
            elif hasattr(self.config, 'settings'):
                enable_cache = self.config.settings.get('enable_cache', True)

            self.matcher = FileMatcher(
                self.config.get_resource_folder(),
                enable_cache=enable_cache
            )

            self.creator = TorrentCreator(
                self.config.get_trackers(),
                self.config.get_output_folder()
            )

            print("âœ… é…ç½®é‡æ–°åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ é‡æ–°åŠ è½½é…ç½®å¤±è´¥: {e}")

    def _export_config(self):
        """å¯¼å‡ºé…ç½®"""
        print("\nğŸ“¤ å¯¼å‡ºé…ç½®")
        print("=" * 30)

        default_path = f"torrent_maker_config_{time.strftime('%Y%m%d_%H%M%S')}.json"
        export_path = input(f"è¯·è¾“å…¥å¯¼å‡ºæ–‡ä»¶è·¯å¾„ (å›è½¦ä½¿ç”¨é»˜è®¤: {default_path}): ").strip()

        if not export_path:
            export_path = default_path

        try:
            if hasattr(self.config, 'export_config'):
                if self.config.export_config(export_path):
                    print(f"âœ… é…ç½®å·²å¯¼å‡ºåˆ°: {export_path}")
                else:
                    print("âŒ å¯¼å‡ºå¤±è´¥")
            else:
                # æ‰‹åŠ¨å¯¼å‡ºé…ç½®
                export_data = {
                    'settings': self.config.settings,
                    'trackers': self.config.get_trackers(),
                    'export_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'version': VERSION
                }

                with open(export_path, 'w', encoding='utf-8') as f:
                    import json
                    json.dump(export_data, f, ensure_ascii=False, indent=4)

                print(f"âœ… é…ç½®å·²å¯¼å‡ºåˆ°: {export_path}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºé…ç½®å¤±è´¥: {e}")

    def _import_config(self):
        """å¯¼å…¥é…ç½®"""
        print("\nğŸ“¥ å¯¼å…¥é…ç½®")
        print("=" * 30)
        print("âš ï¸ è­¦å‘Šï¼šå¯¼å…¥é…ç½®å°†è¦†ç›–å½“å‰æ‰€æœ‰è®¾ç½®")

        import_path = input("è¯·è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„: ").strip()
        if not import_path:
            print("âŒ è·¯å¾„ä¸èƒ½ä¸ºç©º")
            return

        if not os.path.exists(import_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {import_path}")
            return

        confirm = input("ç¡®è®¤å¯¼å…¥é…ç½®ï¼Ÿè¿™å°†è¦†ç›–å½“å‰è®¾ç½® (y/N): ").strip().lower()
        if confirm not in ['y', 'yes', 'æ˜¯']:
            print("âŒ å·²å–æ¶ˆå¯¼å…¥")
            return

        try:
            if hasattr(self.config, 'import_config'):
                if self.config.import_config(import_path):
                    print("âœ… é…ç½®å¯¼å…¥æˆåŠŸ")
                    self._reload_config()  # é‡æ–°åŠ è½½é…ç½®
                else:
                    print("âŒ å¯¼å…¥å¤±è´¥")
            else:
                # æ‰‹åŠ¨å¯¼å…¥é…ç½®
                with open(import_path, 'r', encoding='utf-8') as f:
                    import json
                    import_data = json.load(f)

                if 'settings' in import_data:
                    self.config.settings.update(import_data['settings'])
                    self.config.save_settings()

                if 'trackers' in import_data:
                    self.config.trackers = import_data['trackers']
                    self.config.save_trackers()

                print("âœ… é…ç½®å¯¼å…¥æˆåŠŸ")
                self._reload_config()  # é‡æ–°åŠ è½½é…ç½®

        except Exception as e:
            print(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {e}")

    def _clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        print("\nğŸ§¹ æ¸…ç†ç¼“å­˜")
        print("=" * 40)

        try:
            cleared_items = 0

            # æ¸…ç†æœç´¢ç¼“å­˜
            if hasattr(self.matcher, 'cache') and self.matcher.cache:
                cache_stats = self.matcher.cache.get_stats()
                if cache_stats:
                    cleared_items += cache_stats.get('total_items', 0)
                self.matcher.cache._cache.clear()
                print("âœ… æœç´¢ç¼“å­˜å·²æ¸…ç†")

            # æ¸…ç†æ–‡ä»¶å¤¹ä¿¡æ¯ç¼“å­˜
            if hasattr(self.matcher, 'folder_info_cache') and self.matcher.folder_info_cache:
                cache_stats = self.matcher.folder_info_cache.get_stats()
                if cache_stats:
                    cleared_items += cache_stats.get('total_items', 0)
                self.matcher.folder_info_cache._cache.clear()
                print("âœ… æ–‡ä»¶å¤¹ä¿¡æ¯ç¼“å­˜å·²æ¸…ç†")

            # æ¸…ç†å¤§å°ç¼“å­˜
            if hasattr(self.matcher, 'size_cache') and self.matcher.size_cache:
                if hasattr(self.matcher.size_cache, '_cache'):
                    self.matcher.size_cache._cache.clear()
                    print("âœ… å¤§å°ç¼“å­˜å·²æ¸…ç†")

            # æ¸…ç†æ™ºèƒ½ç´¢å¼•ç¼“å­˜
            if hasattr(self.matcher, 'smart_index') and self.matcher.smart_index:
                if hasattr(self.matcher.smart_index, '_word_index'):
                    self.matcher.smart_index._word_index.clear()
                    print("âœ… æ™ºèƒ½ç´¢å¼•ç¼“å­˜å·²æ¸…ç†")

            print(f"âœ… ç¼“å­˜æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleared_items} ä¸ªç¼“å­˜é¡¹")
            print("ğŸ’¡ å»ºè®®: æ¸…ç†ç¼“å­˜åé¦–æ¬¡æœç´¢å¯èƒ½ä¼šç¨æ…¢ï¼Œä½†å¯ä»¥è§£å†³ç¼–ç é—®é¢˜")

        except Exception as e:
            print(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")

    def _reset_config(self):
        """é‡ç½®é…ç½®ä¸ºé»˜è®¤å€¼"""
        print("\nğŸ”„ é‡ç½®é…ç½®")
        print("=" * 30)
        print("âš ï¸ è­¦å‘Šï¼šè¿™å°†é‡ç½®æ‰€æœ‰é…ç½®ä¸ºé»˜è®¤å€¼")
        print("åŒ…æ‹¬ï¼šèµ„æºæ–‡ä»¶å¤¹ã€è¾“å‡ºæ–‡ä»¶å¤¹ã€Trackeråˆ—è¡¨ç­‰")

        confirm = input("ç¡®è®¤é‡ç½®æ‰€æœ‰é…ç½®ä¸ºé»˜è®¤å€¼ï¼Ÿ(y/N): ").strip().lower()
        if confirm not in ['y', 'yes', 'æ˜¯']:
            print("âŒ å·²å–æ¶ˆé‡ç½®")
            return

        try:
            if hasattr(self.config, 'reset_to_defaults'):
                if self.config.reset_to_defaults():
                    print("âœ… é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
                    self._reload_config()  # é‡æ–°åŠ è½½é…ç½®
                else:
                    print("âŒ é‡ç½®å¤±è´¥")
            else:
                # æ‰‹åŠ¨é‡ç½®é…ç½®
                self.config.settings = self.config.DEFAULT_SETTINGS.copy()
                self.config.trackers = self.config.DEFAULT_TRACKERS.copy()

                # å±•å¼€ç”¨æˆ·ç›®å½•è·¯å¾„
                self.config.settings['resource_folder'] = os.path.expanduser(
                    self.config.settings['resource_folder']
                )
                self.config.settings['output_folder'] = os.path.expanduser(
                    self.config.settings['output_folder']
                )

                self.config.save_settings()
                self.config.save_trackers()

                print("âœ… é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
                self._reload_config()  # é‡æ–°åŠ è½½é…ç½®

        except Exception as e:
            print(f"âŒ é‡ç½®é…ç½®å¤±è´¥: {e}")

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        self.display_header()

        while True:
            try:
                self.display_menu()
                max_choice = 8 if ENHANCED_FEATURES_AVAILABLE else 7
                choice = input(f"è¯·é€‰æ‹©æ“ä½œ (0-{max_choice}): ").strip()

                if choice == '0':
                    print(f"ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ {FULL_VERSION_INFO}ï¼")
                    break
                elif choice == '1':
                    self.search_and_create()
                elif choice == '2':
                    self.quick_create()
                elif choice == '3':
                    self.batch_create()
                elif choice == '4':
                    self.config_management()
                elif choice == '5':
                    self.show_performance_stats()
                elif choice == '6':
                    self._show_queue_management_interface()
                elif choice == '7':
                    if ENHANCED_FEATURES_AVAILABLE:
                        self.search_history_management()
                    else:
                        self.show_help()
                elif choice == '8' and ENHANCED_FEATURES_AVAILABLE:
                    self.show_help()
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

                print()

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break
            except Exception as e:
                print(f"âŒ ç¨‹åºè¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def search_history_management(self):
        """æœç´¢å†å²ç®¡ç†"""
        if not self.search_history:
            print("âŒ æœç´¢å†å²åŠŸèƒ½ä¸å¯ç”¨")
            return
            
        while True:
            print("\nğŸ“ æœç´¢å†å²ç®¡ç†")
            print("=" * 60)
            print("  1. ğŸ“‹ æŸ¥çœ‹æœç´¢å†å²")
            print("  2. ğŸ”¥ æŸ¥çœ‹çƒ­é—¨æœç´¢")
            print("  3. ğŸ“Š æŸ¥çœ‹æœç´¢ç»Ÿè®¡")
            print("  4. ğŸ—‘ï¸  æ¸…ç†æœç´¢å†å²")
            print("  5. ğŸ“¤ å¯¼å‡ºæœç´¢å†å²")
            print("  0. ğŸ”™ è¿”å›ä¸»èœå•")
            print()
            
            choice = input("è¯·é€‰æ‹©æ“ä½œ (0-5): ").strip()
            
            if choice == '0':
                break
            elif choice == '1':
                self._show_search_history()
            elif choice == '2':
                self._show_popular_searches()
            elif choice == '3':
                self._show_search_statistics()
            elif choice == '4':
                self._clear_search_history()
            elif choice == '5':
                self._export_search_history()
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def _show_search_history(self):
        """æ˜¾ç¤ºæœç´¢å†å²"""
        # å°è¯•è·å–è¯¦ç»†æœç´¢è®°å½•ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ç®€å•æŸ¥è¯¢åˆ—è¡¨
        try:
            recent_searches = self.search_history.get_recent_searches(20)
        except AttributeError:
            # å¦‚æœæ²¡æœ‰ get_recent_searches æ–¹æ³•ï¼Œä½¿ç”¨ get_recent_queries
            recent_queries = self.search_history.get_recent_queries(20)
            if not recent_queries:
                print("\nğŸ“ æš‚æ— æœç´¢å†å²")
                return
            print("\nğŸ“‹ æœ€è¿‘æœç´¢å†å²:")
            for i, query in enumerate(recent_queries, 1):
                print(f"  {i}. {query}")
            return
            
        if not recent_searches:
            print("\nğŸ“ æš‚æ— æœç´¢å†å²")
            return
            
        print("\nğŸ“‹ æœ€è¿‘æœç´¢å†å²:")
        print("-" * 80)
        print(f"{'åºå·':<4} {'æœç´¢å†…å®¹':<30} {'ç»“æœæ•°':<8} {'æœç´¢æ—¶é—´':<12} {'è€—æ—¶':<8}")
        print("-" * 80)
        
        for i, search in enumerate(recent_searches, 1):
            # å…¼å®¹ä¸åŒçš„æ•°æ®ç»“æ„
            if isinstance(search, dict):
                query = search.get('query', 'N/A')
                result_count = search.get('result_count', 0)
                timestamp = search.get('timestamp', 'N/A')
                duration = search.get('duration', 'N/A')
                if isinstance(timestamp, str):
                    timestamp_str = timestamp[:16] if len(timestamp) > 16 else timestamp
                else:
                    timestamp_str = timestamp.strftime('%m-%d %H:%M') if hasattr(timestamp, 'strftime') else 'N/A'
                duration_str = f"{duration:.3f}s" if isinstance(duration, (int, float)) else "N/A"
            elif hasattr(search, 'query'):
                query = search.query
                result_count = getattr(search, 'result_count', 0)
                timestamp_str = search.timestamp.strftime('%m-%d %H:%M') if hasattr(search, 'timestamp') else 'N/A'
                duration_str = f"{search.duration:.3f}s" if hasattr(search, 'duration') and search.duration else "N/A"
            else:
                query = str(search)
                result_count = 0
                timestamp_str = 'N/A'
                duration_str = 'N/A'
                
            print(f"{i:<4} {query[:28]:<30} {result_count:<8} {timestamp_str:<12} {duration_str:<8}")
    
    def _show_popular_searches(self):
        """æ˜¾ç¤ºçƒ­é—¨æœç´¢"""
        popular_searches = self.search_history.get_popular_queries(10)
        if not popular_searches:
            print("\nğŸ”¥ æš‚æ— çƒ­é—¨æœç´¢")
            return
            
        print("\nğŸ”¥ çƒ­é—¨æœç´¢ (æŒ‰æœç´¢æ¬¡æ•°æ’åº):")
        print("-" * 50)
        print(f"{'æ’å':<4} {'æœç´¢å†…å®¹':<30} {'æœç´¢æ¬¡æ•°':<8}")
        print("-" * 50)
        
        for i, (query, count) in enumerate(popular_searches, 1):
            print(f"{i:<4} {query[:28]:<30} {count:<8}")
    
    def _show_search_statistics(self):
        """æ˜¾ç¤ºæœç´¢ç»Ÿè®¡"""
        stats = self.search_history.get_statistics()
        if not stats:
            print("\nğŸ“Š æš‚æ— æœç´¢ç»Ÿè®¡")
            return
            
        print("\nğŸ“Š æœç´¢ç»Ÿè®¡ä¿¡æ¯:")
        print("-" * 40)
        print(f"æ€»æœç´¢æ¬¡æ•°: {stats['total_searches']}")
        print(f"æˆåŠŸæœç´¢æ¬¡æ•°: {stats['successful_searches']}")
        print(f"æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"å¹³å‡æœç´¢è€—æ—¶: {stats['average_duration']:.3f}s")
        print(f"å¹³å‡ç»“æœæ•°: {stats['average_results']:.1f}")
        print(f"æœ€æ—©æœç´¢: {stats['earliest_search'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æœ€è¿‘æœç´¢: {stats['latest_search'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    def _clear_search_history(self):
        """æ¸…ç†æœç´¢å†å²"""
        confirm = input("\nâš ï¸ ç¡®è®¤æ¸…ç†æ‰€æœ‰æœç´¢å†å²ï¼Ÿ(y/N): ").strip().lower()
        if confirm in ['y', 'yes', 'æ˜¯']:
            self.search_history.clear_history()
            print("âœ… æœç´¢å†å²å·²æ¸…ç†")
        else:
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
    
    def _export_search_history(self):
        """å¯¼å‡ºæœç´¢å†å²"""
        try:
            filename = f"search_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(os.getcwd(), filename)
            self.search_history.export_history(filepath)
            print(f"âœ… æœç´¢å†å²å·²å¯¼å‡ºåˆ°: {filepath}")
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

    def show_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)

        # è·å–æ–‡ä»¶åŒ¹é…å™¨çš„æ€§èƒ½ç»Ÿè®¡
        if hasattr(self.matcher, 'performance_monitor'):
            matcher_stats = self.matcher.performance_monitor.get_all_stats()
            if matcher_stats:
                print("ğŸ” æœç´¢æ€§èƒ½:")
                for name, stats in matcher_stats.items():
                    if stats:
                        print(f"  {name}:")
                        print(f"    æ‰§è¡Œæ¬¡æ•°: {stats['count']}")
                        print(f"    å¹³å‡è€—æ—¶: {stats['average']:.3f}s")
                        print(f"    æœ€å¤§è€—æ—¶: {stats['max']:.3f}s")
                        print(f"    æ€»è€—æ—¶: {stats['total']:.3f}s")
                print()

        # è·å–ç§å­åˆ›å»ºå™¨çš„æ€§èƒ½ç»Ÿè®¡
        if hasattr(self.creator, 'performance_monitor'):
            creator_stats = self.creator.performance_monitor.get_all_stats()
            if creator_stats:
                print("ğŸ› ï¸ ç§å­åˆ›å»ºæ€§èƒ½:")
                for name, stats in creator_stats.items():
                    if stats:
                        print(f"  {name}:")
                        print(f"    æ‰§è¡Œæ¬¡æ•°: {stats['count']}")
                        print(f"    å¹³å‡è€—æ—¶: {stats['average']:.3f}s")
                        print(f"    æœ€å¤§è€—æ—¶: {stats['max']:.3f}s")
                        print(f"    æ€»è€—æ—¶: {stats['total']:.3f}s")
                print()

        # è·å–ç¼“å­˜ç»Ÿè®¡
        if hasattr(self.matcher, 'cache') and self.matcher.cache:
            cache_stats = self.matcher.cache.get_stats()
            if cache_stats:
                print("ğŸ’¾ ç¼“å­˜ç»Ÿè®¡:")
                print(f"  æ€»ç¼“å­˜é¡¹: {cache_stats['total_items']}")
                print(f"  æœ‰æ•ˆç¼“å­˜é¡¹: {cache_stats['valid_items']}")
                print(f"  è¿‡æœŸç¼“å­˜é¡¹: {cache_stats['expired_items']}")
                print()

        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        print("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        suggestions = self._generate_performance_suggestions()
        if suggestions:
            for i, suggestion in enumerate(suggestions, 1):
                print(f"  {i}. {suggestion}")
        else:
            print("  å½“å‰æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")

        print("=" * 60)

    def _generate_performance_suggestions(self) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        suggestions = []

        # æ£€æŸ¥æœç´¢æ€§èƒ½
        if hasattr(self.matcher, 'performance_monitor'):
            search_stats = self.matcher.performance_monitor.get_stats('fuzzy_search')
            if search_stats and search_stats.get('average', 0) > 2.0:
                suggestions.append("æœç´¢è€—æ—¶è¾ƒé•¿ï¼Œå»ºè®®å¢åŠ ç¼“å­˜æ—¶é—´æˆ–å‡å°‘æœç´¢æ·±åº¦")

        # æ£€æŸ¥ç§å­åˆ›å»ºæ€§èƒ½
        if hasattr(self.creator, 'performance_monitor'):
            creation_stats = self.creator.performance_monitor.get_stats('total_torrent_creation')
            if creation_stats and creation_stats.get('average', 0) > 30.0:
                suggestions.append("ç§å­åˆ›å»ºè€—æ—¶è¾ƒé•¿ï¼Œå»ºè®®æ£€æŸ¥ç£ç›˜æ€§èƒ½æˆ–å‡å°‘æ–‡ä»¶æ•°é‡")

        # æ£€æŸ¥ç¼“å­˜ä½¿ç”¨æƒ…å†µ
        if hasattr(self.matcher, 'cache') and self.matcher.cache:
            cache_stats = self.matcher.cache.get_stats()
            if cache_stats and cache_stats.get('valid_items', 0) == 0:
                suggestions.append("ç¼“å­˜æœªè¢«æœ‰æ•ˆåˆ©ç”¨ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜é…ç½®")

        return suggestions

    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\nâ“ å¸®åŠ©ä¿¡æ¯")
        print("=" * 50)
        print("ğŸ” æœç´¢åŠŸèƒ½:")
        print("  - æ”¯æŒæ¨¡ç³Šæœç´¢ï¼Œå®¹é”™ç‡é«˜")
        print("  - è‡ªåŠ¨è¯†åˆ«å‰§é›†ä¿¡æ¯")
        print("  - æ™ºèƒ½ç¼“å­˜ï¼Œé‡å¤æœç´¢æ›´å¿«")
        print()
        print("âš¡ å¿«é€Ÿåˆ¶ç§:")
        print("  - ç›´æ¥è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„")
        print("  - æ”¯æŒæ‰¹é‡è·¯å¾„ (ç”¨åˆ†å·åˆ†éš”)")
        print()
        print("ğŸ¯ æ€§èƒ½ä¼˜åŒ–:")
        print("  - å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†")
        print("  - æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ")
        print("  - å†…å­˜ä½¿ç”¨ä¼˜åŒ–")
        print("  - å®æ—¶æ€§èƒ½ç›‘æ§")
        print("=" * 50)


def main():
    """ä¸»å‡½æ•°"""
    try:
        app = TorrentMakerApp()
        app.run()
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
