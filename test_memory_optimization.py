#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Torrent Maker v1.5.0 å†…å­˜ç®¡ç†ä¼˜åŒ–æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•å†…å­˜ç®¡ç†åŠŸèƒ½çš„æ•ˆæœ

ä½œè€…ï¼šTorrent Maker Team
ç‰ˆæœ¬ï¼š1.5.0 Memory Optimization
"""

import os
import sys
import time
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from torrent_maker import (
        MemoryManager, MemoryAnalyzer, StreamFileProcessor,
        DirectorySizeCache, TorrentCreator
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class MemoryOptimizationTest:
    """å†…å­˜ç®¡ç†ä¼˜åŒ–æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_data_dir = None
        self.results = {}
    
    def setup_test_data(self) -> str:
        """åˆ›å»ºå†…å­˜æµ‹è¯•æ•°æ®"""
        print("ğŸ”§ åˆ›å»ºå†…å­˜æµ‹è¯•æ•°æ®...")
        
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
        self.test_data_dir = tempfile.mkdtemp(prefix="memory_test_")
        test_path = Path(self.test_data_dir)
        
        # åˆ›å»ºå¤§é‡å°æ–‡ä»¶å’Œå°‘é‡å¤§æ–‡ä»¶
        print("  åˆ›å»ºå°æ–‡ä»¶...")
        small_files_dir = test_path / "small_files"
        small_files_dir.mkdir()
        
        for i in range(1000):  # 1000 ä¸ªå°æ–‡ä»¶
            file_path = small_files_dir / f"small_file_{i:04d}.txt"
            with open(file_path, 'w') as f:
                f.write(f"Small file content {i}" * 100)  # çº¦ 2KB æ¯ä¸ªæ–‡ä»¶
        
        # åˆ›å»ºå¤§æ–‡ä»¶
        print("  åˆ›å»ºå¤§æ–‡ä»¶...")
        large_files_dir = test_path / "large_files"
        large_files_dir.mkdir()
        
        for i in range(3):  # 3 ä¸ªå¤§æ–‡ä»¶
            file_path = large_files_dir / f"large_file_{i}.dat"
            with open(file_path, 'wb') as f:
                # åˆ›å»º 10MB çš„æ–‡ä»¶
                chunk = b'0' * (1024 * 1024)  # 1MB chunk
                for _ in range(10):
                    f.write(chunk)
        
        print(f"âœ… æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ: {self.test_data_dir}")
        return self.test_data_dir
    
    def cleanup_test_data(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        if self.test_data_dir and os.path.exists(self.test_data_dir):
            shutil.rmtree(self.test_data_dir)
            print(f"ğŸ§¹ æµ‹è¯•æ•°æ®å·²æ¸…ç†: {self.test_data_dir}")
    
    def test_memory_manager_basic(self) -> Dict[str, Any]:
        """æµ‹è¯•å†…å­˜ç®¡ç†å™¨åŸºæœ¬åŠŸèƒ½"""
        print("\nğŸ’¾ æµ‹è¯•å†…å­˜ç®¡ç†å™¨åŸºæœ¬åŠŸèƒ½...")
        
        memory_manager = MemoryManager(max_memory_mb=128)
        
        results = {
            'initial_memory': memory_manager.get_memory_usage(),
            'memory_analysis': {},
            'cleanup_results': {},
            'final_memory': {}
        }
        
        print("  åˆå§‹å†…å­˜çŠ¶æ€:")
        initial_mem = results['initial_memory']
        print(f"    RSS: {initial_mem.get('rss_mb', 0):.1f}MB")
        print(f"    ç³»ç»Ÿä½¿ç”¨: {initial_mem.get('system_used_percent', 0):.1f}%")
        
        # è·å–å†…å­˜åˆ†æ
        print("  è·å–å†…å­˜åˆ†æ...")
        analysis = memory_manager.get_memory_analysis()
        results['memory_analysis'] = analysis
        
        print(f"    å¯¹è±¡æ€»æ•°: {analysis['object_analysis']['total_objects']}")
        print(f"    å†…å­˜è¶‹åŠ¿: {analysis['memory_trend']['trend']}")
        print(f"    å»ºè®®æ•°é‡: {len(analysis['recommendations'])}")
        
        # æµ‹è¯•å†…å­˜æ¸…ç†
        print("  æµ‹è¯•å†…å­˜æ¸…ç†...")
        cleanup_result = memory_manager.cleanup_memory()
        results['cleanup_results'] = cleanup_result
        
        print(f"    æ¸…ç†é¡¹ç›®: {cleanup_result.get('memory_pools_cleaned', 0)}")
        print(f"    GC å›æ”¶: {cleanup_result.get('gc_collected', 0)}")
        print(f"    é‡Šæ”¾å†…å­˜: {cleanup_result.get('freed_mb', 0):.1f}MB")
        
        # æœ€ç»ˆå†…å­˜çŠ¶æ€
        results['final_memory'] = memory_manager.get_memory_usage()
        
        return results
    
    def test_stream_processor_memory(self) -> Dict[str, Any]:
        """æµ‹è¯•æµå¼å¤„ç†å™¨å†…å­˜ä¼˜åŒ–"""
        print("\nğŸŒŠ æµ‹è¯•æµå¼å¤„ç†å™¨å†…å­˜ä¼˜åŒ–...")
        
        memory_manager = MemoryManager(max_memory_mb=64)  # è¾ƒå°çš„å†…å­˜é™åˆ¶
        stream_processor = StreamFileProcessor(memory_manager=memory_manager)
        
        results = {
            'large_file_processing': [],
            'directory_processing': {},
            'memory_efficiency': {}
        }
        
        # æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†
        large_files_dir = Path(self.test_data_dir) / "large_files"
        if large_files_dir.exists():
            print("  æµ‹è¯•å¤§æ–‡ä»¶æµå¼å¤„ç†...")
            
            for file_path in large_files_dir.iterdir():
                if file_path.is_file():
                    print(f"    å¤„ç†æ–‡ä»¶: {file_path.name}")
                    
                    start_time = time.time()
                    start_memory = memory_manager.get_memory_usage()['rss_mb']
                    
                    # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                    file_hash = stream_processor.calculate_file_hash(file_path)
                    
                    end_time = time.time()
                    end_memory = memory_manager.get_memory_usage()['rss_mb']
                    
                    results['large_file_processing'].append({
                        'file': file_path.name,
                        'size_mb': file_path.stat().st_size / (1024 * 1024),
                        'processing_time': end_time - start_time,
                        'memory_before': start_memory,
                        'memory_after': end_memory,
                        'memory_delta': end_memory - start_memory,
                        'hash_length': len(file_hash)
                    })
        
        # æµ‹è¯•ç›®å½•å¤„ç†
        print("  æµ‹è¯•ç›®å½•æµå¼å¤„ç†...")
        start_memory = memory_manager.get_memory_usage()['rss_mb']
        
        directory_result = stream_processor.process_large_directory(
            Path(self.test_data_dir), operation='size'
        )
        
        end_memory = memory_manager.get_memory_usage()['rss_mb']
        
        results['directory_processing'] = {
            'total_size_mb': directory_result['total_size'] / (1024 * 1024),
            'file_count': directory_result['file_count'],
            'error_count': len(directory_result['errors']),
            'memory_before': start_memory,
            'memory_after': end_memory,
            'memory_delta': end_memory - start_memory
        }
        
        # å†…å­˜æ•ˆç‡åˆ†æ
        results['memory_efficiency'] = memory_manager.get_memory_analysis()
        
        return results
    
    def test_directory_cache_memory(self) -> Dict[str, Any]:
        """æµ‹è¯•ç›®å½•ç¼“å­˜å†…å­˜ä¼˜åŒ–"""
        print("\nğŸ“ æµ‹è¯•ç›®å½•ç¼“å­˜å†…å­˜ä¼˜åŒ–...")
        
        cache = DirectorySizeCache(max_cache_size=50)  # è¾ƒå°çš„ç¼“å­˜é™åˆ¶
        
        results = {
            'cache_performance': [],
            'memory_usage': [],
            'cache_stats': {}
        }
        
        # æµ‹è¯•å¤šæ¬¡ç›®å½•æ‰«æ
        test_dirs = [
            Path(self.test_data_dir),
            Path(self.test_data_dir) / "small_files",
            Path(self.test_data_dir) / "large_files"
        ]
        
        for i, test_dir in enumerate(test_dirs):
            if test_dir.exists():
                print(f"  æµ‹è¯•ç›®å½• {i+1}: {test_dir.name}")
                
                # ç¬¬ä¸€æ¬¡æ‰«æï¼ˆå†·ç¼“å­˜ï¼‰
                start_time = time.time()
                size1 = cache.get_directory_size(test_dir)
                cold_time = time.time() - start_time
                
                # ç¬¬äºŒæ¬¡æ‰«æï¼ˆçƒ­ç¼“å­˜ï¼‰
                start_time = time.time()
                size2 = cache.get_directory_size(test_dir)
                warm_time = time.time() - start_time
                
                results['cache_performance'].append({
                    'directory': test_dir.name,
                    'size_mb': size1 / (1024 * 1024),
                    'cold_time': cold_time,
                    'warm_time': warm_time,
                    'speedup': cold_time / warm_time if warm_time > 0 else 0,
                    'size_consistent': size1 == size2
                })
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        results['cache_stats'] = cache.get_cache_stats()
        
        return results
    
    def test_integrated_memory_management(self) -> Dict[str, Any]:
        """æµ‹è¯•é›†æˆå†…å­˜ç®¡ç†"""
        print("\nğŸš€ æµ‹è¯•é›†æˆå†…å­˜ç®¡ç†...")
        
        # åˆ›å»º TorrentCreator å®ä¾‹
        creator = TorrentCreator(
            tracker_links=["udp://test.tracker.com:8080/announce"],
            output_dir=tempfile.mkdtemp(),
            max_workers=2
        )
        
        results = {
            'system_info': creator.get_system_info(),
            'performance_stats': {},
            'memory_analysis': {},
            'cleanup_results': {}
        }
        
        print("  è·å–ç³»ç»Ÿä¿¡æ¯...")
        sys_info = results['system_info']
        print(f"    ç‰ˆæœ¬: {sys_info['version']}")
        print(f"    å†…å­˜ä½¿ç”¨: {sys_info['memory_info'].get('rss_mb', 0):.1f}MB")
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        print("  è·å–æ€§èƒ½ç»Ÿè®¡...")
        perf_stats = creator.get_performance_stats()
        results['performance_stats'] = perf_stats
        
        memory_mgmt = perf_stats.get('memory_management', {})
        print(f"    å½“å‰å†…å­˜: {memory_mgmt.get('current_usage_mb', 0):.1f}MB")
        print(f"    å†…å­˜æ•ˆç‡: {memory_mgmt.get('memory_efficiency', 'Unknown')}")
        
        # è·å–å†…å­˜åˆ†æ
        print("  è·å–å†…å­˜åˆ†æ...")
        memory_analysis = creator.memory_manager.get_memory_analysis()
        results['memory_analysis'] = memory_analysis
        
        print(f"    å†…å­˜è¶‹åŠ¿: {memory_analysis['memory_trend']['trend']}")
        print(f"    ä¼˜åŒ–å»ºè®®: {len(memory_analysis['recommendations'])}")
        
        # æµ‹è¯•æ¸…ç†
        print("  æµ‹è¯•é›†æˆæ¸…ç†...")
        cleanup_result = creator.clear_caches()
        results['cleanup_results'] = cleanup_result
        
        print(f"    æ€»æ¸…ç†é¡¹ç›®: {sum(v for k, v in cleanup_result.items() if isinstance(v, int))}")
        
        return results
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰å†…å­˜ç®¡ç†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ Torrent Maker v1.5.0 å†…å­˜ç®¡ç†ä¼˜åŒ–æµ‹è¯•...")
        print("=" * 60)
        
        try:
            # è®¾ç½®æµ‹è¯•æ•°æ®
            self.setup_test_data()
            
            # è¿è¡Œå„é¡¹æµ‹è¯•
            self.results['memory_manager'] = self.test_memory_manager_basic()
            self.results['stream_processor'] = self.test_stream_processor_memory()
            self.results['directory_cache'] = self.test_directory_cache_memory()
            self.results['integrated'] = self.test_integrated_memory_management()
            
            return self.results
            
        finally:
            # æ¸…ç†æµ‹è¯•æ•°æ®
            self.cleanup_test_data()
    
    def print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ“Š Torrent Maker v1.5.0 å†…å­˜ç®¡ç†ä¼˜åŒ–æµ‹è¯•ç»“æœ")
        print("=" * 60)
        
        # å†…å­˜ç®¡ç†å™¨ç»“æœ
        if 'memory_manager' in self.results:
            mm_results = self.results['memory_manager']
            print(f"\nğŸ’¾ å†…å­˜ç®¡ç†å™¨:")
            print(f"  åˆå§‹å†…å­˜: {mm_results['initial_memory'].get('rss_mb', 0):.1f}MB")
            print(f"  æœ€ç»ˆå†…å­˜: {mm_results['final_memory'].get('rss_mb', 0):.1f}MB")
            print(f"  é‡Šæ”¾å†…å­˜: {mm_results['cleanup_results'].get('freed_mb', 0):.1f}MB")
            
            analysis = mm_results['memory_analysis']
            print(f"  å†…å­˜è¶‹åŠ¿: {analysis['memory_trend']['trend']}")
            print(f"  ä¼˜åŒ–å»ºè®®: {len(analysis['recommendations'])}")
        
        # æµå¼å¤„ç†å™¨ç»“æœ
        if 'stream_processor' in self.results:
            sp_results = self.results['stream_processor']
            print(f"\nğŸŒŠ æµå¼å¤„ç†å™¨:")
            
            if sp_results['large_file_processing']:
                avg_memory_delta = sum(item['memory_delta'] for item in sp_results['large_file_processing']) / len(sp_results['large_file_processing'])
                print(f"  å¤§æ–‡ä»¶å¤„ç†: {len(sp_results['large_file_processing'])} ä¸ªæ–‡ä»¶")
                print(f"  å¹³å‡å†…å­˜å¢é•¿: {avg_memory_delta:.1f}MB")
            
            dir_proc = sp_results['directory_processing']
            print(f"  ç›®å½•å¤„ç†: {dir_proc['file_count']} ä¸ªæ–‡ä»¶")
            print(f"  å†…å­˜å¢é•¿: {dir_proc['memory_delta']:.1f}MB")
        
        # ç›®å½•ç¼“å­˜ç»“æœ
        if 'directory_cache' in self.results:
            dc_results = self.results['directory_cache']
            print(f"\nğŸ“ ç›®å½•ç¼“å­˜:")
            
            if dc_results['cache_performance']:
                avg_speedup = sum(item['speedup'] for item in dc_results['cache_performance']) / len(dc_results['cache_performance'])
                print(f"  å¹³å‡åŠ é€Ÿæ¯”: {avg_speedup:.1f}x")
            
            cache_stats = dc_results['cache_stats']
            print(f"  ç¼“å­˜å‘½ä¸­ç‡: {cache_stats.get('hit_rate', 0):.1%}")
            print(f"  ç¼“å­˜å¤§å°: {cache_stats.get('cache_size', 0)}")
        
        # é›†æˆæµ‹è¯•ç»“æœ
        if 'integrated' in self.results:
            int_results = self.results['integrated']
            sys_info = int_results['system_info']
            print(f"\nğŸš€ é›†æˆæµ‹è¯•:")
            print(f"  ç‰ˆæœ¬: {sys_info['version']}")
            print(f"  æ€§èƒ½ç­‰çº§: {sys_info['performance_grade']}")
            print(f"  åŠŸèƒ½ç‰¹æ€§: {len(sys_info['features'])} é¡¹")
        
        print("\n" + "=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Torrent Maker v1.5.0 å†…å­˜ç®¡ç†ä¼˜åŒ–æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    test_suite = MemoryOptimizationTest()
    
    try:
        results = test_suite.run_all_tests()
        test_suite.print_results()
        
        print(f"\nâœ… å†…å­˜ç®¡ç†ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
        print("ğŸš€ v1.5.0 å†…å­˜ç®¡ç†ä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼š")
        print("   ğŸ’¾ æ™ºèƒ½å†…å­˜ç›‘æ§å’Œåˆ†æ")
        print("   ğŸŒŠ æµå¼å¤„ç†é¿å…å†…å­˜æº¢å‡º")
        print("   ğŸ“ LRU ç¼“å­˜å†…å­˜æ§åˆ¶")
        print("   ğŸ§¹ è‡ªåŠ¨å†…å­˜æ¸…ç†å’Œä¼˜åŒ–")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        test_suite.cleanup_test_data()


if __name__ == "__main__":
    main()
